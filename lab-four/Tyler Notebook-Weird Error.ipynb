{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "The dataset we chose contains car evaluation data derived from a hierarchical decision model developed initially for a demonstration of a decision making model and can be found at [[1]](#footnote1). The authors The dataset contains 6 attributes related to either price or technical characteristics. The 7th attribute represents the estimated class of the car and is based on all other attributes. The dataset consists of 1728 entries and is stripped of structural attributes, which means all attributes are directly related to the estimated car class attribute. There are also three intermediate attributes – PRICE, TECH and COMFORT – which are related to the 6 main attributes. \n",
    "## Use case\n",
    "Choosing a vehicle to purchase can be a tedious process that involves hours of research, with studies showing American drivers spend an average of around 15 hours between realizing the need for a new car and making the purchase [[2]](#footnote2). 60% of this time is usually spent in online research of specifications and availability. Generally, although the most important attribute of a car is its ability to transport, the final decision is very often based on an amalgam of its price, safety and capacity. The main purpose for the collection of the dataset we chose was to “actively support the decision maker in the knowledge acquisition and evaluation stages of the decision making process” [[3]](#footnote3). \n",
    "\n",
    "Furthermore, manufacturers have large vested interests in desinging cars that are acceptable to consumers. Developing a car that the market reacts to well can be the difference between a thriving company and a failing company. This is because bringing a car to market has a high level of fixed costs. These costs include: research, design, prototyping, sourcing, manufacuring, initial marketing, transporation, and storage. All these are costs that are incurred before any dollar of revenue from that product line comes in. This money is usually raised through issuing bonds or raising equity. A failed car can make a company default on its loans (because revenues do not cover costs) and for those issuing equity it can tank their equity value given that a share price represents the future cash flows of a company. A company with no profits has no positive cash flows, and thus the company value is destroyed. Thus, it is very important for manufacturers to have an estimate on whether or not their car will perform well. \n",
    "\n",
    "## Prediction task\n",
    "The dataset uses a simple hierarchical model to classify cars in one of 4 categories: Unacceptable (unacc), Acceptable (acc), Good (good), Very Good (vgood). The criteria tree is displayed below. The goal of our prediction task is to correctly identify the class associated with the car based on the 6 attributes that are used in the evaluation model, without specifying the model structure itself. \n",
    "\n",
    "\n",
    "<img src='tree.png' label=\"Criteria tree\"/ height=500 width=500>\n",
    "This could be useful in many different scenarios, such as helping manufacturers determine whether or not a new car would be well accepted by the market. Even after years of research and development, some car manufacturers suffer big financial losses due to lack of proper competitor analysis in the market and target audience expectations [[4]](#footnote4). Thus, for our evaluation criteria on this dataset, we aim to maximize the number of correctly predicted car classes in the range unacceptable and very good, as described above. The higher the percentage, the more reliable and valuable our algorithm will be to said manufacturers upon releasing a new vehicle to the market. \n",
    "\n",
    "As a benchmark to compare our algorithm against, we consider how accurate car manufacturers are now about predicting how successful their newest model will be. Since the actual predictions a car company has for their models is not public information, we use a proxy to approximate the prediction accuracy: the percentage of cars on the market that are acceptable, good, or very good. We assume that the goal of a car company is to produce a car that is not unacceptable. Thus, the percentage of cars on the market that are unacceptable is similar to the prediction error that car manufacturers exhibit. In our data set, 70% of the cars are unacceptable. Thus, we estimate for the purposes of this exercise that car manufacturers have a 30% accuracy rate in predicting the acceptability of cars.\n",
    "\n",
    "\n",
    "The simplicity of the hierarchical decision model used in the training set could be a limitation to this performance and reliability, as we are only basing our results on the 6 attributes that are provided. A further drawback is the fact that all attributes are nominally assigned, which would fail to account for small differences of attribute values near the hard cutoff limits. \n",
    "\n",
    " \n",
    "\n",
    "### References\n",
    "&nbsp;<a name=\"footnote1\">1</a>: https://archive.ics.uci.edu/ml/datasets/Car+Evaluation <br>\n",
    "&nbsp;<a name=\"footnote2\">2</a>: https://www.elephant.com/blog/car-insurance/new-study-details-how-long-it-takes-before-car-shoppers-buy <br>\n",
    "&nbsp;<a name=\"footnote3\">3</a>: http://kt.ijs.si/MarkoBohanec/pub/Avignon88.pdf <br>\n",
    "&nbsp;<a name=\"footnote4\">4</a>: https://www.popularmechanics.com/cars/g1766/10-cars-that-deserved-to-fail/?slide=3 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of cars that are unacceptable: 0.7002314814814815\n",
      "4\n",
      "1382\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "#import s # Business Understandingcipy\n",
    "import scipy\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.special import expit\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import linear_model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "df = pd.read_csv('car.data')\n",
    "buying_maint_map = {'vhigh':3,'high':2,'med':1,'low':0}\n",
    "df['buy_price'] = df['buy_price'].map(buying_maint_map).astype(np.int)\n",
    "df['maint_price'] = df['maint_price'].map(buying_maint_map).astype(np.int)\n",
    "doors_map = {'2':0,'3':1,'4':2,'5more':3}\n",
    "df['doors'] = df['doors'].map(doors_map).astype(np.int)\n",
    "persons_map = {'2':0,'3':1,'4':2,'more':3}\n",
    "df['persons'] = df['persons'].map(persons_map).astype(np.int)\n",
    "trunk_map = {'small':0,'med':1,'big':2}\n",
    "df['trunk_size'] = df['trunk_size'].map(trunk_map).astype(np.int)\n",
    "safety_map = {'low':0,'med':1,'high':2}\n",
    "df['safety'] = df['safety'].map(safety_map).astype(np.int)\n",
    "class_map = {'unacc':0,'acc':1,'good':2,'vgood':3}\n",
    "df['class'] = df['class'].map(class_map).astype(np.int)\n",
    "\n",
    "\n",
    "feature_cols = ['buy_price','maint_price','doors','persons','trunk_size','safety']\n",
    "class_cols = ['class']\n",
    "\n",
    "unacc_percent = len(df[df['class']==0])/len(df['class'])\n",
    "print('Percent of cars that are unacceptable:',unacc_percent)\n",
    "\n",
    "#Make X a 2D numpy array\n",
    "X = df[feature_cols].as_matrix()\n",
    "#Make y a 1D numpy array\n",
    "y = (df[class_cols]==0).astype(np.int).values.ravel()\n",
    "y_not_binary = (df[class_cols]).astype(np.int).values.ravel()\n",
    "print(max(y_not_binary)+1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_not_binary, test_size=0.2, shuffle=True)\n",
    "print(len(X_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only data processing/preparation we do is to convert the text categories such as 'vhigh', 'small', 'unacc', etc. into integer values. Since these classes are ordered, we use integers instead of one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "To manufacturers, our model's effectiveness depends on how it identifies cars that will get a good market reaction. This will allow the manufacturers to sell cars that will generate profits above their fixed costs and stop them from making cars that will lose them money. \n",
    "\n",
    "Manufacturer profits are estimated by: (simplified equation) \n",
    "\n",
    "<b>\n",
    "Profits = (avg profit from good car lines)(# of succeful car lines) - (avg loss from unacceptable cars)(# of unacceptable cars)\n",
    "</b>\n",
    "\n",
    "What this shows is that not only do we need to be sure that all the cars the manufacturers are making only good cars, we have to help them make as many of them as possible. This means that not only does our model needs to be right when is says a car is a good opportunity, but also needs to be able to identify as many opportunities as possible. \n",
    "\n",
    "What we have mentioned above is that our model needs to be good at both <b><i> recall </i></b> and <b><i> precision </i></b>. These can be sometimes competing efforts. To acheive the best balance of the two there exists a famous metric that takes the harmonic average of recall and precision to offer a point that gives the best balance of the two: F1 Score.\n",
    "\n",
    "### F1 Score: \n",
    "\n",
    "The F1 score is the harmonic average between a test's <b><i> recall </i></b> and <b><i> precision </i></b> scores. F1 is best at 1, and worst at 0. \n",
    "\n",
    "The F1 score calculation is: \n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "\n",
    "#### Recall\n",
    "Good recall is the abillity to mark as many class C instances as class C. This means that when a model with perfect recall is given a class, the model will be able to identify every actual member of class C as class C. Note, this does not mean that all instances marked as Class C are indeed class C, just that those that are class C are marked class C. Thus, this metric is concerned with reducing false negatives. \n",
    "\n",
    "In our case, recall is the ability for our model to be able to identity all good cars as good or all unacceptable cars as unacceptable (and so on and so forth). A high recall on Very good for example would meean that any instance that is very good will be marked as good. It does not guaruntee that all cars marked as very good are indeed very good. \n",
    "\n",
    "\n",
    "#### Precision\n",
    "Precision is the ability for a model to be correct when it denotes a class as a certain class. This means that a model with high precision on a certain class will be accurate when it says a test case is of that class. A model with perfect precision on that class will allow the user to know that if that class was identified as class c, it is class c. There is however no guartuntee that the model will catch all the class c's in the test set - that is what recall is for. Thus, this metric is concerned with reducing false positives. \n",
    "\n",
    "In our case, precision is the abillity for the model to be correct when it labels a car as very good for example. This metric is not concerned with whether or not we capture all the good cars, but with our ability to only cars very good if they are indeed very good.\n",
    "\n",
    "### Aditional Customization: \n",
    "\n",
    "The F1 score is calculated for every class, and then our version takes a macro average accross the classes. For our business case however, we notice that there are classes that are more important than others to improve recall and precision on. These classes are: Unacceptable (unacc), Very Good (vgood). The reason is beacuse firstly, consumers are most interested in the best of cars, and the most losses come to a company from making totally unacceptable cars. And judging by our dataset, where most cars are unacceptable, it is important to make sure that manufacturers avoid creating these cars. \n",
    "\n",
    "Furthermore, it is more important that the cars they do end up making are in fact very good, as opposed to seeing a good car as unacceptable. The reason being once again associated with the fixed costs and time associated with manufacturing a bad car vs. missing a good car. One way to create good weigths for this would be to see what is worse, missing a good car or creating a bad car. Generally, creating a bad car is worse because of the reputaion costs and fixed costs associated with it. \n",
    "\n",
    "A good ratio may be to weight F1 by class based upon how manufacturer profits respond to missed opportunities or wasted resources. If we had the data to determine the exact ratio of these economic losses it would help us explain a better F1 ratio. However, given most of this is private information we will estimate this ratio.\n",
    "\n",
    "\n",
    "Thus, we applied weights to the F1 scores by class. These weigths are:</br>\n",
    "<br>\n",
    "<br>\n",
    "Class: unacc, acc, good, vgood\n",
    "<br>\n",
    "Weigths: [1.5,1.0,2.0,2.5]\n",
    "\n",
    "### Final Evaluation Metric:\n",
    "\n",
    "Thus, our final evaluation metric is an F1 score with classes: [unacc, acc, good, vgood] weighted by scaling factors of [1.5,1.0,2.0,2.5].\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "For our cross validation method we needed to find a data splitting method that will result in train sets that best mirror what manufacturers will have when they have this model in deployment. To do this we need to first understand \n",
    "\n",
    "<b><br>\n",
    "1) How manufacturers will use this model\n",
    "<br>\n",
    "2) What is the best cross validation method for that goal\n",
    "</b>\n",
    "\n",
    "### Manufacturers\n",
    "\n",
    "When in deployment the main objective for car manufacturers will be to use this dataset to find what features will make their car acceptable. Generally in a car market there are market leaders and other cars that are not as succesful. This is one reason why in our set the majority of cars are labeled as unacceptable. Manufacturers would like to have these leaders in their set to be able to see what the succesful cars are doing. This means that if we could include the top cars in every set we would most likely be better off. \n",
    "\n",
    "Moreover, many manufacturers have a niche of cars that they sell. For example, Jeep would most likly want to know what makes adventurous cars acceptable vs. what makes luxury cars acceptable. What this means is that manufacturers will find a subset of cars to add to their training set and then each manufacturer would use that set to train the model. This means that there may be a huge variance in sets that each manufacturer uses. What this means for us is that if we could subset the data by type of car we would be able to offer the manufacturers a better model. Our data set does not have this data, so we will have to approximate it. \n",
    "\n",
    "In conclusion, based on manufacturer needs, we will need to be able to create training sets that include top cars as much as possible, and we need to create training sets that do not all look the same. An ideal scenario would be to divide each set by type of car and competing cars, but because our dataset does not have this data, we will need to create sets with variance to match the variance in manufacturer needs. An additional need for our set is to reduce overfitting as much as possible (ubiquitous for ML models). \n",
    "\n",
    "### Method\n",
    "\n",
    "Given our goals, we narrowed our method down to a standard shuffle split. We were choosing between stratified k-fold and shuffle split and had to weigh their pros and cons in relation to our business case. \n",
    "\n",
    "First off, with stratified K-fold, it ensures that every data-point is used once, and it creates sets without overlap that are each microcausms of the full set. his method helps with reducing the overfitting of our model, and stratification helps take care of the issues our class imbalance can cause. This method however does not fare well when it comes to meeting the goals we set for our business case. Firstly, cross validation only allows us to use each point once. This does not match our need that the car market tends to have market leaders that should always be included. Secondly, we are making each set relativly similar in composition through stratification. This helps fight our large class imbalance, but doesn't account for the fact that manufacturers have varied needs and their may be variance is data set population by manufacturer. \n",
    "\n",
    "Given these shortcomings, we chose to use a standard shuffle split. Our dataset is large enough that we do not need to worry to much about creating radically odd training sets, but small enough that we can expect variance in our sets. It is the training set variance in this method which is pushing us to use it. As we mentioned above, car manufacturers will all have their own data population, and since we can't create sets to match each manufacturer, the best we can do is to create sets that have variance. Moreover, this method allows for reusing data points, so this method at least allows for the chance of top cars to be recycled in the sets.\n",
    "\n",
    "Therefore, we will be using a standard shuffle split (train_test_split) to create our training and testing sets. \n",
    "\n",
    "### Method Description\n",
    "\n",
    "For our data split, we will be using the simple built-in train_test_split, with a test_size of 0.1, or 10% of the data.\n",
    "As shown below, a stratified 10-fold cross validation gives us an accuracy around 70%, essentially the same as what we get through the simple shuffled split, perhaps slightly less accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 11 but corresponding boolean dimension is 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, print_progress)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;31m# compute gradient via backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             grads = self._get_gradient(As=As, Zs=Zs, Y_enc=Y_enc,\n\u001b[1;32m--> 242\u001b[1;33m                                               Ws=self.Ws)\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36m_get_gradient\u001b[1;34m(self, As, Zs, Y_enc, Ws)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'quadratic'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_quad_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'cross'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cross_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36m_quad_gradient\u001b[1;34m(self, As, Zs, Y_enc, Ws)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                     \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                     \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;31m#                 elif self.activation_method == 'silu':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;31m#                     temp = self._sigmoid(Zs[i])*((1-As[i]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 11 but corresponding boolean dimension is 10"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "accs = np.array([])\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "nn = NLayerPerceptron(**params)\n",
    "for train_index, test_index in skf.split(X, y_not_binary):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y_not_binary[train_index], y_not_binary[test_index]\n",
    "    nn.fit(X_train, y_train, print_progress=0)\n",
    "    yhat = nn.predict(X_test)\n",
    "    accs = np.append(accs, accuracy_score(y_test,yhat))\n",
    "    print('Test acc:',accuracy_score(y_test,yhat))\n",
    "print(np.mean(accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 11 but corresponding boolean dimension is 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, print_progress)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;31m# compute gradient via backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             grads = self._get_gradient(As=As, Zs=Zs, Y_enc=Y_enc,\n\u001b[1;32m--> 242\u001b[1;33m                                               Ws=self.Ws)\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36m_get_gradient\u001b[1;34m(self, As, Zs, Y_enc, Ws)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'quadratic'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_quad_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'cross'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cross_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36m_quad_gradient\u001b[1;34m(self, As, Zs, Y_enc, Ws)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                     \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                     \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;31m#                 elif self.activation_method == 'silu':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;31m#                     temp = self._sigmoid(Zs[i])*((1-As[i]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 11 but corresponding boolean dimension is 10"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "for iteration in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_not_binary, test_size=0.1, shuffle=True)\n",
    "    nn = NLayerPerceptron(**params)\n",
    "    nn.fit(X_train, y_train, print_progress=10)\n",
    "    yhat = nn.predict(X_test)\n",
    "    print('Test acc:',accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Perceptron Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example adapted from https://github.com/rasbt/python-machine-learning-book/blob/master/code/ch12/ch12.ipynb\n",
    "# Original Author: Sebastian Raschka\n",
    "\n",
    "# This is the optional book we use in the course, excellent intuitions and straightforward programming examples\n",
    "# please note, however, that this code has been manipulated to reflect our assumptions and notation.\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# start with a simple base classifier, which can't be fit or predicted\n",
    "# it only has internal classes to be used by classes that will subclass it\n",
    "class NLayerPerceptron(object):\n",
    "    def __init__(self, n_hidden=30, n_hidden_layers=2,\n",
    "                 C=0.0, epochs=500, eta=0.001, random_state=None, \n",
    "                 cost_function='quadratic', activation_method='sigmoid'):\n",
    "        np.random.seed(random_state)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.l2_C = C\n",
    "        self.epochs = epochs\n",
    "        self.eta = eta\n",
    "        self.cost_function = cost_function\n",
    "        self.activation_method = activation_method\n",
    "        \n",
    "    @staticmethod\n",
    "    def _encode_labels(y):\n",
    "        \"\"\"Encode labels into one-hot representation\"\"\"\n",
    "        onehot = pd.get_dummies(y).values.T\n",
    "            \n",
    "        return onehot\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights with small random numbers.\"\"\"\n",
    "        Ws = [None]*self.n_hidden_layers\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            #if i!=self.n_hidden_layers-1:\n",
    "            if i==0:\n",
    "                Wi_num_elems = (self.n_features_ + 1)*self.n_hidden\n",
    "                Wi = np.random.uniform(-1.0, 1.0,size=Wi_num_elems)\n",
    "                Wi = Wi.reshape(self.n_hidden, self.n_features_ + 1)\n",
    "            elif i==self.n_hidden_layers-1:\n",
    "                Wi_num_elems = (self.n_hidden + 1)*self.n_output_\n",
    "                Wi = np.random.uniform(-1.0, 1.0,size=Wi_num_elems)\n",
    "                Wi = Wi.reshape(self.n_output_, self.n_hidden + 1)\n",
    "            else:\n",
    "                Wi_num_elems = (self.n_hidden + 1)*self.n_hidden\n",
    "                Wi = np.random.uniform(-1.0, 1.0,size=Wi_num_elems)\n",
    "                Wi = Wi.reshape(self.n_hidden, self.n_hidden + 1)\n",
    "            \n",
    "            Ws[i] = Wi\n",
    "        return Ws\n",
    "    \n",
    "    #used for relu\n",
    "    def _sigmoid(self,z):\n",
    "        return expit(z)\n",
    "    \n",
    "    def _activation(self,z):\n",
    "        if self.activation_method=='sigmoid':\n",
    "            return expit(z)\n",
    "        elif self.activation_method=='linear':\n",
    "            return z\n",
    "        elif self.activation_method=='relu':\n",
    "            return np.maximum(0,z.copy())\n",
    "        elif self.activation_method=='silu':\n",
    "            return z*expit(z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias_unit(X, how='column'):\n",
    "        \"\"\"Add bias unit (column or row of 1s) to array at index 0\"\"\"\n",
    "        if how == 'column':\n",
    "            ones = np.ones((X.shape[0], 1))\n",
    "            X_new = np.hstack((ones, X))\n",
    "        elif how == 'row':\n",
    "            ones = np.ones((1, X.shape[1]))\n",
    "            X_new = np.vstack((ones, X))\n",
    "        return X_new\n",
    "    \n",
    "    @staticmethod\n",
    "    def _L2_reg(lambda_, Ws):\n",
    "        \"\"\"Compute L2-regularization cost\"\"\"\n",
    "        # only compute for non-bias terms\n",
    "        meansquaresum = 0\n",
    "        for Wi in Ws:\n",
    "            meansquaresum += np.mean(Wi[:, 1:]**2)\n",
    "        return (lambda_/2.0) * np.sqrt(meansquaresum)\n",
    "    \n",
    "    def _cost(self,A3,Y_enc,Ws):\n",
    "        if self.cost_function=='quadratic':\n",
    "            return self._quad_cost(A3,Y_enc,Ws)\n",
    "        elif self.cost_function=='cross':\n",
    "            return self._cross_cost(A3,Y_enc,Ws)\n",
    "    \n",
    "    def _quad_cost(self,A3,Y_enc,Ws):\n",
    "        '''Get the objective function value'''\n",
    "        cost = np.mean((Y_enc-A3)**2)\n",
    "        L2_term = self._L2_reg(self.l2_C, Ws)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _cross_cost(self,A3,Y_enc,Ws):\n",
    "        '''Get the objective function value'''\n",
    "        cost = -np.mean(np.nan_to_num((Y_enc*np.log(A3)+(1-Y_enc)*np.log(1-A3))))\n",
    "        L2_term = self._L2_reg(self.l2_C, Ws)\n",
    "        return cost + L2_term\n",
    "    \n",
    "    def _feedforward(self, X, Ws):\n",
    "        \"\"\"Compute feedforward step\n",
    "        \"\"\"\n",
    "        As = [None]*(self.n_hidden_layers+1)\n",
    "        Zs = [None]*self.n_hidden_layers\n",
    "        for i in range(len(As)):\n",
    "            if i==0:\n",
    "                As[0] = self._add_bias_unit(X, how='column')\n",
    "                As[0] = As[0].T\n",
    "            else:\n",
    "                Zs[i-1] = Ws[i-1] @ As[i-1]\n",
    "                if i!=len(As)-1:\n",
    "                    As[i] = self._activation(Zs[i-1])\n",
    "                    As[i] = self._add_bias_unit(As[i], how='row')\n",
    "                else:\n",
    "                    As[i] = self._sigmoid(Zs[i-1])\n",
    "\n",
    "        return As, Zs\n",
    "    \n",
    "    def _get_gradient(self, As, Zs, Y_enc, Ws):\n",
    "        if self.cost_function=='quadratic':\n",
    "            return self._quad_gradient(As,Zs,Y_enc,Ws)\n",
    "        elif self.cost_function=='cross':\n",
    "            return self._cross_gradient(As,Zs,Y_enc,Ws)\n",
    "        \n",
    "    \n",
    "    def _quad_gradient(self, As, Zs, Y_enc, Ws):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        # vectorized backpropagation\n",
    "        Vs = [None]*self.n_hidden_layers\n",
    "        grads = [None]*self.n_hidden_layers\n",
    "        for i in range(self.n_hidden_layers,0,-1):\n",
    "            if i==self.n_hidden_layers:\n",
    "                Vs[i-1] = -2*(Y_enc-As[i])*As[i]*(1-As[i])\n",
    "                grads[i-1] = Vs[i-1] @ As[i-1].T\n",
    "            elif self.n_hidden_layers > 2 and i <= self.n_hidden_layers - 2 and i > 0:\n",
    "                if self.activation_method == 'sigmoid':\n",
    "                    Vs[i-1] = As[i]*(1-As[i])*(Ws[i].T @ Vs[i][1:,:])\n",
    "                elif self.activation_method == 'linear':\n",
    "                    Vs[i-1] = (Ws[i].T @ Vs[i][1:,:])\n",
    "                elif self.activation_method == 'relu':\n",
    "                    Vs[i-1] = Ws[i].T @ Vs[i][1:,:]\n",
    "                    Vs[i-1][Zs[i-1]<=0] = 0 \n",
    "#                 elif self.activation_method == 'silu':\n",
    "#                     temp = self._sigmoid(Zs[i])*((1-As[i]))\n",
    "#                     temp2= (As[i] + temp)\n",
    "#                     Vs[i-1] = Ws[i].T @ Vs[i][1:,:] * temp2\n",
    "                    \n",
    "                grads[i-1] = Vs[i-1][1:,:] @ As[i-1].T\n",
    "            else:\n",
    "                if self.activation_method == 'sigmoid':\n",
    "                    Vs[i-1] = As[i]*(1-As[i])*(Ws[i].T @ Vs[i])\n",
    "                elif self.activation_method == 'linear':\n",
    "                    Vs[i-1] = (Ws[i].T @ Vs[i])\n",
    "                elif self.activation_method == 'relu':\n",
    "                    Vs[i-1] = Ws[i].T @ Vs[i]\n",
    "                    Vs[i-1][Zs[i-1]<=0] = 0 \n",
    "#                 elif self.activation_method == 'silu':\n",
    "#                     temp = self._sigmoid(Zs[i])*((1-As[i]))\n",
    "#                     temp2 = (As[i] + temp)\n",
    "#                     Vs[i-1] = Ws[i].T @ Vs[i] * temp2\n",
    "                grads[i-1] = Vs[i-1][1:,:] @ As[i-1].T\n",
    "        \n",
    "        return grads\n",
    "\n",
    "    \n",
    "    def _cross_gradient(self, As, Zs, Y_enc, Ws):\n",
    "        \"\"\" Compute gradient step using backpropagation.\n",
    "        \"\"\"\n",
    "        \n",
    "        Vs = [None]*self.n_hidden_layers\n",
    "        grads = [None]*self.n_hidden_layers\n",
    "        for i in range(self.n_hidden_layers,0,-1):\n",
    "            if i==self.n_hidden_layers:\n",
    "                Vs[i-1] = As[i]-Y_enc\n",
    "                grads[i-1] = Vs[i-1] @ As[i-1].T\n",
    "            elif self.n_hidden_layers > 2 and i <= self.n_hidden_layers - 2 and i > 0:\n",
    "                if self.activation_method == 'sigmoid':\n",
    "                    Vs[i-1] = As[i]*(1-As[i])*(Ws[i].T @ Vs[i][1:,:])\n",
    "                elif self.activation_method == 'linear':\n",
    "                    Vs[i-1] = (Ws[i].T @ Vs[i][1:,:])\n",
    "                elif self.activation_method == 'relu':\n",
    "                    Vs[i-1] = Ws[i].T @ Vs[i][1:,:]\n",
    "                    Vs[i-1][Zs[i-1]<=0] = 0 \n",
    "#                 elif self.activation_method == 'silu':\n",
    "#                     Vs[i-1] = Ws[i].T @ Vs[i][1:,:] * (As[i] + (1-As[i])*self._sigmoid(Zs[i]))\n",
    "                grads[i-1] = Vs[i-1][1:,:] @ As[i-1].T\n",
    "            else:\n",
    "                if self.activation_method == 'sigmoid':\n",
    "                    Vs[i-1] = As[i]*(1-As[i])*(Ws[i].T @ Vs[i])\n",
    "                elif self.activation_method == 'linear':\n",
    "                    Vs[i-1] = (Ws[i].T @ Vs[i])\n",
    "                elif self.activation_method == 'relu':\n",
    "                    Vs[i-1] = Ws[i].T @ Vs[i]\n",
    "                    Vs[i-1][Zs[i-1]<=0] = 0 \n",
    "#                 elif self.activation_method == 'silu':\n",
    "#                     Vs[i-1] = Ws[i].T @ Vs[i] * (As[i] + (1-As[i])*self._sigmoid(Zs[i]))\n",
    "                grads[i-1] = Vs[i-1][1:,:] @ As[i-1].T\n",
    "        \n",
    "        return grads\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict class labels\"\"\"\n",
    "        As,_ = self._feedforward(X, self.Ws)\n",
    "        y_pred = np.argmax(As[-1], axis=0)\n",
    "        return y_pred\n",
    "\n",
    "    def fit(self, X, y, print_progress=False):\n",
    "        \"\"\" Learn weights from training data.\"\"\"\n",
    "        \n",
    "        X_data, y_data = X.copy(), y.copy()\n",
    "        Y_enc = self._encode_labels(y)\n",
    "        \n",
    "        # init weights and setup matrices\n",
    "        self.n_features_ = X_data.shape[1]\n",
    "        self.n_output_ = Y_enc.shape[0]\n",
    "        self.Ws = self._initialize_weights()\n",
    "        #gradients holds the gradients at each layer and iteration, but does not correctly separate them for some reason\n",
    "        gradients = [[]]*self.n_hidden_layers\n",
    "        self.cost_ = []\n",
    "        for i in range(self.epochs):\n",
    "\n",
    "            if print_progress>0 and (i+1)%print_progress==0:\n",
    "                sys.stderr.write('\\rEpoch: %d/%d' % (i+1, self.epochs))\n",
    "                sys.stderr.flush()\n",
    "\n",
    "            # feedforward all instances\n",
    "            As, Zs = self._feedforward(X_data,self.Ws)\n",
    "            \n",
    "            cost = self._cost(As[-1],Y_enc,self.Ws)\n",
    "            self.cost_.append(cost)\n",
    "\n",
    "            # compute gradient via backpropagation\n",
    "            grads = self._get_gradient(As=As, Zs=Zs, Y_enc=Y_enc,\n",
    "                                              Ws=self.Ws)\n",
    "            \n",
    "            for j in range(len(self.Ws)):\n",
    "                self.Ws[j] -= self.eta * grads[j]\n",
    "                #append to gradients array (does not correctly split, so needs extra work )\n",
    "                gradients[j].append(np.mean(grads[j]))\n",
    "        self.gradients_=[]\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            self.gradients_.append(gradients[0][i:][::self.n_hidden_layers])\n",
    "                \n",
    "            \n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(n_hidden=10, \n",
    "              n_hidden_layers=4,\n",
    "              C=0.1, # tradeoff L2 regularizer\n",
    "              epochs=500, # iterations\n",
    "              eta=0.001,  # learning rate\n",
    "              random_state=1,\n",
    "              cost_function='quadratic',\n",
    "              activation_method='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 11 but corresponding boolean dimension is 10",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, print_progress)\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[1;31m# compute gradient via backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             grads = self._get_gradient(As=As, Zs=Zs, Y_enc=Y_enc,\n\u001b[1;32m--> 242\u001b[1;33m                                               Ws=self.Ws)\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36m_get_gradient\u001b[1;34m(self, As, Zs, Y_enc, Ws)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'quadratic'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_quad_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcost_function\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'cross'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cross_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_enc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-7e4f9604d64a>\u001b[0m in \u001b[0;36m_quad_gradient\u001b[1;34m(self, As, Zs, Y_enc, Ws)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation_method\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'relu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                     \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m                     \u001b[0mVs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mZs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;31m#                 elif self.activation_method == 'silu':\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;31m#                     temp = self._sigmoid(Zs[i])*((1-As[i]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 11 but corresponding boolean dimension is 10"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nn = NLayerPerceptron(**params)\n",
    "nn.fit(X_train, y_train, print_progress=10)\n",
    "yhat = nn.predict(X_test)\n",
    "print('Test acc:',accuracy_score(y_test,yhat))\n",
    "sample_weights = [1.5,1.0,2.0,2.5]\n",
    "weights = [sample_weights[x] for x in y_test ]\n",
    "print('F1 acc: ', f1_score(y_test,yhat,average='weighted', sample_weight=weights) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tune the hyper-parameters of cost function, activation method and number of layers, we used our evaluation criteria of the F1 score with sample weights of [1.5,1.0,2.0,2.5] for each of the classes and the train_test_split that we found to do a better job than a Stratified KFold. The advantage of using a simple train_test_split is that it drives the number of models we need to build down by a factor of how many folds we decide to have in our KFold. The other parameters, such as neurons to train for each layer, C, number of iterations and learning rate were kept constant across this tuning. It is important to note that they could also have an effect on our performance, but due to the high number of models that needed to be trained already and the lack of high-end equipment, we decided to keep those constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-373fcf9ac5e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mf1score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cost:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"| Activation:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"| Layers:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"| F1 Score:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"| Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f1_score' is not defined"
     ]
    }
   ],
   "source": [
    "cost_functions = ['quadratic', 'cross']\n",
    "activation_functions = ['sigmoid','linear', 'relu']\n",
    "num_hidden_layers= [x for x in range(2,8)]\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "results = []\n",
    "for cost in cost_functions:\n",
    "    for activation in activation_functions:\n",
    "        for num in num_hidden_layers:\n",
    "            params = dict(n_hidden=30, \n",
    "              n_hidden_layers=num,\n",
    "              C=0.1, # tradeoff L2 regularizer\n",
    "              epochs=500, # iterations\n",
    "              eta=0.001,  # learning rate\n",
    "              random_state=1,\n",
    "              cost_function=cost,\n",
    "              activation_method=activation)\n",
    "            nn = NLayerPerceptron(**params)\n",
    "            nn.fit(X_train, y_train)\n",
    "            yhat = nn.predict(X_test)\n",
    "            f1score = f1_score(y_test,yhat,average='weighted', sample_weight=weights)\n",
    "            acc = accuracy_score(y_test,yhat)\n",
    "            print(\"Cost:\", cost, \"| Activation:\", activation, \"| Layers:\", num, \"| F1 Score:\", f1score, \"| Accuracy:\", acc )\n",
    "            results.append({'cost':cost, 'activation':activation, 'layers':num, 'f1_score':f1score, 'accuracy':acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14f81029b38>"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f83884e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "df = pd.DataFrame(results)\n",
    "df['f1_score']= df['f1_score'].astype(np.float64)\n",
    "df['cost_activation']=df['cost'] + \" \"+ df['activation'] \n",
    "sns.swarmplot(data=df, y='f1_score',x='layers', hue='cost_activation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the graph above that the sigmoid activation function performs significantly better than all other activation functions for our dataset. We can also notice that adding more hidden layers does not improve our performance. In general the cross entropy cost function yields better results for a sigmoid activation function ,while the same is not necessarily true for ReLu at lower number of layers. As the number of layers grows, the accuracy of ReLu or Linear activation does not seem to be affected. Since the functions are very similar for their values over 0, we can assume that the majority of values generated do not go under 0 for more than 3 layers, since the performance is nearly identical for both cost functions with those activation methods. The best model to use out of the 36 tested appears to be between Quadratic Sigmoid with 3 layers and Cross Sigmoid with 3 layers. Due to the fact that for all other layers the sigmoid activation performs much better with a cross entropy cost function, compared to the quadratic cost function, we can conclude it is better fit for our data. Thus, we can conclude that a Cross Sigmoid with 3 layers is the best combination of hyper-parameters to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient magnitude visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = dict(n_hidden=30, \n",
    "              n_hidden_layers=3,\n",
    "              C=0.1, # tradeoff L2 regularizer\n",
    "              epochs=500, # iterations\n",
    "              eta=0.001,  # learning rate\n",
    "              random_state=1,\n",
    "              cost_function='cross',\n",
    "              activation_method='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 500/500"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.956647398844\n",
      "F1 acc:  0.964770093822\n",
      "Wall time: 1.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "nn = NLayerPerceptron(**params)\n",
    "nn.fit(X_train, y_train, print_progress=10)\n",
    "yhat = nn.predict(X_test)\n",
    "print('Test acc:',accuracy_score(y_test,yhat))\n",
    "sample_weights = [1.5,1.0,2.0,2.5]\n",
    "weights = [sample_weights[x] for x in y_test ]\n",
    "print('F1 acc: ', f1_score(y_test,yhat,average='weighted', sample_weight=weights) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEFCAYAAAABjYvXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14f80b03ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(1,1,1)\n",
    "for i in range(0,params['n_hidden_layers']):\n",
    "#     print(nn.gradients_[i])\n",
    "    plt.plot(np.abs(nn.gradients_[i]), label='w' + str(i) )\n",
    "plt.legend()\n",
    "plt.ylabel('Average gradient magnitude')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot shows the average magnitutde of the gradients against the training iteration for our best performing model using 3 hidden layers, the cross entropy cost function and the sigmoid activation function. With these hyper-parameters, we can see that the gradients in the outer layer (w2) converge very fast to 0, and we can see that after the 100th iteration, the gradients in all 3 layers are very close to one another in terms of mean value. The gradients seem to stay fairly consistent and the plot does not contain any value spikes."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
