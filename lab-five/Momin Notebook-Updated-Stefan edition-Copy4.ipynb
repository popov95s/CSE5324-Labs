{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input, Dropout\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45466 items in unprocessed dataframe\n",
      "4572 classes for production_companies\n",
      "1441 classes for genres\n",
      "23298 items in processed dataframe\n",
      "\n",
      "['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', 'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', 'runtime_category', 'runtime_category_int', 'above_average_vote', 'genres_int']\n",
      "budget                      float64\n",
      "genres                       object\n",
      "id                            int64\n",
      "popularity                  float64\n",
      "production_companies         object\n",
      "revenue                     float64\n",
      "runtime                     float64\n",
      "title                        object\n",
      "vote_average                float64\n",
      "vote_count                  float64\n",
      "made_in_us                     bool\n",
      "production_companies_int      int64\n",
      "runtime_category             object\n",
      "runtime_category_int          int64\n",
      "above_average_vote             bool\n",
      "genres_int                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "\n",
    "df = pd.read_csv('movies_metadata.csv')\n",
    "\n",
    "print(len(df),'items in unprocessed dataframe')\n",
    "df = df[df.status=='Released']\n",
    "df = df[df.original_language=='en']\n",
    "df = df.drop(columns=['adult','belongs_to_collection','homepage','imdb_id','original_language','overview',\n",
    "                     'poster_path','release_date','spoken_languages',\n",
    "                     'status','tagline','video','original_title'])\n",
    "\n",
    "def contains_us(row):\n",
    "    return 'US' in row\n",
    "\n",
    "def get_genres(row):\n",
    "    s = re.findall(\"'name': '(.*?)'\",row)\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_prod_companies(row):\n",
    "\n",
    "    s = re.findall(\"{'name': '(.*?)'\",row)\n",
    "    '''\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "    '''\n",
    "    if len(s) > 1:\n",
    "        return 'Collaboration'\n",
    "    elif len(s) == 1:\n",
    "        return s[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def discretize_runtime(row):\n",
    "    if row < 40:\n",
    "        return 'Short Film'\n",
    "    elif row < 80:\n",
    "        return 'Less than Feature Film'\n",
    "    elif row < 130:\n",
    "        return 'Below Average Feature Film'\n",
    "    else:\n",
    "        return 'Above Average Feature Film'\n",
    "\n",
    "df['made_in_us'] = df.production_countries.apply(contains_us)\n",
    "df = df.drop(columns=['production_countries'])\n",
    "df['production_companies'] = df.production_companies.apply(get_prod_companies)\n",
    "\n",
    "df['genres'] = df.genres.apply(get_genres)\n",
    "\n",
    "df = df.dropna()\n",
    "enc = LabelEncoder()\n",
    "df['production_companies_int'] = enc.fit_transform(df.production_companies)\n",
    "\n",
    "df['runtime_category'] = df.runtime.apply(discretize_runtime)\n",
    "df['runtime_category_int'] = enc.fit_transform(df.runtime_category)\n",
    "\n",
    "df['budget'] = df.budget.apply(float)\n",
    "df['popularity'] = df.popularity.apply(float)\n",
    "df['id'] = df.id.apply(int)\n",
    "\n",
    "\n",
    "avg = df.vote_average.mean()\n",
    "df['above_average_vote'] = df.vote_average > avg\n",
    "for x in df['genres']:\n",
    "    x.sort()\n",
    "df['genres'] = df['genres'].apply(\"_\".join)\n",
    "\n",
    "df['genres_int'] = enc.fit_transform(df.genres)\n",
    "print(max(df.production_companies_int)+1,'classes for production_companies')\n",
    "print(max(df.genres_int)+1,'classes for genres')\n",
    "\n",
    "print(len(df),'items in processed dataframe\\n')\n",
    "print(list(df))\n",
    "print(df.dtypes)\n",
    "categorical_headers_ints = ['production_companies_int','genres_int','runtime_category_int']\n",
    "numeric_headers = ['budget','popularity','revenue','runtime','vote_average','vote_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     5.1\n",
      "0.50     6.0\n",
      "0.75     6.7\n",
      "0.90     7.3\n",
      "0.99     8.3\n",
      "1.00    10.0\n",
      "Name: vote_average, dtype: float64\n",
      "22449\n"
     ]
    }
   ],
   "source": [
    "print(df.vote_average.quantile([.25,.5,.75,.9,.99,1]))\n",
    "print(len(df[df.vote_count>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we work with the Kaggle Movies Dataset. This dataset contains metadata on 45,466 different movies released on or before July 2017. The dataset includes information about each movie such as the budget, the genres, the runtime, the revenue, and popularity scores based on data from the research group GroupLens.\n",
    "\n",
    "In preprocessing the data, we first remove the features we will not be using for classification. Then, we create a few new columns.\n",
    "\n",
    "First, we create a column called made_in_us. This is a modification of the original column production_countries, which contains a list of the countries each movie was produced in. Since there were a large number of such countries, we chose to represent that column as a binary value of if this movie was produced in the United States or in a different country.\n",
    "\n",
    "Next, we create a column called production_companies_int. This is a modification of the original column production_companies, which contains a list of the production companies that created each movie. We take this list of production companies and represent collaborations between multiple production companies as the class \"collaboration\" - we do this because there is a large number of combinations otherwise. Then, we encode the production company as an integer using sklearn's LabelEncoder class.\n",
    "\n",
    "Next, we create a column called genres_int. This is a modification of the original column genres, which contains a list of the genres each movie belongs to. We take this list of genres and encode it using sklearn's LabelEncoder class. In the case that there are multiple genres for a movie, such as a romantic comedy, we represent this combination as its own class, unlike with the production companies. The rationale behind this choice is that there is a much larger number of production companies than genres - we can represent all combinations of genres with 2,970 classes. \n",
    "\n",
    "Next, we create a column called above_average_vote. This is a modification of the original column average_vote, which is the average of all votes given to this movie on a scale of 0-10. This column is the target column; we will try to predict if a movie can score above average.\n",
    "\n",
    "Finally, we create a column called runtime_category_int. This is a modification of the original column runtime, which is the runtime of the movie in minutes. We discretize the runtime into 4 categories: short film, less than feature film, below average feature film, and above average feature film. We use the following cutoffs: a short film is less than 40 minutes, a movie that is less than a feature film is less than 80 minutes, a feature film below average is less than 130 minutes, and a feature film above average is longer than 130 minutes. \n",
    "\n",
    "We derive the runtime of a short film from the rules the Oscar awards establish for the short film category (http://www.oscars.org/sites/oscars/files/90aa_short_films.pdf). We derive the length of a feature film from the Screen Actor's Guild (http://www.sagaftra.org/files/sag/Low_Budget_Ageement_1_5.pdf). We derive the average length of a feature film from a Business Insider study (http://www.businessinsider.com/movies-are-getting-longer-2013-1).\n",
    "\n",
    "We choose to represent the runtime category as categorical data and not ordinal data. The reason we represent runtime categorically instead of ordinally is because different categories of film are not necessarily similar to one another. For example, below average feature films are closer in length to short films than above average feature films are. However, since short films are often not shown in movie theatres, it is likely that there is an entirely different audience for short films than there is for below average length feature films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "\n",
    "df_features = ['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', \n",
    "               'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', \n",
    "               'runtime_category', 'runtime_category_int', 'genres_int']\n",
    "df_class = ['above_average_vote']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    train_list.append(train_index)\n",
    "    test_list.append(test_index)\n",
    "\n",
    "\n",
    "df_train = deepcopy(df.iloc[train_list[0]])\n",
    "df_test = deepcopy(df.iloc[test_list[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODING ONLY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 4572 7542 7546]\n",
      "(20967, 7202)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# now let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "y_train = df_train[df_class].values.astype(np.int)\n",
    "y_test = df_test[df_class].values.astype(np.int)\n",
    "\n",
    "# the ohe instance will help us to organize our encoded matrix\n",
    "print(ohe.feature_indices_)\n",
    "print(X_train_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_ohe (InputLayer)              (None, 7202)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X_Numeric (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ohe_1 (Dense)                   (None, 10)           72030       X_ohe[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "num_1 (Dense)                   (None, 10)           70          X_Numeric[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 20)           0           ohe_1[0][0]                      \n",
      "                                                                 num_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 1)            21          concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 72,121\n",
      "Trainable params: 72,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combine the features with two branches\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# and save off the numeric features\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num = df_test[numeric_headers].values\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "# create dense input branch for numeric\n",
    "inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "x = concatenate([xSparse, xDense], name='concat')\n",
    "predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and Dense layers\n",
    "model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to define precision metric\n",
    "import keras.backend as K\n",
    "#precision metric gotten from previous release of keras\n",
    "#https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  907]\n",
      " [   1 1422]] 0.6105624731644482\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy', precision])\n",
    "model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "          y_train, \n",
    "          epochs=5, \n",
    "          batch_size=50, \n",
    "          verbose=0)\n",
    "\n",
    "yhat = model.predict([X_test_ohe,\n",
    "                      X_test_num]) # each branch has an input\n",
    "\n",
    "yhat = np.round(yhat)\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.precision_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide and Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      genres            runtime_category\n",
      "2346                  Horror  Below Average Feature Film\n",
      "2347                  Horror  Below Average Feature Film\n",
      "2350                  Comedy  Below Average Feature Film\n",
      "2352  Horror_Science Fiction  Below Average Feature Film\n",
      "2354  Drama_Thriller_Mystery  Above Average Feature Film\n",
      "                      genres  made_in_us\n",
      "2346                  Horror        True\n",
      "2347                  Horror        True\n",
      "2350                  Comedy        True\n",
      "2352  Horror_Science Fiction        True\n",
      "2354  Drama_Thriller_Mystery       False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                 ['genres','made_in_us']]\n",
    "\n",
    "#'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "# we need to create separate lists for each branch\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_wide_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # create crossed labels\n",
    "    print (df_train[cols].head())\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "    \n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_wide_branch_outputs.append(x)\n",
    "    \n",
    "# merge the branches together\n",
    "wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "# reset this input branch\n",
    "all_deep_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_headers_ints:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values )\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name=col+'_embed')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_deep_branch_outputs.append(x)\n",
    "    \n",
    "# also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                        sparse=False,\n",
    "                        name='numeric_data'))\n",
    "\n",
    "x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "#ohe = OneHotEncoder()\n",
    "#X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "#X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "#inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "#sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "# merge the deep branches together\n",
    "deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=10,activation='relu', name='deep3')(drop_out_deep)\n",
    "    \n",
    "final_branch = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "final_branch = Dense(units=1,activation='sigmoid',name='combined')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2796 - acc: 0.5841 - precision: 0.6128 - val_loss: 0.3478 - val_acc: 0.5311 - val_precision: 0.6051\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2202 - acc: 0.6787 - precision: 0.6827 - val_loss: 0.2475 - val_acc: 0.6710 - val_precision: 0.6343\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1740 - acc: 0.7584 - precision: 0.7503 - val_loss: 0.2414 - val_acc: 0.6941 - val_precision: 0.6433\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1474 - acc: 0.8344 - precision: 0.8233 - val_loss: 0.2408 - val_acc: 0.6958 - val_precision: 0.6438\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.1304 - acc: 0.8764 - precision: 0.8735 - val_loss: 0.2436 - val_acc: 0.6864 - val_precision: 0.6382\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1206 - acc: 0.8938 - precision: 0.8893 - val_loss: 0.2351 - val_acc: 0.7130 - val_precision: 0.6540\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1142 - acc: 0.9007 - precision: 0.8942 - val_loss: 0.2367 - val_acc: 0.7130 - val_precision: 0.6521\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1066 - acc: 0.9104 - precision: 0.9045 - val_loss: 0.2319 - val_acc: 0.7113 - val_precision: 0.6511\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.0971 - acc: 0.9200 - precision: 0.9058 - val_loss: 0.2333 - val_acc: 0.7130 - val_precision: 0.6515\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.0925 - acc: 0.9229 - precision: 0.9057 - val_loss: 0.2307 - val_acc: 0.7199 - val_precision: 0.6555\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy', precision])\n",
    "initial_weights = model.get_weights()\n",
    "# lets also add the history variable to see how we are doing\n",
    "# and lets add a validation set to keep track of our progress\n",
    "history = model.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 293  615]\n",
      " [  38 1385]] 0.6925\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat), mt.precision_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epochs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2322403e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['precision'])\n",
    "\n",
    "plt.ylabel('Precision %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, we create cross-product features for the wide part of our wide-and-deep network. We cross the values for genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "\n",
    "We decide to cross the values for genres_int and runtime_category_int because films of different genres often have different lengths. For example, action movies have an average runtime of 100.46 minutes, whereas animation movies have an average runtime of 61.04 minutes. Thus, we speculate that a long animation movie will have a different reaction than a long action movie.\n",
    "\n",
    "Next, we cross the values for genres_int and made_in_us int. We base this feature cross on the idea that different countries may prefer different genres of movie. This hypothesis is supported by independent research from the New York Film Academy (https://www.nyfa.edu/student-resources/12-of-the-most-popular-movie-genres-by-country/) and the American Film Market & Conferences association (http://americanfilmmarket.com/relative-popularity-genres-around-world/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chosen task is a binary classification task: can we predict if a movie will score above or below average when rated by users on a scale of 0-10? We found in our data set that the average of the ~22,000 movies reviewed is a 6.0/10; therefore, a movie that scores above 6.0 is above average, any a movie scoring 6.0 or less is not.\n",
    "\n",
    "The business case for our prediction task is a movie studio trying to determine if their next movie will score above average or not. We imagine that a movie studio would come to us for our analysis after defining the basic criteria for their movie, such as genre, budget, and approximate runtime. At this point in the production cycle, the firm has not yet invested large amounts of time or money into creating the movie outline. Thus, the movie studio would much rather us reject a good idea than accept a bad idea; a rejected good idea is a waste of the small amount of time put into creating a movie outline, but an accepted bad idea will waste future resources as well as the outline time.\n",
    "\n",
    "With this use case in mind, we advance precision as our chosen evaluation criteria. Precision, mathematically defined as tp/(tp+fp), is a measure of what percentage of named positives are true positives. In our use case, a precision score of 30% means that, of the movies we said would do better than average, only 30% actually did better than average.\n",
    "\n",
    "The movie studio would be interested in a high-precision system because this system is good at telling if a movie will be above average. A 90% precision score means that 9 out of 10 movies that we say will succeed do in fact succeed; this goves the movie studio an idea of how likely it is that their movie is a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will use a 10-fold stratified cross-validation approach for splitting our data into training and testing sets. The reason we use cross-validation instead of shuffle-split is that we worry we do not have enough data. After pre-processing, we are left with ~22,000 movies. This is not an entirely small dataset; however, the feature space is quite large. For example, the movie genre alone can take on 2,970 different values, and the production company 4,572 values. We use 10-folds so that 90% of our data comprises the training set in each fold; this will ensure to the best of our ability that we have enough data.\n",
    "\n",
    "The reason we use stratified cross-validation is to preserve the class distributions seen in the data; if one class of a feature occurs 10% of the time in the data, it will occur 10% of the time in the training data and 10% of the time in the testing data. We use stratified cross-validation because our data represent the real-world distribution. When applied to real movies, it will also be true that there is large class imbalance in certain features; it is unlikely that in the future a dramatically different percentage of the market will be dominated by Animated-Romantic-Action-Adult films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.3385 - acc: 0.5880 - precision: 0.6663 - val_loss: 0.4772 - val_acc: 0.4753 - val_precision: 0.5996\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2901 - acc: 0.6673 - precision: 0.7306 - val_loss: 0.4587 - val_acc: 0.5187 - val_precision: 0.6425\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2611 - acc: 0.7254 - precision: 0.7902 - val_loss: 0.4566 - val_acc: 0.5204 - val_precision: 0.6423\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2461 - acc: 0.7521 - precision: 0.8226 - val_loss: 0.4534 - val_acc: 0.5298 - val_precision: 0.6494\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2325 - acc: 0.7696 - precision: 0.8374 - val_loss: 0.4589 - val_acc: 0.5225 - val_precision: 0.6448\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2303 - acc: 0.7753 - precision: 0.8541 - val_loss: 0.4527 - val_acc: 0.5345 - val_precision: 0.6548\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2211 - acc: 0.7847 - precision: 0.8612 - val_loss: 0.4329 - val_acc: 0.5521 - val_precision: 0.6453\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1634 - acc: 0.8436 - precision: 0.8576 - val_loss: 0.2625 - val_acc: 0.7242 - val_precision: 0.6587\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.1367 - acc: 0.8721 - precision: 0.8614 - val_loss: 0.2622 - val_acc: 0.7233 - val_precision: 0.6583\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1370 - acc: 0.8713 - precision: 0.8692 - val_loss: 0.2612 - val_acc: 0.7267 - val_precision: 0.6590\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.2843 - acc: 0.6352 - precision: 0.6586 - val_loss: 0.2758 - val_acc: 0.6276 - val_precision: 0.6107\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2316 - acc: 0.7145 - precision: 0.7116 - val_loss: 0.2535 - val_acc: 0.7134 - val_precision: 0.6162\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2348 - acc: 0.7480 - precision: 0.7708 - val_loss: 0.4527 - val_acc: 0.5062 - val_precision: 0.6180\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2697 - acc: 0.7327 - precision: 0.8122 - val_loss: 0.4463 - val_acc: 0.5242 - val_precision: 0.6189\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2544 - acc: 0.7565 - precision: 0.8329 - val_loss: 0.4416 - val_acc: 0.5298 - val_precision: 0.6203\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2418 - acc: 0.7697 - precision: 0.8412 - val_loss: 0.4391 - val_acc: 0.5260 - val_precision: 0.6180\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2182 - acc: 0.7930 - precision: 0.8534 - val_loss: 0.4365 - val_acc: 0.5332 - val_precision: 0.6202\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2212 - acc: 0.7896 - precision: 0.8494 - val_loss: 0.4319 - val_acc: 0.5375 - val_precision: 0.6210\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2138 - acc: 0.7981 - precision: 0.8486 - val_loss: 0.4315 - val_acc: 0.5350 - val_precision: 0.6208\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2081 - acc: 0.8035 - precision: 0.8555 - val_loss: 0.4290 - val_acc: 0.5367 - val_precision: 0.6187\n",
      "Testing on 3 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2820 - acc: 0.6500 - precision: 0.6700 - val_loss: 0.2724 - val_acc: 0.6697 - val_precision: 0.6111\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2327 - acc: 0.7046 - precision: 0.7075 - val_loss: 0.2723 - val_acc: 0.6628 - val_precision: 0.6114\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2131 - acc: 0.7469 - precision: 0.7441 - val_loss: 0.2680 - val_acc: 0.6701 - val_precision: 0.6114\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1943 - acc: 0.7797 - precision: 0.7710 - val_loss: 0.2586 - val_acc: 0.6946 - val_precision: 0.6124\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1795 - acc: 0.8059 - precision: 0.7914 - val_loss: 0.2568 - val_acc: 0.7006 - val_precision: 0.6124\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1676 - acc: 0.8210 - precision: 0.8016 - val_loss: 0.2557 - val_acc: 0.7036 - val_precision: 0.6124\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1594 - acc: 0.8334 - precision: 0.8095 - val_loss: 0.2549 - val_acc: 0.7023 - val_precision: 0.6124\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.1555 - acc: 0.8429 - precision: 0.8189 - val_loss: 0.2534 - val_acc: 0.7036 - val_precision: 0.6126\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 59s 3ms/step - loss: 0.1499 - acc: 0.8480 - precision: 0.8225 - val_loss: 0.2534 - val_acc: 0.7044 - val_precision: 0.6124\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1505 - acc: 0.8506 - precision: 0.8290 - val_loss: 0.2525 - val_acc: 0.7091 - val_precision: 0.6124\n"
     ]
    }
   ],
   "source": [
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2689 - acc: 0.6143 - precision: 0.6402 - val_loss: 0.2969 - val_acc: 0.6461 - val_precision: 0.6262\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2352 - acc: 0.6945 - precision: 0.6893 - val_loss: 0.2910 - val_acc: 0.6568 - val_precision: 0.6297\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1967 - acc: 0.7922 - precision: 0.7683 - val_loss: 0.2871 - val_acc: 0.6727 - val_precision: 0.6353\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1738 - acc: 0.8418 - precision: 0.8142 - val_loss: 0.2866 - val_acc: 0.6782 - val_precision: 0.6371\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1614 - acc: 0.8574 - precision: 0.8300 - val_loss: 0.2835 - val_acc: 0.6813 - val_precision: 0.6384\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.1519 - acc: 0.8672 - precision: 0.8368 - val_loss: 0.2815 - val_acc: 0.6950 - val_precision: 0.6498\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1443 - acc: 0.8742 - precision: 0.8426 - val_loss: 0.2793 - val_acc: 0.6993 - val_precision: 0.6484\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1387 - acc: 0.8789 - precision: 0.8463 - val_loss: 0.2780 - val_acc: 0.6984 - val_precision: 0.6472\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1353 - acc: 0.8817 - precision: 0.8509 - val_loss: 0.2766 - val_acc: 0.6993 - val_precision: 0.6475\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1305 - acc: 0.8839 - precision: 0.8508 - val_loss: 0.2753 - val_acc: 0.7143 - val_precision: 0.6569\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2654 - acc: 0.6249 - precision: 0.6390 - val_loss: 0.2714 - val_acc: 0.6474 - val_precision: 0.6114\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.2357 - acc: 0.7122 - precision: 0.6987 - val_loss: 0.2662 - val_acc: 0.6688 - val_precision: 0.6133\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 79s 4ms/step - loss: 0.1940 - acc: 0.8138 - precision: 0.7850 - val_loss: 0.2581 - val_acc: 0.6997 - val_precision: 0.6170\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 79s 4ms/step - loss: 0.1723 - acc: 0.8459 - precision: 0.8111 - val_loss: 0.2558 - val_acc: 0.7091 - val_precision: 0.6196\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 79s 4ms/step - loss: 0.1583 - acc: 0.8585 - precision: 0.8240 - val_loss: 0.2541 - val_acc: 0.7048 - val_precision: 0.6171\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 80s 4ms/step - loss: 0.1503 - acc: 0.8648 - precision: 0.8301 - val_loss: 0.2505 - val_acc: 0.7117 - val_precision: 0.6189\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 83s 4ms/step - loss: 0.1436 - acc: 0.8702 - precision: 0.8359 - val_loss: 0.2502 - val_acc: 0.7113 - val_precision: 0.6197\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 82s 4ms/step - loss: 0.1378 - acc: 0.8724 - precision: 0.8386 - val_loss: 0.2476 - val_acc: 0.7160 - val_precision: 0.6185\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 87s 4ms/step - loss: 0.1332 - acc: 0.8755 - precision: 0.8418 - val_loss: 0.2458 - val_acc: 0.7181 - val_precision: 0.6197\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 78s 4ms/step - loss: 0.1321 - acc: 0.8755 - precision: 0.8415 - val_loss: 0.2454 - val_acc: 0.7220 - val_precision: 0.6186\n",
      "Testing on 3 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 95s 5ms/step - loss: 0.2777 - acc: 0.6056 - precision: 0.6284 - val_loss: 0.2840 - val_acc: 0.6281 - val_precision: 0.6107\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 83s 4ms/step - loss: 0.2447 - acc: 0.6872 - precision: 0.6910 - val_loss: 0.2755 - val_acc: 0.6598 - val_precision: 0.6117\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 81s 4ms/step - loss: 0.2115 - acc: 0.7620 - precision: 0.7537 - val_loss: 0.2709 - val_acc: 0.6697 - val_precision: 0.6118\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 78s 4ms/step - loss: 0.1898 - acc: 0.8012 - precision: 0.7918 - val_loss: 0.2673 - val_acc: 0.6761 - val_precision: 0.6117\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 80s 4ms/step - loss: 0.1795 - acc: 0.8168 - precision: 0.8073 - val_loss: 0.2643 - val_acc: 0.6787 - val_precision: 0.6114\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 76s 4ms/step - loss: 0.1667 - acc: 0.8320 - precision: 0.8175 - val_loss: 0.2613 - val_acc: 0.6890 - val_precision: 0.6120\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 78s 4ms/step - loss: 0.1558 - acc: 0.8487 - precision: 0.8276 - val_loss: 0.2577 - val_acc: 0.6937 - val_precision: 0.6124\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 77s 4ms/step - loss: 0.1457 - acc: 0.8574 - precision: 0.8314 - val_loss: 0.2559 - val_acc: 0.6988 - val_precision: 0.6120\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 76s 4ms/step - loss: 0.1400 - acc: 0.8645 - precision: 0.8349 - val_loss: 0.2544 - val_acc: 0.7010 - val_precision: 0.6120\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 96s 5ms/step - loss: 0.1360 - acc: 0.8688 - precision: 0.8392 - val_loss: 0.2519 - val_acc: 0.7074 - val_precision: 0.6118\n"
     ]
    }
   ],
   "source": [
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    print(\"Testing on\", len(histories2)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(drop_out_deep)\n",
    "\n",
    "    final_branch2 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch2 = Dense(units=1,activation='sigmoid',name='combined')(final_branch2)\n",
    "\n",
    "    model2 = Model(inputs=all_inputs, outputs=final_branch2)\n",
    "    model2.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history2 = model2.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories2.append(history2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8512573963221669 0.8437929553554705\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "precisions1 = [x.history['precision'][-1] for x in histories1]\n",
    "precisions2 = [x.history['precision'][-1] for x in histories2]\n",
    "\n",
    "print(np.mean(precisions1), np.mean(precisions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Precision %')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23224104240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([x for x in range(1,4)], precisions1, label='Network 1')\n",
    "plt.scatter([x for x in range(1,4)], precisions2,label='Network 2')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on average, our first and second network perform very closely to one another, although Network 2 seems to be more consistent over the first 3 folds we validated on. In the block below, we look at the average precision based on every epoch and training/test fold. Since each epoch is expensive, that average could give us insight as to which network would perform better without much training. We could not afford to run 3 epochs on all 10 KFolds as it was a very expensive operation and we do not own the hardware needed to  We see that Network 1 performed better overall and decide to use as our "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983502310774848 0.7912543513079443\n"
     ]
    }
   ],
   "source": [
    "precisions1 = [x.history['precision'] for x in histories1]\n",
    "precisions2 = [x.history['precision'] for x in histories2]\n",
    "\n",
    "print(np.mean(precisions1), np.mean(precisions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precisions_MLP=[]\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    \n",
    "    inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "    # create dense input branch for numeric\n",
    "    inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "    xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "    x = concatenate([xSparse, xDense], name='concat')\n",
    "    predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and Dense layers\n",
    "    model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "              y_train, \n",
    "              epochs=5, \n",
    "              batch_size=50, \n",
    "              verbose=0)\n",
    "\n",
    "    yhat = model.predict([X_test_ohe,\n",
    "                          X_test_num]) # each branch has an input\n",
    "\n",
    "    yhat = np.round(yhat)\n",
    "    precisions_MLP.append(mt.precision_score(y_test,yhat))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.6104676104676104, 0.695557963163597]\n",
      "[0.8692450988001025, 0.85551376503277, 0.8290133251336282]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Precision %')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2324dcbd8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(precisions_MLP)\n",
    "print([x.history['precision'][-1] for x in histories1])\n",
    "hist = [x.history['precision'][-1] for x in histories1]\n",
    "plt.scatter([x for x in range(1,4)],precisions_MLP, label='MLP')\n",
    "plt.scatter([x for x in range(1,4)], hist,label='Wide & Deep')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "df_features = ['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', \n",
    "               'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', \n",
    "               'runtime_category', 'runtime_category_int', 'genres_int']\n",
    "df_class = ['above_average_vote']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    train_list.append(train_index)\n",
    "    test_list.append(test_index)\n",
    "\n",
    "df_train = deepcopy(df.iloc[train_list[0]])\n",
    "df_test = deepcopy(df.iloc[test_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 66s 3ms/step - loss: 0.5934 - acc: 0.4066 - precision: 0.5532 - val_loss: 0.5155 - val_acc: 0.4359 - val_precision: 0.6046\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.4050 - acc: 0.5950 - precision: 0.6107 - val_loss: 0.3527 - val_acc: 0.6040 - val_precision: 0.6225\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.4018 - acc: 0.5982 - precision: 0.6112 - val_loss: 0.3539 - val_acc: 0.6032 - val_precision: 0.6220\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.4007 - acc: 0.5993 - precision: 0.6111 - val_loss: 0.3539 - val_acc: 0.6032 - val_precision: 0.6220\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.4010 - acc: 0.5990 - precision: 0.6112 - val_loss: 0.3539 - val_acc: 0.6032 - val_precision: 0.6220\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 67s 3ms/step - loss: 0.4113 - acc: 0.5887 - precision: 0.6108 - val_loss: 0.3342 - val_acc: 0.6152 - val_precision: 0.6359\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 72s 3ms/step - loss: 0.4581 - acc: 0.5419 - precision: 0.6100 - val_loss: 0.5217 - val_acc: 0.4303 - val_precision: 0.6085\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.5837 - acc: 0.4163 - precision: 0.5979 - val_loss: 0.5217 - val_acc: 0.4303 - val_precision: 0.6085\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 72s 3ms/step - loss: 0.5778 - acc: 0.4222 - precision: 0.6182 - val_loss: 0.5217 - val_acc: 0.4303 - val_precision: 0.6085\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 67s 3ms/step - loss: 0.5862 - acc: 0.4138 - precision: 0.5336 - val_loss: 0.5412 - val_acc: 0.4226 - val_precision: 0.6139\n",
      "Testing on 2 split\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-7d4550b3e2cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# create crossed labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mX_crossed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mX_crossed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4875\u001b[0m                         \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4876\u001b[0m                         \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4877\u001b[1;33m                         ignore_failures=ignore_failures)\n\u001b[0m\u001b[0;32m   4878\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4879\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4931\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4932\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[1;32m-> 4933\u001b[1;33m                                         labels=labels)\n\u001b[0m\u001b[0;32m   4934\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4935\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.reduce\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src\\reduce.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.Reducer.get_result\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-7d4550b3e2cf>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# create crossed labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mX_crossed_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mX_crossed_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'_'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m__str__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__unicode__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__bytes__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__unicode__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m         self.to_string(buf=buf, name=self.name, dtype=self.dtype,\n\u001b[1;32m-> 1066\u001b[1;33m                        max_rows=max_rows, length=show_dimensions)\n\u001b[0m\u001b[0;32m   1067\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mto_string\u001b[1;34m(self, buf, na_rep, float_format, header, index, length, dtype, name, max_rows)\u001b[0m\n\u001b[0;32m   1108\u001b[0m                                         \u001b[0mfloat_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m                                         max_rows=max_rows)\n\u001b[1;32m-> 1110\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;31m# catch contract violations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_string\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m'Series([], '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfooter\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m')'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[0mfmt_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhave_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_formatted_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[0mfmt_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_formatted_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36m_get_formatted_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mhave_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mfmt_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfmt_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhave_header\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, name, formatter, **kwargs)\u001b[0m\n\u001b[0;32m   1955\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mheader\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1956\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1957\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_format_with_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_format_with_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_rep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NaN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_format_with_header\u001b[1;34m(self, header, na_rep, **kwargs)\u001b[0m\n\u001b[0;32m   1972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m             \u001b[1;31m# could have nans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1974\u001b[1;33m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1975\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0malias\u001b[0m \u001b[0mof\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \"\"\"\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_isna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_new\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"isna is not defined for MultiIndex\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mABCSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_isna_ndarraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCGeneric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pandas\\core\\dtypes\\missing.py\u001b[0m in \u001b[0;36m_isna_ndarraylike\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    145\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                 \u001b[0mvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnaobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mneeds_i8_conversion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    \n",
    "    for col in numeric_headers:\n",
    "        col_vals = df_train[col]\n",
    "        std = np.std(col_vals)\n",
    "        random.seed(1)\n",
    "        df_train[col] = col_vals.apply(lambda x: x + (random.random() * .5 * std))\n",
    "    \n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with only puturbing the class variable slightly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.3119 - acc: 0.6153 - precision: 0.6976 - val_loss: 0.3061 - val_acc: 0.6615 - val_precision: 0.6627\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 67s 3ms/step - loss: 0.2594 - acc: 0.6883 - precision: 0.7596 - val_loss: 0.3128 - val_acc: 0.6461 - val_precision: 0.6589\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 68s 3ms/step - loss: 0.2262 - acc: 0.7401 - precision: 0.7774 - val_loss: 0.2928 - val_acc: 0.6877 - val_precision: 0.6587\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.2650 - acc: 0.7172 - precision: 0.7980 - val_loss: 0.4626 - val_acc: 0.5217 - val_precision: 0.6355\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.2610 - acc: 0.7315 - precision: 0.8173 - val_loss: 0.4652 - val_acc: 0.5148 - val_precision: 0.6431\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 72s 3ms/step - loss: 0.2198 - acc: 0.7749 - precision: 0.8206 - val_loss: 0.2655 - val_acc: 0.7177 - val_precision: 0.6549\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 68s 3ms/step - loss: 0.1471 - acc: 0.8504 - precision: 0.8243 - val_loss: 0.2657 - val_acc: 0.7199 - val_precision: 0.6536\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 66s 3ms/step - loss: 0.1406 - acc: 0.8594 - precision: 0.8313 - val_loss: 0.2642 - val_acc: 0.7203 - val_precision: 0.6577\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.1374 - acc: 0.8624 - precision: 0.8342 - val_loss: 0.2635 - val_acc: 0.7263 - val_precision: 0.6571\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 72s 3ms/step - loss: 0.1349 - acc: 0.8664 - precision: 0.8385 - val_loss: 0.2625 - val_acc: 0.7254 - val_precision: 0.6610\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "\n",
    "for train,test in zip(train_list[0:1],test_list[0:1]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    \n",
    "    for col in df_class:\n",
    "        col_vals = df_train[col]\n",
    "        std = np.std(col_vals)\n",
    "        random.seed(1)\n",
    "        df_train[col] = col_vals.apply(lambda x: x + (random.random() * .1 * std))\n",
    "    \n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 72s 3ms/step - loss: 0.2618 - acc: 0.6616 - precision: 0.6777 - val_loss: 0.2864 - val_acc: 0.6611 - val_precision: 0.6295\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 75s 4ms/step - loss: 0.2106 - acc: 0.7427 - precision: 0.7336 - val_loss: 0.2802 - val_acc: 0.6864 - val_precision: 0.6432\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.1731 - acc: 0.8106 - precision: 0.7849 - val_loss: 0.2718 - val_acc: 0.7109 - val_precision: 0.6557\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 73s 3ms/step - loss: 0.1553 - acc: 0.8427 - precision: 0.8136 - val_loss: 0.2693 - val_acc: 0.7121 - val_precision: 0.6572\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 72s 3ms/step - loss: 0.1436 - acc: 0.8611 - precision: 0.8299 - val_loss: 0.2651 - val_acc: 0.7284 - val_precision: 0.6597\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 68s 3ms/step - loss: 0.1361 - acc: 0.8704 - precision: 0.8386 - val_loss: 0.2625 - val_acc: 0.7302 - val_precision: 0.6610\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.1307 - acc: 0.8761 - precision: 0.8441 - val_loss: 0.2621 - val_acc: 0.7310 - val_precision: 0.6591\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.1301 - acc: 0.8762 - precision: 0.8458 - val_loss: 0.2633 - val_acc: 0.7233 - val_precision: 0.6625\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.1268 - acc: 0.8811 - precision: 0.8508 - val_loss: 0.2609 - val_acc: 0.7332 - val_precision: 0.6642\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 74s 4ms/step - loss: 0.1240 - acc: 0.8854 - precision: 0.8536 - val_loss: 0.2612 - val_acc: 0.7319 - val_precision: 0.6642\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "\n",
    "for train,test in zip(train_list[0:1],test_list[0:1]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    \n",
    "    for col in df_class:\n",
    "        col_vals = df_train[col]\n",
    "        std = np.std(col_vals)\n",
    "        random.seed(1)\n",
    "        df_train[col] = col_vals.apply(lambda x: x + (random.random() * .25 * std))\n",
    "    \n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform t-SNE clustering of the weights in two of our OHE embedded layers to look for similarities between the separate classes of our Runtime Category and a subsample of our genres. We aim to prove that the Runtimes should have little to do with each other and be 4 completely separate classes, while the genres should get clustered together to other entries that have part of the same genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 3 nearest neighbors...\n",
      "[t-SNE] Indexed 4 samples in 0.001s...\n",
      "[t-SNE] Computed neighbors for 4 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 4 / 4\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 39.479099\n",
      "[t-SNE] Error after 400 iterations: 0.048721\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a40d9f7668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "weights=model1.get_layer(name='runtime_category_int_embed').get_weights()\n",
    "weight_labels=['Short Film','Less than Feature Film','Below Average Feature Film','Above Average Feature Film']\n",
    "tsne = TSNE(n_components=2, verbose=1)\n",
    "transformed_weights = tsne.fit_transform(weights[0])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(transformed_weights[:,0], transformed_weights[:,1],lw=0, s=40)\n",
    "for i, txt in enumerate(weight_labels):\n",
    "    ax.annotate(txt, (transformed_weights[:,0][i], transformed_weights[:,1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 12 nearest neighbors...\n",
      "[t-SNE] Indexed 13 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 13 samples in 0.001s...\n",
      "[t-SNE] Computed conditional probabilities for sample 13 / 13\n",
      "[t-SNE] Mean sigma: 1125899906842624.000000\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 56.194069\n",
      "[t-SNE] Error after 1000 iterations: 0.306846\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a4522e4240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "weights=model1.get_layer(name='genres_int_embed').get_weights()\n",
    "weight_labels=df['genres'].unique()[0:13]\n",
    "tsne = TSNE(n_components=2, verbose=1)\n",
    "transformed_weights = tsne.fit_transform(weights[0][0:13])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(transformed_weights[:,0], transformed_weights[:,1],lw=0, s=40)\n",
    "\n",
    "for i, txt in enumerate(weight_labels):\n",
    "    ax.annotate(txt, (transformed_weights[:,0][i], transformed_weights[:,1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see from the two plots of the t-SNE clusters that the runtimes were indeed 4 separate classes. Some of the genres were close such as Comedy_Horror, Comedy_Romance, Comedy and Animation_Comedy_Family. Some of the \"Action\" genres were successfully grouped together. There are some errors, but this is largely due to the fact not all possible genres are included in this cluster. We only perform the t-SNE clustering on a small subset, since 1441 different classes would be illegible."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
