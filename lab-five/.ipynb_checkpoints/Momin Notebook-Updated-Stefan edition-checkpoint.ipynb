{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as mt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input, Dropout\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45466 items in unprocessed dataframe\n",
      "4572 classes for production_companies\n",
      "2970 classes for genres\n",
      "23298 items in processed dataframe\n",
      "\n",
      "['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', 'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', 'runtime_category', 'runtime_category_int', 'genres_int', 'above_average_vote']\n",
      "budget                      float64\n",
      "genres                       object\n",
      "id                            int64\n",
      "popularity                  float64\n",
      "production_companies         object\n",
      "revenue                     float64\n",
      "runtime                     float64\n",
      "title                        object\n",
      "vote_average                float64\n",
      "vote_count                  float64\n",
      "made_in_us                     bool\n",
      "production_companies_int      int64\n",
      "runtime_category             object\n",
      "runtime_category_int          int64\n",
      "genres_int                    int64\n",
      "above_average_vote             bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "\n",
    "df = pd.read_csv('movies_metadata.csv')\n",
    "\n",
    "print(len(df),'items in unprocessed dataframe')\n",
    "df = df[df.status=='Released']\n",
    "df = df[df.original_language=='en']\n",
    "df = df.drop(columns=['adult','belongs_to_collection','homepage','imdb_id','original_language','overview',\n",
    "                     'poster_path','release_date','spoken_languages',\n",
    "                     'status','tagline','video','original_title'])\n",
    "\n",
    "def contains_us(row):\n",
    "    return 'US' in row\n",
    "\n",
    "def get_genres(row):\n",
    "    s = re.findall(\"'name': '(.*?)'\",row)\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_prod_companies(row):\n",
    "\n",
    "    s = re.findall(\"{'name': '(.*?)'\",row)\n",
    "    '''\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "    '''\n",
    "    if len(s) > 1:\n",
    "        return 'Collaboration'\n",
    "    elif len(s) == 1:\n",
    "        return s[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def discretize_runtime(row):\n",
    "    if row < 40:\n",
    "        return 'Short Film'\n",
    "    elif row < 80:\n",
    "        return 'Less than Feature Film'\n",
    "    elif row < 130:\n",
    "        return 'Below Average Feature Film'\n",
    "    else:\n",
    "        return 'Above Average Feature Film'\n",
    "\n",
    "df['made_in_us'] = df.production_countries.apply(contains_us)\n",
    "df = df.drop(columns=['production_countries'])\n",
    "df['production_companies'] = df.production_companies.apply(get_prod_companies)\n",
    "\n",
    "df['genres'] = df.genres.apply(get_genres)\n",
    "\n",
    "df = df.dropna()\n",
    "enc = LabelEncoder()\n",
    "df['production_companies_int'] = enc.fit_transform(df.production_companies)\n",
    "\n",
    "df['runtime_category'] = df.runtime.apply(discretize_runtime)\n",
    "df['runtime_category_int'] = enc.fit_transform(df.runtime_category)\n",
    "\n",
    "df['budget'] = df.budget.apply(float)\n",
    "df['popularity'] = df.popularity.apply(float)\n",
    "df['id'] = df.id.apply(int)\n",
    "\n",
    "\n",
    "df['genres_int'] = enc.fit_transform(df.genres)\n",
    "avg = df.vote_average.mean()\n",
    "df['above_average_vote'] = df.vote_average > avg\n",
    "\n",
    "df['genres'] = df['genres'].apply(\"_\".join)\n",
    "\n",
    "print(max(df.production_companies_int)+1,'classes for production_companies')\n",
    "print(max(df.genres_int)+1,'classes for genres')\n",
    "\n",
    "print(len(df),'items in processed dataframe\\n')\n",
    "print(list(df))\n",
    "print(df.dtypes)\n",
    "categorical_headers_ints = ['production_companies_int','genres_int','runtime_category_int']\n",
    "numeric_headers = ['budget','popularity','revenue','runtime','vote_average','vote_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     5.1\n",
      "0.50     6.0\n",
      "0.75     6.7\n",
      "0.90     7.3\n",
      "0.99     8.3\n",
      "1.00    10.0\n",
      "Name: vote_average, dtype: float64\n",
      "22449\n"
     ]
    }
   ],
   "source": [
    "print(df.vote_average.quantile([.25,.5,.75,.9,.99,1]))\n",
    "print(len(df[df.vote_count>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we work with the Kaggle Movies Dataset. This dataset contains metadata on 45,466 different movies released on or before July 2017. The dataset includes information about each movie such as the budget, the genres, the runtime, the revenue, and popularity scores based on data from the research group GroupLens.\n",
    "\n",
    "In preprocessing the data, we first remove the features we will not be using for classification. Then, we create a few new columns.\n",
    "\n",
    "First, we create a column called made_in_us. This is a modification of the original column production_countries, which contains a list of the countries each movie was produced in. Since there were a large number of such countries, we chose to represent that column as a binary value of if this movie was produced in the United States or in a different country.\n",
    "\n",
    "Next, we create a column called production_companies_int. This is a modification of the original column production_companies, which contains a list of the production companies that created each movie. We take this list of production companies and represent collaborations between multiple production companies as the class \"collaboration\" - we do this because there is a large number of combinations otherwise. Then, we encode the production company as an integer using sklearn's LabelEncoder class.\n",
    "\n",
    "Next, we create a column called genres_int. This is a modification of the original column genres, which contains a list of the genres each movie belongs to. We take this list of genres and encode it using sklearn's LabelEncoder class. In the case that there are multiple genres for a movie, such as a romantic comedy, we represent this combination as its own class, unlike with the production companies. The rationale behind this choice is that there is a much larger number of production companies than genres - we can represent all combinations of genres with 2,970 classes. \n",
    "\n",
    "Next, we create a column called above_average_vote. This is a modification of the original column average_vote, which is the average of all votes given to this movie on a scale of 0-10. This column is the target column; we will try to predict if a movie can score above average.\n",
    "\n",
    "Finally, we create a column called runtime_category_int. This is a modification of the original column runtime, which is the runtime of the movie in minutes. We discretize the runtime into 4 categories: short film, less than feature film, below average feature film, and above average feature film. We use the following cutoffs: a short film is less than 40 minutes, a movie that is less than a feature film is less than 80 minutes, a feature film below average is less than 130 minutes, and a feature film above average is longer than 130 minutes. \n",
    "\n",
    "We derive the runtime of a short film from the rules the Oscar awards establish for the short film category (http://www.oscars.org/sites/oscars/files/90aa_short_films.pdf). We derive the length of a feature film from the Screen Actor's Guild (http://www.sagaftra.org/files/sag/Low_Budget_Ageement_1_5.pdf). We derive the average length of a feature film from a Business Insider study (http://www.businessinsider.com/movies-are-getting-longer-2013-1).\n",
    "\n",
    "We choose to represent the runtime category as categorical data and not ordinal data. The reason we represent runtime categorically instead of ordinally is because different categories of film are not necessarily similar to one another. For example, below average feature films are closer in length to short films than above average feature films are. However, since short films are often not shown in movie theatres, it is likely that there is an entirely different audience for short films than there is for below average length feature films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "\n",
    "df_features = ['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', \n",
    "               'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', \n",
    "               'runtime_category', 'runtime_category_int', 'genres_int']\n",
    "df_class = ['above_average_vote']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    train_list.append(train_index)\n",
    "    test_list.append(test_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train = deepcopy(df.iloc[train_list[0]])\n",
    "df_test = deepcopy(df.iloc[test_list[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODING ONLY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 4572 7542 7546]\n",
      "(20967, 7202)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# now let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "y_train = df_train[df_class].values.astype(np.int)\n",
    "y_test = df_test[df_class].values.astype(np.int)\n",
    "\n",
    "# the ohe instance will help us to organize our encoded matrix\n",
    "print(ohe.feature_indices_)\n",
    "print(X_train_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_ohe (InputLayer)              (None, 7202)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X_Numeric (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ohe_1 (Dense)                   (None, 10)           72030       X_ohe[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "num_1 (Dense)                   (None, 10)           70          X_Numeric[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 20)           0           ohe_1[0][0]                      \n",
      "                                                                 num_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 1)            21          concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 72,121\n",
      "Trainable params: 72,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combine the features with two branches\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# and save off the numeric features\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num = df_test[numeric_headers].values\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "# create dense input branch for numeric\n",
    "inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "x = concatenate([xSparse, xDense], name='concat')\n",
    "predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and Dense layers\n",
    "model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to define precision metric\n",
    "import keras.backend as K\n",
    "#precision metric gotten from previous release of keras\n",
    "#https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1  907]\n",
      " [   1 1422]] 0.6105624731644482\n",
      "Wall time: 8.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy', precision])\n",
    "model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "          y_train, \n",
    "          epochs=10, \n",
    "          batch_size=50, \n",
    "          verbose=0)\n",
    "\n",
    "yhat = model.predict([X_test_ohe,\n",
    "                      X_test_num]) # each branch has an input\n",
    "\n",
    "yhat = np.round(yhat)\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.precision_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide and Deep Model (No OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      genres            runtime_category\n",
      "2346                  Horror  Below Average Feature Film\n",
      "2347                  Horror  Below Average Feature Film\n",
      "2350                  Comedy  Below Average Feature Film\n",
      "2352  Horror_Science Fiction  Below Average Feature Film\n",
      "2354  Drama_Thriller_Mystery  Above Average Feature Film\n",
      "                      genres  made_in_us\n",
      "2346                  Horror        True\n",
      "2347                  Horror        True\n",
      "2350                  Comedy        True\n",
      "2352  Horror_Science Fiction        True\n",
      "2354  Drama_Thriller_Mystery       False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                 ['genres','made_in_us']]\n",
    "\n",
    "#'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "# we need to create separate lists for each branch\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_wide_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # create crossed labels\n",
    "    print (df_train[cols].head())\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "    \n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_wide_branch_outputs.append(x)\n",
    "    \n",
    "# merge the branches together\n",
    "wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "# reset this input branch\n",
    "all_deep_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_headers_ints:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values )\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name=col+'_embed')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_deep_branch_outputs.append(x)\n",
    "    \n",
    "# also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                        sparse=False,\n",
    "                        name='numeric_data'))\n",
    "\n",
    "x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "#ohe = OneHotEncoder()\n",
    "#X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "#X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "#inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "#sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "# merge the deep branches together\n",
    "deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=10,activation='relu', name='deep3')(drop_out_deep)\n",
    "    \n",
    "final_branch = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "final_branch = Dense(units=1,activation='sigmoid',name='combined')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvocationException\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\pydot_ng\\__init__.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format)\u001b[0m\n\u001b[0;32m   1889\u001b[0m                 raise InvocationException(\n\u001b[1;32m-> 1890\u001b[1;33m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[0;32m   1891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvocationException\u001b[0m: GraphViz's executables not found",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1752a1e5a8b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2796 - acc: 0.5841 - precision: 0.6128 - val_loss: 0.3478 - val_acc: 0.5311 - val_precision: 0.6051\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2202 - acc: 0.6787 - precision: 0.6827 - val_loss: 0.2475 - val_acc: 0.6710 - val_precision: 0.6343\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1740 - acc: 0.7584 - precision: 0.7503 - val_loss: 0.2414 - val_acc: 0.6941 - val_precision: 0.6433\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1474 - acc: 0.8344 - precision: 0.8233 - val_loss: 0.2408 - val_acc: 0.6958 - val_precision: 0.6438\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.1304 - acc: 0.8764 - precision: 0.8735 - val_loss: 0.2436 - val_acc: 0.6864 - val_precision: 0.6382\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1206 - acc: 0.8938 - precision: 0.8893 - val_loss: 0.2351 - val_acc: 0.7130 - val_precision: 0.6540\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1142 - acc: 0.9007 - precision: 0.8942 - val_loss: 0.2367 - val_acc: 0.7130 - val_precision: 0.6521\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1066 - acc: 0.9104 - precision: 0.9045 - val_loss: 0.2319 - val_acc: 0.7113 - val_precision: 0.6511\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.0971 - acc: 0.9200 - precision: 0.9058 - val_loss: 0.2333 - val_acc: 0.7130 - val_precision: 0.6515\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.0925 - acc: 0.9229 - precision: 0.9057 - val_loss: 0.2307 - val_acc: 0.7199 - val_precision: 0.6555\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy', precision])\n",
    "initial_weights = model.get_weights()\n",
    "# lets also add the history variable to see how we are doing\n",
    "# and lets add a validation set to keep track of our progress\n",
    "history = model.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 293  615]\n",
      " [  38 1385]] 0.6925\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat), mt.precision_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epochs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2322403e0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['precision'])\n",
    "\n",
    "plt.ylabel('Precision %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, we create cross-product features for the wide part of our wide-and-deep network. We cross the values for genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "\n",
    "We decide to cross the values for genres_int and runtime_category_int because films of different genres often have different lengths. For example, action movies have an average runtime of 100.46 minutes, whereas animation movies have an average runtime of 61.04 minutes. Thus, we speculate that a long animation movie will have a different reaction than a long action movie.\n",
    "\n",
    "Next, we cross the values for genres_int and made_in_us int. We base this feature cross on the idea that different countries may prefer different genres of movie. This hypothesis is supported by independent research from the New York Film Academy (https://www.nyfa.edu/student-resources/12-of-the-most-popular-movie-genres-by-country/) and the American Film Market & Conferences association (http://americanfilmmarket.com/relative-popularity-genres-around-world/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chosen task is a binary classification task: can we predict if a movie will score above or below average when rated by users on a scale of 0-10? We found in our data set that the average of the ~22,000 movies reviewed is a 6.0/10; therefore, a movie that scores above 6.0 is above average, any a movie scoring 6.0 or less is not.\n",
    "\n",
    "The business case for our prediction task is a movie studio trying to determine if their next movie will score above average or not. We imagine that a movie studio would come to us for our analysis after defining the basic criteria for their movie, such as genre, budget, and approximate runtime. At this point in the production cycle, the firm has not yet invested large amounts of time or money into creating the movie outline. Thus, the movie studio would much rather us reject a good idea than accept a bad idea; a rejected good idea is a waste of the small amount of time put into creating a movie outline, but an accepted bad idea will waste future resources as well as the outline time.\n",
    "\n",
    "With this use case in mind, we advance precision as our chosen evaluation criteria. Precision, mathematically defined as tp/(tp+fp), is a measure of what percentage of named positives are true positives. In our use case, a precision score of 30% means that, of the movies we said would do better than average, only 30% actually did better than average.\n",
    "\n",
    "The movie studio would be interested in a high-precision system because this system is good at telling if a movie will be above average. A 90% precision score means that 9 out of 10 movies that we say will succeed do in fact succeed; this goves the movie studio an idea of how likely it is that their movie is a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will use a 10-fold stratified cross-validation approach for splitting our data into training and testing sets. The reason we use cross-validation instead of shuffle-split is that we worry we do not have enough data. After pre-processing, we are left with ~22,000 movies. This is not an entirely small dataset; however, the feature space is quite large. For example, the movie genre alone can take on 2,970 different values, and the production company 4,572 values. We use 10-folds so that 90% of our data comprises the training set in each fold; this will ensure to the best of our ability that we have enough data.\n",
    "\n",
    "The reason we use stratified cross-validation is to preserve the class distributions seen in the data; if one class of a feature occurs 10% of the time in the data, it will occur 10% of the time in the training data and 10% of the time in the testing data. We use stratified cross-validation because our data represent the real-world distribution. When applied to real movies, it will also be true that there is large class imbalance in certain features; it is unlikely that in the future a dramatically different percentage of the market will be dominated by Animated-Romantic-Action-Adult films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.3385 - acc: 0.5880 - precision: 0.6663 - val_loss: 0.4772 - val_acc: 0.4753 - val_precision: 0.5996\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2901 - acc: 0.6673 - precision: 0.7306 - val_loss: 0.4587 - val_acc: 0.5187 - val_precision: 0.6425\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2611 - acc: 0.7254 - precision: 0.7902 - val_loss: 0.4566 - val_acc: 0.5204 - val_precision: 0.6423\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2461 - acc: 0.7521 - precision: 0.8226 - val_loss: 0.4534 - val_acc: 0.5298 - val_precision: 0.6494\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2325 - acc: 0.7696 - precision: 0.8374 - val_loss: 0.4589 - val_acc: 0.5225 - val_precision: 0.6448\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2303 - acc: 0.7753 - precision: 0.8541 - val_loss: 0.4527 - val_acc: 0.5345 - val_precision: 0.6548\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2211 - acc: 0.7847 - precision: 0.8612 - val_loss: 0.4329 - val_acc: 0.5521 - val_precision: 0.6453\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1634 - acc: 0.8436 - precision: 0.8576 - val_loss: 0.2625 - val_acc: 0.7242 - val_precision: 0.6587\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.1367 - acc: 0.8721 - precision: 0.8614 - val_loss: 0.2622 - val_acc: 0.7233 - val_precision: 0.6583\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1370 - acc: 0.8713 - precision: 0.8692 - val_loss: 0.2612 - val_acc: 0.7267 - val_precision: 0.6590\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.2843 - acc: 0.6352 - precision: 0.6586 - val_loss: 0.2758 - val_acc: 0.6276 - val_precision: 0.6107\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2316 - acc: 0.7145 - precision: 0.7116 - val_loss: 0.2535 - val_acc: 0.7134 - val_precision: 0.6162\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2348 - acc: 0.7480 - precision: 0.7708 - val_loss: 0.4527 - val_acc: 0.5062 - val_precision: 0.6180\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2697 - acc: 0.7327 - precision: 0.8122 - val_loss: 0.4463 - val_acc: 0.5242 - val_precision: 0.6189\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2544 - acc: 0.7565 - precision: 0.8329 - val_loss: 0.4416 - val_acc: 0.5298 - val_precision: 0.6203\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2418 - acc: 0.7697 - precision: 0.8412 - val_loss: 0.4391 - val_acc: 0.5260 - val_precision: 0.6180\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2182 - acc: 0.7930 - precision: 0.8534 - val_loss: 0.4365 - val_acc: 0.5332 - val_precision: 0.6202\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2212 - acc: 0.7896 - precision: 0.8494 - val_loss: 0.4319 - val_acc: 0.5375 - val_precision: 0.6210\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2138 - acc: 0.7981 - precision: 0.8486 - val_loss: 0.4315 - val_acc: 0.5350 - val_precision: 0.6208\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2081 - acc: 0.8035 - precision: 0.8555 - val_loss: 0.4290 - val_acc: 0.5367 - val_precision: 0.6187\n",
      "Testing on 3 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2820 - acc: 0.6500 - precision: 0.6700 - val_loss: 0.2724 - val_acc: 0.6697 - val_precision: 0.6111\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2327 - acc: 0.7046 - precision: 0.7075 - val_loss: 0.2723 - val_acc: 0.6628 - val_precision: 0.6114\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2131 - acc: 0.7469 - precision: 0.7441 - val_loss: 0.2680 - val_acc: 0.6701 - val_precision: 0.6114\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1943 - acc: 0.7797 - precision: 0.7710 - val_loss: 0.2586 - val_acc: 0.6946 - val_precision: 0.6124\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1795 - acc: 0.8059 - precision: 0.7914 - val_loss: 0.2568 - val_acc: 0.7006 - val_precision: 0.6124\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1676 - acc: 0.8210 - precision: 0.8016 - val_loss: 0.2557 - val_acc: 0.7036 - val_precision: 0.6124\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1594 - acc: 0.8334 - precision: 0.8095 - val_loss: 0.2549 - val_acc: 0.7023 - val_precision: 0.6124\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.1555 - acc: 0.8429 - precision: 0.8189 - val_loss: 0.2534 - val_acc: 0.7036 - val_precision: 0.6126\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 59s 3ms/step - loss: 0.1499 - acc: 0.8480 - precision: 0.8225 - val_loss: 0.2534 - val_acc: 0.7044 - val_precision: 0.6124\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1505 - acc: 0.8506 - precision: 0.8290 - val_loss: 0.2525 - val_acc: 0.7091 - val_precision: 0.6124\n"
     ]
    }
   ],
   "source": [
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2689 - acc: 0.6143 - precision: 0.6402 - val_loss: 0.2969 - val_acc: 0.6461 - val_precision: 0.6262\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2352 - acc: 0.6945 - precision: 0.6893 - val_loss: 0.2910 - val_acc: 0.6568 - val_precision: 0.6297\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1967 - acc: 0.7922 - precision: 0.7683 - val_loss: 0.2871 - val_acc: 0.6727 - val_precision: 0.6353\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1738 - acc: 0.8418 - precision: 0.8142 - val_loss: 0.2866 - val_acc: 0.6782 - val_precision: 0.6371\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1614 - acc: 0.8574 - precision: 0.8300 - val_loss: 0.2835 - val_acc: 0.6813 - val_precision: 0.6384\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.1519 - acc: 0.8672 - precision: 0.8368 - val_loss: 0.2815 - val_acc: 0.6950 - val_precision: 0.6498\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1443 - acc: 0.8742 - precision: 0.8426 - val_loss: 0.2793 - val_acc: 0.6993 - val_precision: 0.6484\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1387 - acc: 0.8789 - precision: 0.8463 - val_loss: 0.2780 - val_acc: 0.6984 - val_precision: 0.6472\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1353 - acc: 0.8817 - precision: 0.8509 - val_loss: 0.2766 - val_acc: 0.6993 - val_precision: 0.6475\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.1305 - acc: 0.8839 - precision: 0.8508 - val_loss: 0.2753 - val_acc: 0.7143 - val_precision: 0.6569\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2654 - acc: 0.6249 - precision: 0.6390 - val_loss: 0.2714 - val_acc: 0.6474 - val_precision: 0.6114\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.2357 - acc: 0.7122 - precision: 0.6987 - val_loss: 0.2662 - val_acc: 0.6688 - val_precision: 0.6133\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 79s 4ms/step - loss: 0.1940 - acc: 0.8138 - precision: 0.7850 - val_loss: 0.2581 - val_acc: 0.6997 - val_precision: 0.6170\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 79s 4ms/step - loss: 0.1723 - acc: 0.8459 - precision: 0.8111 - val_loss: 0.2558 - val_acc: 0.7091 - val_precision: 0.6196\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 79s 4ms/step - loss: 0.1583 - acc: 0.8585 - precision: 0.8240 - val_loss: 0.2541 - val_acc: 0.7048 - val_precision: 0.6171\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 80s 4ms/step - loss: 0.1503 - acc: 0.8648 - precision: 0.8301 - val_loss: 0.2505 - val_acc: 0.7117 - val_precision: 0.6189\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 83s 4ms/step - loss: 0.1436 - acc: 0.8702 - precision: 0.8359 - val_loss: 0.2502 - val_acc: 0.7113 - val_precision: 0.6197\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 82s 4ms/step - loss: 0.1378 - acc: 0.8724 - precision: 0.8386 - val_loss: 0.2476 - val_acc: 0.7160 - val_precision: 0.6185\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 87s 4ms/step - loss: 0.1332 - acc: 0.8755 - precision: 0.8418 - val_loss: 0.2458 - val_acc: 0.7181 - val_precision: 0.6197\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 78s 4ms/step - loss: 0.1321 - acc: 0.8755 - precision: 0.8415 - val_loss: 0.2454 - val_acc: 0.7220 - val_precision: 0.6186\n",
      "Testing on 3 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/10\n",
      "20967/20967 [==============================] - 95s 5ms/step - loss: 0.2777 - acc: 0.6056 - precision: 0.6284 - val_loss: 0.2840 - val_acc: 0.6281 - val_precision: 0.6107\n",
      "Epoch 2/10\n",
      "20967/20967 [==============================] - 83s 4ms/step - loss: 0.2447 - acc: 0.6872 - precision: 0.6910 - val_loss: 0.2755 - val_acc: 0.6598 - val_precision: 0.6117\n",
      "Epoch 3/10\n",
      "20967/20967 [==============================] - 81s 4ms/step - loss: 0.2115 - acc: 0.7620 - precision: 0.7537 - val_loss: 0.2709 - val_acc: 0.6697 - val_precision: 0.6118\n",
      "Epoch 4/10\n",
      "20967/20967 [==============================] - 78s 4ms/step - loss: 0.1898 - acc: 0.8012 - precision: 0.7918 - val_loss: 0.2673 - val_acc: 0.6761 - val_precision: 0.6117\n",
      "Epoch 5/10\n",
      "20967/20967 [==============================] - 80s 4ms/step - loss: 0.1795 - acc: 0.8168 - precision: 0.8073 - val_loss: 0.2643 - val_acc: 0.6787 - val_precision: 0.6114\n",
      "Epoch 6/10\n",
      "20967/20967 [==============================] - 76s 4ms/step - loss: 0.1667 - acc: 0.8320 - precision: 0.8175 - val_loss: 0.2613 - val_acc: 0.6890 - val_precision: 0.6120\n",
      "Epoch 7/10\n",
      "20967/20967 [==============================] - 78s 4ms/step - loss: 0.1558 - acc: 0.8487 - precision: 0.8276 - val_loss: 0.2577 - val_acc: 0.6937 - val_precision: 0.6124\n",
      "Epoch 8/10\n",
      "20967/20967 [==============================] - 77s 4ms/step - loss: 0.1457 - acc: 0.8574 - precision: 0.8314 - val_loss: 0.2559 - val_acc: 0.6988 - val_precision: 0.6120\n",
      "Epoch 9/10\n",
      "20967/20967 [==============================] - 76s 4ms/step - loss: 0.1400 - acc: 0.8645 - precision: 0.8349 - val_loss: 0.2544 - val_acc: 0.7010 - val_precision: 0.6120\n",
      "Epoch 10/10\n",
      "20967/20967 [==============================] - 96s 5ms/step - loss: 0.1360 - acc: 0.8688 - precision: 0.8392 - val_loss: 0.2519 - val_acc: 0.7074 - val_precision: 0.6118\n"
     ]
    }
   ],
   "source": [
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    print(\"Testing on\", len(histories2)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(drop_out_deep)\n",
    "\n",
    "    final_branch2 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch2 = Dense(units=1,activation='sigmoid',name='combined')(final_branch2)\n",
    "\n",
    "    model2 = Model(inputs=all_inputs, outputs=final_branch2)\n",
    "    model2.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history2 = model2.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories2.append(history2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8512573963221669 0.8437929553554705\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "precisions1 = [x.history['val_precision'][-1] for x in histories1]\n",
    "precisions2 = [x.history['val_precision'][-1] for x in histories2]\n",
    "\n",
    "print(np.mean(precisions1), np.mean(precisions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Precision %')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23224104240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([x for x in range(1,11)], precisions1, label='Network 1')\n",
    "plt.scatter([x for x in range(1,11)], precisions2,label='Network 2')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on average, our first and second network perform very closely to one another, although Network 2 seems to be more consistent over the first 3 folds we validated on. In the block below, we look at the average precision based on every epoch and training/test fold. Since each epoch is expensive, that average could give us insight as to which network would perform better without much training. We could not afford to run 3 epochs on all 10 KFolds as it was a very expensive operation and we do not own the hardware needed to  We see that Network 1 performed better overall and decide to use as our "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983502310774848 0.7912543513079443\n"
     ]
    }
   ],
   "source": [
    "precisions1 = [x.history['val_precision'] for x in histories1]\n",
    "precisions2 = [x.history['val_precision'] for x in histories2]\n",
    "\n",
    "print(np.mean(precisions1), np.mean(precisions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precisions_MLP=[]\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    \n",
    "    inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "    # create dense input branch for numeric\n",
    "    inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "    xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "    x = concatenate([xSparse, xDense], name='concat')\n",
    "    predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and Dense layers\n",
    "    model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "              y_train, \n",
    "              epochs=10, \n",
    "              batch_size=50, \n",
    "              verbose=0)\n",
    "\n",
    "    yhat = model.predict([X_test_ohe,\n",
    "                          X_test_num]) # each branch has an input\n",
    "\n",
    "    yhat = np.round(yhat)\n",
    "    precisions_MLP.append(mt.precision_score(y_test,yhat))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.6104676104676104, 0.695557963163597]\n",
      "[0.8692450988001025, 0.85551376503277, 0.8290133251336282]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Precision %')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2324dcbd8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(precisions_MLP)\n",
    "print([x.history['val_precision'][-1] for x in histories1])\n",
    "hist = [x.history['val_precision'][-1] for x in histories1]\n",
    "plt.scatter([x for x in range(1,11)],precisions_MLP, label='MLP')\n",
    "plt.scatter([x for x in range(1,11)], hist,label='Wide & Deep')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
