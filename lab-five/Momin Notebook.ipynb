{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45466 items in unprocessed dataframe\n",
      "4572 classes for production_companies\n",
      "2970 classes for genres\n",
      "23298 items in processed dataframe\n",
      "\n",
      "['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', 'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', 'runtime_category', 'runtime_category_int', 'genres_int', 'above_average_vote']\n",
      "budget                      float64\n",
      "genres                       object\n",
      "id                            int64\n",
      "popularity                  float64\n",
      "production_companies         object\n",
      "revenue                     float64\n",
      "runtime                     float64\n",
      "title                        object\n",
      "vote_average                float64\n",
      "vote_count                  float64\n",
      "made_in_us                     bool\n",
      "production_companies_int      int64\n",
      "runtime_category             object\n",
      "runtime_category_int          int64\n",
      "genres_int                    int64\n",
      "above_average_vote             bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "\n",
    "df = pd.read_csv('movies_metadata.csv')\n",
    "\n",
    "print(len(df),'items in unprocessed dataframe')\n",
    "df = df[df.status=='Released']\n",
    "df = df[df.original_language=='en']\n",
    "df = df.drop(columns=['adult','belongs_to_collection','homepage','imdb_id','original_language','overview',\n",
    "                     'poster_path','release_date','spoken_languages',\n",
    "                     'status','tagline','video','original_title'])\n",
    "\n",
    "def contains_us(row):\n",
    "    return 'US' in row\n",
    "\n",
    "def get_genres(row):\n",
    "    s = re.findall(\"'name': '(.*?)'\",row)\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_prod_companies(row):\n",
    "\n",
    "    s = re.findall(\"{'name': '(.*?)'\",row)\n",
    "    '''\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "    '''\n",
    "    if len(s) > 1:\n",
    "        return 'Collaboration'\n",
    "    elif len(s) == 1:\n",
    "        return s[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def discretize_runtime(row):\n",
    "    if row < 40:\n",
    "        return 'Short Film'\n",
    "    elif row < 80:\n",
    "        return 'Less than Feature Film'\n",
    "    elif row < 130:\n",
    "        return 'Below Average Feature Film'\n",
    "    else:\n",
    "        return 'Above Average Feature Film'\n",
    "\n",
    "df['made_in_us'] = df.production_countries.apply(contains_us)\n",
    "df = df.drop(columns=['production_countries'])\n",
    "df['production_companies'] = df.production_companies.apply(get_prod_companies)\n",
    "\n",
    "df['genres'] = df.genres.apply(get_genres)\n",
    "\n",
    "df = df.dropna()\n",
    "enc = LabelEncoder()\n",
    "df['production_companies_int'] = enc.fit_transform(df.production_companies)\n",
    "\n",
    "df['runtime_category'] = df.runtime.apply(discretize_runtime)\n",
    "df['runtime_category_int'] = enc.fit_transform(df.runtime_category)\n",
    "\n",
    "df['budget'] = df.budget.apply(float)\n",
    "df['popularity'] = df.popularity.apply(float)\n",
    "df['id'] = df.id.apply(int)\n",
    "\n",
    "\n",
    "df['genres_int'] = enc.fit_transform(df.genres)\n",
    "avg = df.vote_average.mean()\n",
    "df['above_average_vote'] = df.vote_average > avg\n",
    "\n",
    "print(max(df.production_companies_int)+1,'classes for production_companies')\n",
    "print(max(df.genres_int)+1,'classes for genres')\n",
    "\n",
    "print(len(df),'items in processed dataframe\\n')\n",
    "print(list(df))\n",
    "print(df.dtypes)\n",
    "\n",
    "categorical_headers_ints = ['production_companies_int','genres_int','runtime_category_int']\n",
    "numeric_headers = ['budget','popularity','revenue','runtime','vote_average','vote_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     5.1\n",
      "0.50     6.0\n",
      "0.75     6.7\n",
      "0.90     7.3\n",
      "0.99     8.3\n",
      "1.00    10.0\n",
      "Name: vote_average, dtype: float64\n",
      "22449\n"
     ]
    }
   ],
   "source": [
    "print(df.vote_average.quantile([.25,.5,.75,.9,.99,1]))\n",
    "print(len(df[df.vote_count>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we work with the Kaggle Movies Dataset. This dataset contains metadata on 45,466 different movies released on or before July 2017. The dataset includes information about each movie such as the budget, the genres, the runtime, the revenue, and popularity scores based on data from the research group GroupLens.\n",
    "\n",
    "In preprocessing the data, we first remove the features we will not be using for classification. Then, we create a few new columns.\n",
    "\n",
    "First, we create a column called made_in_us. This is a modification of the original column production_countries, which contains a list of the countries each movie was produced in. Since there were a large number of such countries, we chose to represent that column as a binary value of if this movie was produced in the United States or in a different country.\n",
    "\n",
    "Next, we create a column called production_companies_int. This is a modification of the original column production_companies, which contains a list of the production companies that created each movie. We take this list of production companies and represent collaborations between multiple production companies as the class \"collaboration\" - we do this because there is a large number of combinations otherwise. Then, we encode the production company as an integer using sklearn's LabelEncoder class.\n",
    "\n",
    "Next, we create a column called genres_int. This is a modification of the original column genres, which contains a list of the genres each movie belongs to. We take this list of genres and encode it using sklearn's LabelEncoder class. In the case that there are multiple genres for a movie, such as a romantic comedy, we represent this combination as its own class, unlike with the production companies. The rationale behind this choice is that there is a much larger number of production companies than genres - we can represent all combinations of genres with 2,970 classes. \n",
    "\n",
    "Next, we create a column called above_average_vote. This is a modification of the original column average_vote, which is the average of all votes given to this movie on a scale of 0-10. This column is the target column; we will try to predict if a movie can score above average.\n",
    "\n",
    "Finally, we create a column called runtime_category_int. This is a modification of the original column runtime, which is the runtime of the movie in minutes. We discretize the runtime into 4 categories: short film, less than feature film, below average feature film, and above average feature film. We use the following cutoffs: a short film is less than 40 minutes, a movie that is less than a feature film is less than 80 minutes, a feature film below average is less than 130 minutes, and a feature film above average is longer than 130 minutes. \n",
    "\n",
    "We derive the runtime of a short film from the rules the Oscar awards establish for the short film category (http://www.oscars.org/sites/oscars/files/90aa_short_films.pdf). We derive the length of a feature film from the Screen Actor's Guild (http://www.sagaftra.org/files/sag/Low_Budget_Ageement_1_5.pdf). We derive the average length of a feature film from a Business Insider study (http://www.businessinsider.com/movies-are-getting-longer-2013-1).\n",
    "\n",
    "We choose to represent the runtime category as categorical data and not ordinal data. The reason we represent runtime categorically instead of ordinally is because different categories of film are not necessarily similar to one another. For example, below average feature films are closer in length to short films than above average feature films are. However, since short films are often not shown in movie theatres, it is likely that there is an entirely different audience for short films than there is for below average length feature films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "\n",
    "df_features = ['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', \n",
    "               'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', \n",
    "               'runtime_category', 'runtime_category_int', 'genres_int']\n",
    "df_class = ['above_average_vote']\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    train_list.append(train_index)\n",
    "    test_list.append(test_index)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_train = deepcopy(df.iloc[train_list[0]])\n",
    "df_test = deepcopy(df.iloc[test_list[0]])\n",
    "\n",
    "#print (df_train.head())\n",
    "#print (df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 4572 7542 7546]\n",
      "(20967, 7202)\n",
      "<class 'scipy.sparse.csr.csr_matrix'> ========THIS IS SPARSE ENCODED=======\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# now let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "y_train = df_train[df_class].values.astype(np.int)\n",
    "y_test = df_test[df_class].values.astype(np.int)\n",
    "\n",
    "# the ohe instance will help us to organize our encoded matrix\n",
    "print(ohe.feature_indices_)\n",
    "print(X_train_ohe.shape)\n",
    "print(type(X_train_ohe), '========THIS IS SPARSE ENCODED=======')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Cross the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_ohe (InputLayer)              (None, 7202)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X_Numeric (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ohe_1 (Dense)                   (None, 10)           72030       X_ohe[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "num_1 (Dense)                   (None, 10)           70          X_Numeric[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 20)           0           ohe_1[0][0]                      \n",
      "                                                                 num_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 1)            21          concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 72,121\n",
      "Trainable params: 72,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combine the features with two branches\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# and save off the numeric features\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num = df_test[numeric_headers].values\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "# create dense input branch for numeric\n",
    "inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "x = concatenate([xSparse, xDense], name='concat')\n",
    "predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and Dense layers\n",
    "model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 290  618]\n",
      " [  64 1359]] 0.7074217074217074\n",
      "Wall time: 7.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "          y_train, \n",
    "          epochs=10, \n",
    "          batch_size=50, \n",
    "          verbose=0)\n",
    "\n",
    "yhat = model.predict([X_test_ohe,\n",
    "                      X_test_num]) # each branch has an input\n",
    "\n",
    "yhat = np.round(yhat)\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.accuracy_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.46123161306407\n",
      "61.03592233009709\n"
     ]
    }
   ],
   "source": [
    "#insert crossing code\n",
    "\n",
    "def has_action(row):\n",
    "    return 'Action' in row\n",
    "\n",
    "def has_animation(row):\n",
    "    return 'Animation' in row\n",
    "\n",
    "action_movies = df[df.genres.apply(has_action)]\n",
    "animation_movies = df[df.genres.apply(has_animation)]\n",
    "\n",
    "print(action_movies.runtime.mean())\n",
    "print(animation_movies.runtime.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, we create cross-product features for the wide part of our wide-and-deep network. We cross the values for genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "\n",
    "We decide to cross the values for genres_int and runtime_category_int because films of different genres often have different lengths. For example, action movies have an average runtime of 100.46 minutes, whereas animation movies have an average runtime of 61.04 minutes. Thus, we speculate that a long animation movie will have a different reaction than a long action movie.\n",
    "\n",
    "Next, we cross the values for genres_int and made_in_us int. We base this feature cross on the idea that different countries may prefer different genres of movie. This hypothesis is supported by independent research from the New York Film Academy (https://www.nyfa.edu/student-resources/12-of-the-most-popular-movie-genres-by-country/) and the American Film Market & Conferences association (http://americanfilmmarket.com/relative-popularity-genres-around-world/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chosen task is a binary classification task: can we predict if a movie will score above or below average when rated by users on a scale of 0-10? We found in our data set that the average of the ~22,000 movies reviewed is a 6.0/10; therefore, a movie that scores above 6.0 is above average, any a movie scoring 6.0 or less is not.\n",
    "\n",
    "The business case for our prediction task is a movie studio trying to determine if their next movie will score above average or not. We imagine that a movie studio would come to us for our analysis after defining the basic criteria for their movie, such as genre, budget, and approximate runtime. At this point in the production cycle, the firm has not yet invested large amounts of time or money into creating the movie outline. Thus, the movie studio would much rather us reject a good idea than accept a bad idea; a rejected good idea is a waste of the small amount of time put into creating a movie outline, but an accepted bad idea will waste future resources as well as the outline time.\n",
    "\n",
    "With this use case in mind, we advance precision as our chosen evaluation criteria. Precision, mathematically defined as tp/(tp+fp), is a measure of what percentage of named positives are true positives. In our use case, a precision score of 30% means that, of the movies we said would do better than average, only 30% actually did better than average.\n",
    "\n",
    "The movie studio would be interested in a high-precision system because this system is good at telling if a movie will be above average. A 90% precision score means that 9 out of 10 movies that we say will succeed do in fact succeed; this goves the movie studio an idea of how likely it is that their movie is a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will use a 10-fold stratified cross-validation approach for splitting our data into training and testing sets. The reason we use cross-validation instead of shuffle-split is that we worry we do not have enough data. After pre-processing, we are left with ~22,000 movies. This is not an entirely small dataset; however, the feature space is quite large. For example, the movie genre alone can take on 2,970 different values, and the production company 4,572 values. We use 10-folds so that 90% of our data comprises the training set in each fold; this will ensure to the best of our ability that we have enough data.\n",
    "\n",
    "The reason we use stratified cross-validation is to preserve the class distributions seen in the data; if one class of a feature occurs 10% of the time in the data, it will occur 10% of the time in the training data and 10% of the time in the testing data. We use stratified cross-validation because our data represent the real-world distribution. When applied to real movies, it will also be true that there is large class imbalance in certain features; it is unlikely that in the future a dramatically different percentage of the market will be dominated by Animated-Romantic-Action-Adult films."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
