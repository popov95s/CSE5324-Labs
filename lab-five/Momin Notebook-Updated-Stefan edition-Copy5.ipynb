{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as mt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Input, Dropout\n",
    "from keras.layers import Embedding, Flatten, Merge, concatenate\n",
    "from keras.models import Model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45466 items in unprocessed dataframe\n",
      "4572 classes for production_companies\n",
      "1441 classes for genres\n",
      "23298 items in processed dataframe\n",
      "\n",
      "['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', 'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', 'runtime_category', 'runtime_category_int', 'above_average_vote', 'genres_int']\n",
      "budget                      float64\n",
      "genres                       object\n",
      "id                            int64\n",
      "popularity                  float64\n",
      "production_companies         object\n",
      "revenue                     float64\n",
      "runtime                     float64\n",
      "title                        object\n",
      "vote_average                float64\n",
      "vote_count                  float64\n",
      "made_in_us                     bool\n",
      "production_companies_int      int64\n",
      "runtime_category             object\n",
      "runtime_category_int          int64\n",
      "above_average_vote             bool\n",
      "genres_int                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
    "\n",
    "\n",
    "df = pd.read_csv('movies_metadata.csv')\n",
    "\n",
    "print(len(df),'items in unprocessed dataframe')\n",
    "df = df[df.status=='Released']\n",
    "df = df[df.original_language=='en']\n",
    "df = df.drop(columns=['adult','belongs_to_collection','homepage','imdb_id','original_language','overview',\n",
    "                     'poster_path','release_date','spoken_languages',\n",
    "                     'status','tagline','video','original_title'])\n",
    "\n",
    "def contains_us(row):\n",
    "    return 'US' in row\n",
    "\n",
    "def get_genres(row):\n",
    "    s = re.findall(\"'name': '(.*?)'\",row)\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_prod_companies(row):\n",
    "\n",
    "    s = re.findall(\"{'name': '(.*?)'\",row)\n",
    "    '''\n",
    "    if len(s) > 0:\n",
    "        return s\n",
    "    else:\n",
    "        return None\n",
    "    '''\n",
    "    if len(s) > 1:\n",
    "        return 'Collaboration'\n",
    "    elif len(s) == 1:\n",
    "        return s[0]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def discretize_runtime(row):\n",
    "    if row < 40:\n",
    "        return 'Short Film'\n",
    "    elif row < 80:\n",
    "        return 'Less than Feature Film'\n",
    "    elif row < 130:\n",
    "        return 'Below Average Feature Film'\n",
    "    else:\n",
    "        return 'Above Average Feature Film'\n",
    "\n",
    "df['made_in_us'] = df.production_countries.apply(contains_us)\n",
    "df = df.drop(columns=['production_countries'])\n",
    "df['production_companies'] = df.production_companies.apply(get_prod_companies)\n",
    "\n",
    "df['genres'] = df.genres.apply(get_genres)\n",
    "\n",
    "df = df.dropna()\n",
    "enc = LabelEncoder()\n",
    "df['production_companies_int'] = enc.fit_transform(df.production_companies)\n",
    "\n",
    "df['runtime_category'] = df.runtime.apply(discretize_runtime)\n",
    "df['runtime_category_int'] = enc.fit_transform(df.runtime_category)\n",
    "\n",
    "df['budget'] = df.budget.apply(float)\n",
    "df['popularity'] = df.popularity.apply(float)\n",
    "df['id'] = df.id.apply(int)\n",
    "\n",
    "\n",
    "avg = df.vote_average.mean()\n",
    "df['above_average_vote'] = df.vote_average > avg\n",
    "for x in df['genres']:\n",
    "    x.sort()\n",
    "df['genres_int'] = enc.fit_transform(df.genres)\n",
    "df['genres'] = df['genres'].apply(\"_\".join)\n",
    "\n",
    "\n",
    "print(max(df.production_companies_int)+1,'classes for production_companies')\n",
    "print(max(df.genres_int)+1,'classes for genres')\n",
    "\n",
    "print(len(df),'items in processed dataframe\\n')\n",
    "print(list(df))\n",
    "print(df.dtypes)\n",
    "categorical_headers_ints = ['production_companies_int','genres_int','runtime_category_int']\n",
    "numeric_headers = ['budget','popularity','revenue','runtime','vote_average','vote_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25     5.1\n",
      "0.50     6.0\n",
      "0.75     6.7\n",
      "0.90     7.3\n",
      "0.99     8.3\n",
      "1.00    10.0\n",
      "Name: vote_average, dtype: float64\n",
      "22449\n"
     ]
    }
   ],
   "source": [
    "print(df.vote_average.quantile([.25,.5,.75,.9,.99,1]))\n",
    "print(len(df[df.vote_count>0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we work with the Kaggle Movies Dataset. This dataset contains metadata on 45,466 different movies released on or before July 2017. The dataset includes information about each movie such as the budget, the genres, the runtime, the revenue, and popularity scores based on data from the research group GroupLens.\n",
    "\n",
    "In preprocessing the data, we first remove the features we will not be using for classification. Then, we create a few new columns.\n",
    "\n",
    "First, we create a column called made_in_us. This is a modification of the original column production_countries, which contains a list of the countries each movie was produced in. Since there were a large number of such countries, we chose to represent that column as a binary value of if this movie was produced in the United States or in a different country.\n",
    "\n",
    "Next, we create a column called production_companies_int. This is a modification of the original column production_companies, which contains a list of the production companies that created each movie. We take this list of production companies and represent collaborations between multiple production companies as the class \"collaboration\" - we do this because there is a large number of combinations otherwise. Then, we encode the production company as an integer using sklearn's LabelEncoder class.\n",
    "\n",
    "Next, we create a column called genres_int. This is a modification of the original column genres, which contains a list of the genres each movie belongs to. We take this list of genres and encode it using sklearn's LabelEncoder class. In the case that there are multiple genres for a movie, such as a romantic comedy, we represent this combination as its own class, unlike with the production companies. The rationale behind this choice is that there is a much larger number of production companies than genres - we can represent all combinations of genres with 2,970 classes. \n",
    "\n",
    "Next, we create a column called above_average_vote. This is a modification of the original column average_vote, which is the average of all votes given to this movie on a scale of 0-10. This column is the target column; we will try to predict if a movie can score above average.\n",
    "\n",
    "Finally, we create a column called runtime_category_int. This is a modification of the original column runtime, which is the runtime of the movie in minutes. We discretize the runtime into 4 categories: short film, less than feature film, below average feature film, and above average feature film. We use the following cutoffs: a short film is less than 40 minutes, a movie that is less than a feature film is less than 80 minutes, a feature film below average is less than 130 minutes, and a feature film above average is longer than 130 minutes. \n",
    "\n",
    "We derive the runtime of a short film from the rules the Oscar awards establish for the short film category (http://www.oscars.org/sites/oscars/files/90aa_short_films.pdf). We derive the length of a feature film from the Screen Actor's Guild (http://www.sagaftra.org/files/sag/Low_Budget_Ageement_1_5.pdf). We derive the average length of a feature film from a Business Insider study (http://www.businessinsider.com/movies-are-getting-longer-2013-1).\n",
    "\n",
    "We choose to represent the runtime category as categorical data and not ordinal data. The reason we represent runtime categorically instead of ordinally is because different categories of film are not necessarily similar to one another. For example, below average feature films are closer in length to short films than above average feature films are. However, since short films are often not shown in movie theatres, it is likely that there is an entirely different audience for short films than there is for below average length feature films."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crossing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "\n",
    "df_features = ['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', \n",
    "               'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', \n",
    "               'runtime_category', 'runtime_category_int', 'genres_int']\n",
    "df_class = ['above_average_vote']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "## Comparison to MLP\n",
    "\n",
    "\n",
    "precisions_MLP=[]\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    \n",
    "    inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "    # create dense input branch for numeric\n",
    "    inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "    xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "    x = concatenate([xSparse, xDense], name='concat')\n",
    "    predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and Dense layers\n",
    "    model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "              y_train, \n",
    "              epochs=10, \n",
    "              batch_size=50, \n",
    "              verbose=0)\n",
    "\n",
    "    yhat = model.predict([X_test_ohe,\n",
    "                          X_test_num]) # each branch has an input\n",
    "\n",
    "    yhat = np.round(yhat)\n",
    "    precisions_MLP.append(mt.precision_score(y_test,yhat))\n",
    "\n",
    "    \n",
    "\n",
    "print(precisions_MLP)\n",
    "print([x.history['val_precision'][-1] for x in histories1])\n",
    "hist = [x.history['val_precision'][-1] for x in histories1]\n",
    "plt.scatter([x for x in range(1,4)],precisions_MLP, label='MLP')\n",
    "plt.scatter([x for x in range(1,4)], hist,label='Wide & Deep')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    train_list.append(train_index)\n",
    "    test_list.append(test_index)\n",
    "\n",
    "\n",
    "df_train = deepcopy(df.iloc[train_list[0]])\n",
    "df_test = deepcopy(df.iloc[test_list[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONE HOT ENCODING ONLY MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 4572 6013 6017]\n",
      "(20967, 5795)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# now let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "y_train = df_train[df_class].values.astype(np.int)\n",
    "y_test = df_test[df_class].values.astype(np.int)\n",
    "\n",
    "# the ohe instance will help us to organize our encoded matrix\n",
    "print(ohe.feature_indices_)\n",
    "print(X_train_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X_ohe (InputLayer)              (None, 5795)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "X_Numeric (InputLayer)          (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ohe_1 (Dense)                   (None, 10)           57960       X_ohe[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "num_1 (Dense)                   (None, 10)           70          X_Numeric[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 20)           0           ohe_1[0][0]                      \n",
      "                                                                 num_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "combined (Dense)                (None, 1)            21          concat[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 58,051\n",
      "Trainable params: 58,051\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# combine the features with two branches\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "ohe = OneHotEncoder()\n",
    "X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# and save off the numeric features\n",
    "X_train_num =  df_train[numeric_headers].values\n",
    "X_test_num = df_test[numeric_headers].values\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "# create dense input branch for numeric\n",
    "inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "x = concatenate([xSparse, xDense], name='concat')\n",
    "predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and Dense layers\n",
    "model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cell to define precision metric\n",
    "import keras.backend as K\n",
    "#precision metric gotten from previous release of keras\n",
    "#https://github.com/keras-team/keras/commit/a56b1a55182acf061b1eb2e2c86b48193a0e88f7\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[527 381]\n",
      " [764 659]] 0.6336538461538461\n",
      "Wall time: 8.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy', precision])\n",
    "model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "          y_train, \n",
    "          epochs=5, \n",
    "          batch_size=50, \n",
    "          verbose=0)\n",
    "\n",
    "yhat = model.predict([X_test_ohe,\n",
    "                      X_test_num]) # each branch has an input\n",
    "\n",
    "yhat = np.round(yhat)\n",
    "print(mt.confusion_matrix(y_test,yhat),mt.precision_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wide and Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      genres            runtime_category\n",
      "2346                  Horror  Below Average Feature Film\n",
      "2347                  Horror  Below Average Feature Film\n",
      "2350                  Comedy  Below Average Feature Film\n",
      "2352  Horror_Science Fiction  Below Average Feature Film\n",
      "2354  Drama_Mystery_Thriller  Above Average Feature Film\n",
      "                      genres  made_in_us\n",
      "2346                  Horror        True\n",
      "2347                  Horror        True\n",
      "2350                  Comedy        True\n",
      "2352  Horror_Science Fiction        True\n",
      "2354  Drama_Mystery_Thriller       False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                 ['genres','made_in_us']]\n",
    "\n",
    "#'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "# we need to create separate lists for each branch\n",
    "embed_branches = []\n",
    "X_ints_train = []\n",
    "X_ints_test = []\n",
    "all_inputs = []\n",
    "all_wide_branch_outputs = []\n",
    "\n",
    "for cols in cross_columns:\n",
    "    # encode crossed columns as ints for the embedding\n",
    "    enc = LabelEncoder()\n",
    "    \n",
    "    # create crossed labels\n",
    "    print (df_train[cols].head())\n",
    "    X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "    X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "    \n",
    "    enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "    X_crossed_train = enc.transform(X_crossed_train)\n",
    "    X_crossed_test = enc.transform(X_crossed_test)\n",
    "    X_ints_train.append( X_crossed_train )\n",
    "    X_ints_test.append( X_crossed_test )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_wide_branch_outputs.append(x)\n",
    "    \n",
    "# merge the branches together\n",
    "wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "# reset this input branch\n",
    "all_deep_branch_outputs = []\n",
    "# add in the embeddings\n",
    "for col in categorical_headers_ints:\n",
    "    # encode as ints for the embedding\n",
    "    X_ints_train.append( df_train[col].values )\n",
    "    X_ints_test.append( df_test[col].values )\n",
    "    \n",
    "    # get the number of categories\n",
    "    N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "    \n",
    "    # create embedding branch from the number of categories\n",
    "    inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "    all_inputs.append(inputs)\n",
    "    x = Embedding(input_dim=N, \n",
    "                  output_dim=int(np.sqrt(N)), \n",
    "                  input_length=1, name=col+'_embed')(inputs)\n",
    "    x = Flatten()(x)\n",
    "    all_deep_branch_outputs.append(x)\n",
    "    \n",
    "# also get a dense branch of the numeric features\n",
    "all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                        sparse=False,\n",
    "                        name='numeric_data'))\n",
    "\n",
    "x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "# let's encode the integer outputs as one hot encoded labels\n",
    "#ohe = OneHotEncoder()\n",
    "#X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "#X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "# create sparse input branch for ohe\n",
    "#inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "#sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "# merge the deep branches together\n",
    "deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "deep_branch = Dense(units=10,activation='relu', name='deep3')(drop_out_deep)\n",
    "final_branch = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "final_branch = Dense(units=1,activation='sigmoid',name='combined')(final_branch)\n",
    "\n",
    "model = Model(inputs=all_inputs, outputs=final_branch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.2766 - acc: 0.6028 - precision: 0.6273 - val_loss: 0.2995 - val_acc: 0.6323 - val_precision: 0.6198\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.2517 - acc: 0.6532 - precision: 0.6539 - val_loss: 0.2915 - val_acc: 0.6680 - val_precision: 0.6335\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.2146 - acc: 0.7488 - precision: 0.7301 - val_loss: 0.2852 - val_acc: 0.6903 - val_precision: 0.6440\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 68s 3ms/step - loss: 0.1982 - acc: 0.7973 - precision: 0.7797 - val_loss: 0.2813 - val_acc: 0.7027 - val_precision: 0.6495\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 70s 3ms/step - loss: 0.1779 - acc: 0.8298 - precision: 0.8032 - val_loss: 0.2790 - val_acc: 0.7057 - val_precision: 0.6521\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model.compile(optimizer='adagrad',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['accuracy', precision])\n",
    "initial_weights = model.get_weights()\n",
    "# lets also add the history variable to see how we are doing\n",
    "# and lets add a validation set to keep track of our progress\n",
    "history = model.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"848pt\" viewBox=\"0.00 0.00 1138.50 848.00\" width=\"1139pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 844)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-844 1134.5,-844 1134.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 1784421155280 -->\n",
       "<g class=\"node\" id=\"node1\"><title>1784421155280</title>\n",
       "<polygon fill=\"none\" points=\"24,-803.5 24,-839.5 258,-839.5 258,-803.5 24,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-817.8\">production_companies_int: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1784421157800 -->\n",
       "<g class=\"node\" id=\"node4\"><title>1784421157800</title>\n",
       "<polygon fill=\"none\" points=\"0,-730.5 0,-766.5 282,-766.5 282,-730.5 0,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-744.8\">production_companies_int_embed: Embedding</text>\n",
       "</g>\n",
       "<!-- 1784421155280&#45;&gt;1784421157800 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>1784421155280-&gt;1784421157800</title>\n",
       "<path d=\"M141,-803.313C141,-795.289 141,-785.547 141,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"144.5,-776.529 141,-766.529 137.5,-776.529 144.5,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784441214680 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1784441214680</title>\n",
       "<polygon fill=\"none\" points=\"324.5,-803.5 324.5,-839.5 465.5,-839.5 465.5,-803.5 324.5,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-817.8\">genres_int: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1784441232184 -->\n",
       "<g class=\"node\" id=\"node5\"><title>1784441232184</title>\n",
       "<polygon fill=\"none\" points=\"300.5,-730.5 300.5,-766.5 489.5,-766.5 489.5,-730.5 300.5,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-744.8\">genres_int_embed: Embedding</text>\n",
       "</g>\n",
       "<!-- 1784441214680&#45;&gt;1784441232184 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1784441214680-&gt;1784441232184</title>\n",
       "<path d=\"M395,-803.313C395,-795.289 395,-785.547 395,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"398.5,-776.529 395,-766.529 391.5,-776.529 398.5,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784441092080 -->\n",
       "<g class=\"node\" id=\"node3\"><title>1784441092080</title>\n",
       "<polygon fill=\"none\" points=\"532,-803.5 532,-839.5 734,-839.5 734,-803.5 532,-803.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"633\" y=\"-817.8\">runtime_category_int: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1784452764504 -->\n",
       "<g class=\"node\" id=\"node6\"><title>1784452764504</title>\n",
       "<polygon fill=\"none\" points=\"508,-730.5 508,-766.5 758,-766.5 758,-730.5 508,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"633\" y=\"-744.8\">runtime_category_int_embed: Embedding</text>\n",
       "</g>\n",
       "<!-- 1784441092080&#45;&gt;1784452764504 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>1784441092080-&gt;1784452764504</title>\n",
       "<path d=\"M633,-803.313C633,-795.289 633,-785.547 633,-776.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"636.5,-776.529 633,-766.529 629.5,-776.529 636.5,-776.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784441160984 -->\n",
       "<g class=\"node\" id=\"node8\"><title>1784441160984</title>\n",
       "<polygon fill=\"none\" points=\"167,-657.5 167,-693.5 283,-693.5 283,-657.5 167,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"225\" y=\"-671.8\">flatten_33: Flatten</text>\n",
       "</g>\n",
       "<!-- 1784421157800&#45;&gt;1784441160984 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>1784421157800-&gt;1784441160984</title>\n",
       "<path d=\"M161.334,-730.313C172.065,-721.243 185.394,-709.977 197.078,-700.1\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"199.475,-702.657 204.853,-693.529 194.956,-697.311 199.475,-702.657\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784441232072 -->\n",
       "<g class=\"node\" id=\"node9\"><title>1784441232072</title>\n",
       "<polygon fill=\"none\" points=\"361,-657.5 361,-693.5 477,-693.5 477,-657.5 361,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"419\" y=\"-671.8\">flatten_34: Flatten</text>\n",
       "</g>\n",
       "<!-- 1784441232184&#45;&gt;1784441232072 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1784441232184-&gt;1784441232072</title>\n",
       "<path d=\"M400.81,-730.313C403.551,-722.202 406.887,-712.336 409.949,-703.277\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"413.357,-704.123 413.244,-693.529 406.726,-701.881 413.357,-704.123\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784452767024 -->\n",
       "<g class=\"node\" id=\"node10\"><title>1784452767024</title>\n",
       "<polygon fill=\"none\" points=\"543,-657.5 543,-693.5 659,-693.5 659,-657.5 543,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"601\" y=\"-671.8\">flatten_35: Flatten</text>\n",
       "</g>\n",
       "<!-- 1784452764504&#45;&gt;1784452767024 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>1784452764504-&gt;1784452767024</title>\n",
       "<path d=\"M625.254,-730.313C621.52,-722.028 616.96,-711.91 612.805,-702.693\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"615.975,-701.207 608.675,-693.529 609.593,-704.084 615.975,-701.207\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784420961920 -->\n",
       "<g class=\"node\" id=\"node7\"><title>1784420961920</title>\n",
       "<polygon fill=\"none\" points=\"776.5,-730.5 776.5,-766.5 935.5,-766.5 935.5,-730.5 776.5,-730.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"856\" y=\"-744.8\">numeric_data: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1784421157744 -->\n",
       "<g class=\"node\" id=\"node11\"><title>1784421157744</title>\n",
       "<polygon fill=\"none\" points=\"773,-657.5 773,-693.5 889,-693.5 889,-657.5 773,-657.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"831\" y=\"-671.8\">numeric_1: Dense</text>\n",
       "</g>\n",
       "<!-- 1784420961920&#45;&gt;1784421157744 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>1784420961920-&gt;1784421157744</title>\n",
       "<path d=\"M849.948,-730.313C847.062,-722.115 843.543,-712.123 840.326,-702.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"843.619,-701.799 836.996,-693.529 837.016,-704.124 843.619,-701.799\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784421684336 -->\n",
       "<g class=\"node\" id=\"node12\"><title>1784421684336</title>\n",
       "<polygon fill=\"none\" points=\"419.5,-584.5 419.5,-620.5 600.5,-620.5 600.5,-584.5 419.5,-584.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-598.8\">concat_embeds: Concatenate</text>\n",
       "</g>\n",
       "<!-- 1784441160984&#45;&gt;1784421684336 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>1784441160984-&gt;1784421684336</title>\n",
       "<path d=\"M283.018,-660.047C325.866,-649.372 384.665,-634.724 431.681,-623.011\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"432.667,-626.372 441.524,-620.559 430.975,-619.58 432.667,-626.372\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784441232072&#45;&gt;1784421684336 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>1784441232072-&gt;1784421684336</title>\n",
       "<path d=\"M441.029,-657.313C452.765,-648.156 467.371,-636.76 480.116,-626.816\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"482.443,-629.44 488.174,-620.529 478.137,-623.921 482.443,-629.44\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784452767024&#45;&gt;1784421684336 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>1784452767024-&gt;1784421684336</title>\n",
       "<path d=\"M578.971,-657.313C567.235,-648.156 552.629,-636.76 539.884,-626.816\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"541.863,-623.921 531.826,-620.529 537.557,-629.44 541.863,-623.921\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784421157744&#45;&gt;1784421684336 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>1784421157744-&gt;1784421684336</title>\n",
       "<path d=\"M772.869,-661.642C723.783,-650.785 652.773,-635.079 596.928,-622.727\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"597.561,-619.282 587.041,-620.54 596.049,-626.117 597.561,-619.282\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784421683328 -->\n",
       "<g class=\"node\" id=\"node13\"><title>1784421683328</title>\n",
       "<polygon fill=\"none\" points=\"441.5,-511.5 441.5,-547.5 578.5,-547.5 578.5,-511.5 441.5,-511.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-525.8\">dropout_13: Dropout</text>\n",
       "</g>\n",
       "<!-- 1784421684336&#45;&gt;1784421683328 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>1784421684336-&gt;1784421683328</title>\n",
       "<path d=\"M510,-584.313C510,-576.289 510,-566.547 510,-557.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"513.5,-557.529 510,-547.529 506.5,-557.529 513.5,-557.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784453018064 -->\n",
       "<g class=\"node\" id=\"node16\"><title>1784453018064</title>\n",
       "<polygon fill=\"none\" points=\"464,-438.5 464,-474.5 556,-474.5 556,-438.5 464,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-452.8\">deep1: Dense</text>\n",
       "</g>\n",
       "<!-- 1784421683328&#45;&gt;1784453018064 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>1784421683328-&gt;1784453018064</title>\n",
       "<path d=\"M510,-511.313C510,-503.289 510,-493.547 510,-484.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"513.5,-484.529 510,-474.529 506.5,-484.529 513.5,-484.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784451212008 -->\n",
       "<g class=\"node\" id=\"node14\"><title>1784451212008</title>\n",
       "<polygon fill=\"none\" points=\"621,-438.5 621,-474.5 845,-474.5 845,-438.5 621,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-452.8\">genres_runtime_category: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1784452754792 -->\n",
       "<g class=\"node\" id=\"node17\"><title>1784452754792</title>\n",
       "<polygon fill=\"none\" points=\"597,-365.5 597,-401.5 869,-401.5 869,-365.5 597,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-379.8\">genres_runtime_category_embed: Embedding</text>\n",
       "</g>\n",
       "<!-- 1784451212008&#45;&gt;1784452754792 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>1784451212008-&gt;1784452754792</title>\n",
       "<path d=\"M733,-438.313C733,-430.289 733,-420.547 733,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"736.5,-411.529 733,-401.529 729.5,-411.529 736.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784398402952 -->\n",
       "<g class=\"node\" id=\"node15\"><title>1784398402952</title>\n",
       "<polygon fill=\"none\" points=\"911.5,-438.5 911.5,-474.5 1106.5,-474.5 1106.5,-438.5 911.5,-438.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1009\" y=\"-452.8\">genres_made_in_us: InputLayer</text>\n",
       "</g>\n",
       "<!-- 1784450284008 -->\n",
       "<g class=\"node\" id=\"node18\"><title>1784450284008</title>\n",
       "<polygon fill=\"none\" points=\"887.5,-365.5 887.5,-401.5 1130.5,-401.5 1130.5,-365.5 887.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1009\" y=\"-379.8\">genres_made_in_us_embed: Embedding</text>\n",
       "</g>\n",
       "<!-- 1784398402952&#45;&gt;1784450284008 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>1784398402952-&gt;1784450284008</title>\n",
       "<path d=\"M1009,-438.313C1009,-430.289 1009,-420.547 1009,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1012.5,-411.529 1009,-401.529 1005.5,-411.529 1012.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784421350144 -->\n",
       "<g class=\"node\" id=\"node19\"><title>1784421350144</title>\n",
       "<polygon fill=\"none\" points=\"441.5,-365.5 441.5,-401.5 578.5,-401.5 578.5,-365.5 441.5,-365.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"510\" y=\"-379.8\">dropout_14: Dropout</text>\n",
       "</g>\n",
       "<!-- 1784453018064&#45;&gt;1784421350144 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>1784453018064-&gt;1784421350144</title>\n",
       "<path d=\"M510,-438.313C510,-430.289 510,-420.547 510,-411.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"513.5,-411.529 510,-401.529 506.5,-411.529 513.5,-411.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784452755184 -->\n",
       "<g class=\"node\" id=\"node20\"><title>1784452755184</title>\n",
       "<polygon fill=\"none\" points=\"675,-292.5 675,-328.5 791,-328.5 791,-292.5 675,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-306.8\">flatten_31: Flatten</text>\n",
       "</g>\n",
       "<!-- 1784452754792&#45;&gt;1784452755184 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>1784452754792-&gt;1784452755184</title>\n",
       "<path d=\"M733,-365.313C733,-357.289 733,-347.547 733,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"736.5,-338.529 733,-328.529 729.5,-338.529 736.5,-338.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784450283000 -->\n",
       "<g class=\"node\" id=\"node21\"><title>1784450283000</title>\n",
       "<polygon fill=\"none\" points=\"880,-292.5 880,-328.5 996,-328.5 996,-292.5 880,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"938\" y=\"-306.8\">flatten_32: Flatten</text>\n",
       "</g>\n",
       "<!-- 1784450284008&#45;&gt;1784450283000 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>1784450284008-&gt;1784450283000</title>\n",
       "<path d=\"M991.813,-365.313C982.917,-356.417 971.909,-345.409 962.172,-335.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"964.575,-333.125 955.029,-328.529 959.625,-338.075 964.575,-333.125\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784421343584 -->\n",
       "<g class=\"node\" id=\"node22\"><title>1784421343584</title>\n",
       "<polygon fill=\"none\" points=\"478,-292.5 478,-328.5 570,-328.5 570,-292.5 478,-292.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-306.8\">deep2: Dense</text>\n",
       "</g>\n",
       "<!-- 1784421350144&#45;&gt;1784421343584 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>1784421350144-&gt;1784421343584</title>\n",
       "<path d=\"M513.389,-365.313C514.971,-357.289 516.892,-347.547 518.662,-338.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"522.141,-339.017 520.642,-328.529 515.274,-337.663 522.141,-339.017\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784452753560 -->\n",
       "<g class=\"node\" id=\"node23\"><title>1784452753560</title>\n",
       "<polygon fill=\"none\" points=\"651,-219.5 651,-255.5 815,-255.5 815,-219.5 651,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"733\" y=\"-233.8\">wide_concat: Concatenate</text>\n",
       "</g>\n",
       "<!-- 1784452755184&#45;&gt;1784452753560 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>1784452755184-&gt;1784452753560</title>\n",
       "<path d=\"M733,-292.313C733,-284.289 733,-274.547 733,-265.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"736.5,-265.529 733,-255.529 729.5,-265.529 736.5,-265.529\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784450283000&#45;&gt;1784452753560 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>1784450283000-&gt;1784452753560</title>\n",
       "<path d=\"M888.897,-292.494C859.825,-282.425 822.801,-269.602 792.129,-258.979\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"793.007,-255.579 782.412,-255.614 790.716,-262.194 793.007,-255.579\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784421367704 -->\n",
       "<g class=\"node\" id=\"node24\"><title>1784421367704</title>\n",
       "<polygon fill=\"none\" points=\"482.5,-219.5 482.5,-255.5 619.5,-255.5 619.5,-219.5 482.5,-219.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"551\" y=\"-233.8\">dropout_15: Dropout</text>\n",
       "</g>\n",
       "<!-- 1784421343584&#45;&gt;1784421367704 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>1784421343584-&gt;1784421367704</title>\n",
       "<path d=\"M530.536,-292.313C533.653,-284.115 537.453,-274.123 540.928,-264.985\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"544.241,-266.12 544.524,-255.529 537.698,-263.632 544.241,-266.12\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784452751432 -->\n",
       "<g class=\"node\" id=\"node25\"><title>1784452751432</title>\n",
       "<polygon fill=\"none\" points=\"648.5,-146.5 648.5,-182.5 795.5,-182.5 795.5,-146.5 648.5,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"722\" y=\"-160.8\">wide_combined: Dense</text>\n",
       "</g>\n",
       "<!-- 1784452753560&#45;&gt;1784452751432 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>1784452753560-&gt;1784452751432</title>\n",
       "<path d=\"M730.337,-219.313C729.094,-211.289 727.585,-201.547 726.194,-192.569\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"729.628,-191.875 724.638,-182.529 722.711,-192.947 729.628,-191.875\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784442018896 -->\n",
       "<g class=\"node\" id=\"node26\"><title>1784442018896</title>\n",
       "<polygon fill=\"none\" points=\"527,-146.5 527,-182.5 619,-182.5 619,-146.5 527,-146.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"573\" y=\"-160.8\">deep3: Dense</text>\n",
       "</g>\n",
       "<!-- 1784421367704&#45;&gt;1784442018896 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>1784421367704-&gt;1784442018896</title>\n",
       "<path d=\"M556.326,-219.313C558.839,-211.202 561.896,-201.336 564.703,-192.277\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"568.107,-193.117 567.723,-182.529 561.42,-191.045 568.107,-193.117\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784441578720 -->\n",
       "<g class=\"node\" id=\"node27\"><title>1784441578720</title>\n",
       "<polygon fill=\"none\" points=\"548,-73.5 548,-109.5 746,-109.5 746,-73.5 548,-73.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"647\" y=\"-87.8\">concat_deep_wide: Concatenate</text>\n",
       "</g>\n",
       "<!-- 1784452751432&#45;&gt;1784441578720 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>1784452751432-&gt;1784441578720</title>\n",
       "<path d=\"M703.845,-146.313C694.448,-137.417 682.82,-126.409 672.533,-116.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"674.656,-113.862 664.988,-109.529 669.844,-118.945 674.656,-113.862\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784442018896&#45;&gt;1784441578720 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>1784442018896-&gt;1784441578720</title>\n",
       "<path d=\"M590.913,-146.313C600.185,-137.417 611.658,-126.409 621.807,-116.672\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"624.459,-118.978 629.252,-109.529 619.613,-113.927 624.459,-118.978\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 1784442096664 -->\n",
       "<g class=\"node\" id=\"node28\"><title>1784442096664</title>\n",
       "<polygon fill=\"none\" points=\"590.5,-0.5 590.5,-36.5 703.5,-36.5 703.5,-0.5 590.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"647\" y=\"-14.8\">combined: Dense</text>\n",
       "</g>\n",
       "<!-- 1784441578720&#45;&gt;1784442096664 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>1784441578720-&gt;1784442096664</title>\n",
       "<path d=\"M647,-73.3129C647,-65.2895 647,-55.5475 647,-46.5691\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"650.5,-46.5288 647,-36.5288 643.5,-46.5289 650.5,-46.5288\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 273  635]\n",
      " [  51 1372]] 0.6836073741903338\n"
     ]
    }
   ],
   "source": [
    "yhat = np.round(model.predict(X_ints_test + [X_test_num]))\n",
    "print(mt.confusion_matrix(y_test,yhat), mt.precision_score(y_test,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epochs')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a464f9d6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history.history['precision'])\n",
    "\n",
    "plt.ylabel('Precision %')\n",
    "plt.title('Training')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history.history['val_precision'])\n",
    "plt.title('Validation')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preprocessing, we create cross-product features for the wide part of our wide-and-deep network. We cross the values for genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "\n",
    "We decide to cross the values for genres_int and runtime_category_int because films of different genres often have different lengths. For example, action movies have an average runtime of 100.46 minutes, whereas animation movies have an average runtime of 61.04 minutes. Thus, we speculate that a long animation movie will have a different reaction than a long action movie.\n",
    "\n",
    "Next, we cross the values for genres_int and made_in_us int. We base this feature cross on the idea that different countries may prefer different genres of movie. This hypothesis is supported by independent research from the New York Film Academy (https://www.nyfa.edu/student-resources/12-of-the-most-popular-movie-genres-by-country/) and the American Film Market & Conferences association (http://americanfilmmarket.com/relative-popularity-genres-around-world/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our chosen task is a binary classification task: can we predict if a movie will score above or below average when rated by users on a scale of 0-10? We found in our data set that the average of the ~22,000 movies reviewed is a 6.0/10; therefore, a movie that scores above 6.0 is above average, any a movie scoring 6.0 or less is not.\n",
    "\n",
    "The business case for our prediction task is a movie studio trying to determine if their next movie will score above average or not. We imagine that a movie studio would come to us for our analysis after defining the basic criteria for their movie, such as genre, budget, and approximate runtime. At this point in the production cycle, the firm has not yet invested large amounts of time or money into creating the movie outline. Thus, the movie studio would much rather us reject a good idea than accept a bad idea; a rejected good idea is a waste of the small amount of time put into creating a movie outline, but an accepted bad idea will waste future resources as well as the outline time.\n",
    "\n",
    "With this use case in mind, we advance precision as our chosen evaluation criteria. Precision, mathematically defined as tp/(tp+fp), is a measure of what percentage of named positives are true positives. In our use case, a precision score of 30% means that, of the movies we said would do better than average, only 30% actually did better than average.\n",
    "\n",
    "The movie studio would be interested in a high-precision system because this system is good at telling if a movie will be above average. A 90% precision score means that 9 out of 10 movies that we say will succeed do in fact succeed; this goves the movie studio an idea of how likely it is that their movie is a winner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab, we will use a 10-fold stratified cross-validation approach for splitting our data into training and testing sets. The reason we use cross-validation instead of shuffle-split is that we worry we do not have enough data. After pre-processing, we are left with ~22,000 movies. This is not an entirely small dataset; however, the feature space is quite large. For example, the movie genre alone can take on 2,970 different values, and the production company 4,572 values. We use 10-folds so that 90% of our data comprises the training set in each fold; this will ensure to the best of our ability that we have enough data.\n",
    "\n",
    "The reason we use stratified cross-validation is to preserve the class distributions seen in the data; if one class of a feature occurs 10% of the time in the data, it will occur 10% of the time in the training data and 10% of the time in the testing data. We use stratified cross-validation because our data represent the real-world distribution. When applied to real movies, it will also be true that there is large class imbalance in certain features; it is unlikely that in the future a dramatically different percentage of the market will be dominated by Animated-Romantic-Action-Adult films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 68s 3ms/step - loss: 0.3539 - acc: 0.5768 - precision: 0.6860 - val_loss: 0.4799 - val_acc: 0.4951 - val_precision: 0.6549\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.3195 - acc: 0.6275 - precision: 0.7538 - val_loss: 0.4730 - val_acc: 0.5071 - val_precision: 0.6732\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 70s 3ms/step - loss: 0.2914 - acc: 0.6748 - precision: 0.8059 - val_loss: 0.2779 - val_acc: 0.7040 - val_precision: 0.6737\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 71s 3ms/step - loss: 0.2141 - acc: 0.7639 - precision: 0.8231 - val_loss: 0.3477 - val_acc: 0.6255 - val_precision: 0.6846\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 67s 3ms/step - loss: 0.2345 - acc: 0.7530 - precision: 0.8620 - val_loss: 0.4687 - val_acc: 0.5127 - val_precision: 0.7234\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 69s 3ms/step - loss: 0.2537 - acc: 0.6763 - precision: 0.6886 - val_loss: 0.2690 - val_acc: 0.6697 - val_precision: 0.6114\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2096 - acc: 0.7428 - precision: 0.7356 - val_loss: 0.2590 - val_acc: 0.6903 - val_precision: 0.61200.2099 - a\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1825 - acc: 0.7914 - precision: 0.7723 - val_loss: 0.2551 - val_acc: 0.6933 - val_precision: 0.6123\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.1632 - acc: 0.8251 - precision: 0.7988 - val_loss: 0.2493 - val_acc: 0.7100 - val_precision: 0.6128\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.1514 - acc: 0.8446 - precision: 0.8149 - val_loss: 0.2504 - val_acc: 0.7147 - val_precision: 0.6132\n",
      "Testing on 3 split\n",
      "Train on 20968 samples, validate on 2330 samples\n",
      "Epoch 1/5\n",
      "20968/20968 [==============================] - 63s 3ms/step - loss: 0.2988 - acc: 0.6253 - precision: 0.6839 - val_loss: 0.2052 - val_acc: 0.7549 - val_precision: 0.6112\n",
      "Epoch 2/5\n",
      "20968/20968 [==============================] - 61s 3ms/step - loss: 0.2437 - acc: 0.7037 - precision: 0.7424 - val_loss: 0.2056 - val_acc: 0.7670 - val_precision: 0.6104\n",
      "Epoch 3/5\n",
      "20968/20968 [==============================] - 63s 3ms/step - loss: 0.2165 - acc: 0.7515 - precision: 0.7649 - val_loss: 0.1876 - val_acc: 0.7863 - val_precision: 0.6109\n",
      "Epoch 4/5\n",
      "20968/20968 [==============================] - 62s 3ms/step - loss: 0.1949 - acc: 0.7885 - precision: 0.7919 - val_loss: 0.1852 - val_acc: 0.7893 - val_precision: 0.6109\n",
      "Epoch 5/5\n",
      "20968/20968 [==============================] - 62s 3ms/step - loss: 0.2014 - acc: 0.7912 - precision: 0.8149 - val_loss: 0.1816 - val_acc: 0.7910 - val_precision: 0.6109\n"
     ]
    }
   ],
   "source": [
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "for train,test in zip(train_list[0:5:2],test_list[0:5:2]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.2675 - acc: 0.6317 - precision: 0.6487 - val_loss: 0.2930 - val_acc: 0.6461 - val_precision: 0.6268\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.2375 - acc: 0.6912 - precision: 0.6898 - val_loss: 0.2895 - val_acc: 0.6607 - val_precision: 0.6308\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1993 - acc: 0.7687 - precision: 0.7540 - val_loss: 0.2834 - val_acc: 0.6808 - val_precision: 0.6366\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 59s 3ms/step - loss: 0.1775 - acc: 0.8164 - precision: 0.7976 - val_loss: 0.2778 - val_acc: 0.7036 - val_precision: 0.6479\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1656 - acc: 0.8363 - precision: 0.8187 - val_loss: 0.2733 - val_acc: 0.7181 - val_precision: 0.6537\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 64s 3ms/step - loss: 0.2571 - acc: 0.5922 - precision: 0.6662 - val_loss: 0.2494 - val_acc: 0.6491 - val_precision: 0.6125\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.2186 - acc: 0.6907 - precision: 0.7237 - val_loss: 0.2418 - val_acc: 0.6474 - val_precision: 0.6139\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.1729 - acc: 0.8435 - precision: 0.8430 - val_loss: 0.2377 - val_acc: 0.6529 - val_precision: 0.6134\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.1423 - acc: 0.8972 - precision: 0.8874 - val_loss: 0.2359 - val_acc: 0.6645 - val_precision: 0.6145\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.1301 - acc: 0.9179 - precision: 0.9022 - val_loss: 0.2348 - val_acc: 0.6701 - val_precision: 0.6145\n",
      "Testing on 3 split\n",
      "Train on 20968 samples, validate on 2330 samples\n",
      "Epoch 1/5\n",
      "20968/20968 [==============================] - 63s 3ms/step - loss: 0.2686 - acc: 0.6318 - precision: 0.6510 - val_loss: 0.2280 - val_acc: 0.6957 - val_precision: 0.6107\n",
      "Epoch 2/5\n",
      "20968/20968 [==============================] - 62s 3ms/step - loss: 0.2421 - acc: 0.7087 - precision: 0.7158 - val_loss: 0.2054 - val_acc: 0.7588 - val_precision: 0.6112\n",
      "Epoch 3/5\n",
      "20968/20968 [==============================] - 63s 3ms/step - loss: 0.1986 - acc: 0.7851 - precision: 0.7747 - val_loss: 0.1976 - val_acc: 0.7734 - val_precision: 0.6106\n",
      "Epoch 4/5\n",
      "20968/20968 [==============================] - 65s 3ms/step - loss: 0.1724 - acc: 0.8267 - precision: 0.8041 - val_loss: 0.1922 - val_acc: 0.7807 - val_precision: 0.6103\n",
      "Epoch 5/5\n",
      "20968/20968 [==============================] - 65s 3ms/step - loss: 0.1612 - acc: 0.8435 - precision: 0.8204 - val_loss: 0.1896 - val_acc: 0.7833 - val_precision: 0.6108\n"
     ]
    }
   ],
   "source": [
    "for train,test in zip(train_list[0:5:2],test_list[0:5:2]):\n",
    "    print(\"Testing on\", len(histories2)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=10,activation='relu', name='deep3')(drop_out_deep)\n",
    "\n",
    "    final_branch2 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch2 = Dense(units=1,activation='sigmoid',name='combined')(final_branch2)\n",
    "\n",
    "    model2 = Model(inputs=all_inputs, outputs=final_branch2)\n",
    "    model2.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history2 = model2.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories2.append(history2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6491572519553537 0.6263475307205343\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "precisions1 = [x.history['val_precision'][-1] for x in histories1]\n",
    "precisions2 = [x.history['val_precision'][-1] for x in histories2]\n",
    "\n",
    "print(np.mean(precisions1), np.mean(precisions2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Precision %')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2a444f20908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([x for x in range(1,4)], precisions1, label='Network 1')\n",
    "plt.scatter([x for x in range(1,4)], precisions2,label='Network 2')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that on average, our first and second network perform very closely to one another, although Network 2 seems to be more consistent over the first 3 folds we validated on. In the block below, we look at the average precision based on every epoch and training/test fold. Since each epoch is expensive, that average could give us insight as to which network would perform better without much training. We could not afford to run 3 epochs on all 10 KFolds as it was a very expensive operation and we do not own the hardware needed to  We see that Network 1 performed better overall and decide to use as our "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6350410277963655 0.621217282277813\n"
     ]
    }
   ],
   "source": [
    "precisions1 = [x.history['val_precision'] for x in histories1]\n",
    "precisions2 = [x.history['val_precision'] for x in histories2]\n",
    "\n",
    "print(np.mean(precisions1), np.mean(precisions2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precisions_MLP=[]\n",
    "for train,test in zip(train_list[0:3],test_list[0:3]):\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    \n",
    "    inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    xSparse = Dense(units=10, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "    # create dense input branch for numeric\n",
    "    inputsDense = Input(shape=(X_train_num.shape[1],),sparse=False, name='X_Numeric')\n",
    "    xDense = Dense(units=10, activation='relu',name='num_1')(inputsDense)\n",
    "\n",
    "    x = concatenate([xSparse, xDense], name='concat')\n",
    "    predictions = Dense(1,activation='sigmoid', name='combined')(x)\n",
    "\n",
    "    # This creates a model that includes\n",
    "    # the Input layer and Dense layers\n",
    "    model = Model(inputs=[inputsSparse,inputsDense], outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer='sgd',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    model.fit([ X_train_ohe, X_train_num ], # inputs for each branch are a list\n",
    "              y_train, \n",
    "              epochs=10, \n",
    "              batch_size=50, \n",
    "              verbose=0)\n",
    "\n",
    "    yhat = model.predict([X_test_ohe,\n",
    "                          X_test_num]) # each branch has an input\n",
    "\n",
    "    yhat = np.round(yhat)\n",
    "    precisions_MLP.append(mt.precision_score(y_test,yhat))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5954598370197904, 0.6433301797540208, 0.6727722772277228]\n",
      "[0.6589720079899857, 0.6187309109054886, 0.6123887859460675]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Precision %')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2325a8cbf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(precisions_MLP)\n",
    "print([x.history['val_precision'][-1] for x in histories1])\n",
    "hist = [x.history['val_precision'][-1] for x in histories1]\n",
    "plt.scatter([x for x in range(1,4)],precisions_MLP, label='MLP')\n",
    "plt.scatter([x for x in range(1,4)], hist,label='Wide & Deep')\n",
    "plt.legend()\n",
    "plt.xlabel('Fold number')\n",
    "plt.ylabel('Precision %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "df_features = ['budget', 'genres', 'id', 'popularity', 'production_companies', 'revenue', \n",
    "               'runtime', 'title', 'vote_average', 'vote_count', 'made_in_us', 'production_companies_int', \n",
    "               'runtime_category', 'runtime_category_int', 'genres_int']\n",
    "df_class = ['above_average_vote']\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10)\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "train_list = []\n",
    "test_list = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    train_list.append(train_index)\n",
    "    test_list.append(test_index)\n",
    "\n",
    "df_train = deepcopy(df.iloc[train_list[0]])\n",
    "df_test = deepcopy(df.iloc[test_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 67s 3ms/step - loss: 0.6105 - acc: 0.3895 - precision: 0.0015 - val_loss: 0.6102 - val_acc: 0.3895 - val_precision: 0.0000e+00\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 61s 3ms/step - loss: 0.6105 - acc: 0.3895 - precision: 0.0015 - val_loss: 0.6102 - val_acc: 0.3895 - val_precision: 0.0000e+00\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.6104 - acc: 0.3896 - precision: 0.0061 - val_loss: 0.6102 - val_acc: 0.3895 - val_precision: 0.0000e+00\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.6104 - acc: 0.3896 - precision: 0.0031 - val_loss: 0.6102 - val_acc: 0.3895 - val_precision: 0.0000e+00\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.6106 - acc: 0.3894 - precision: 0.0015 - val_loss: 0.6102 - val_acc: 0.3895 - val_precision: 0.0000e+00\n",
      "Testing on 2 split\n",
      "Train on 20967 samples, validate on 2331 samples\n",
      "Epoch 1/5\n",
      "20967/20967 [==============================] - 67s 3ms/step - loss: 0.3904 - acc: 0.6096 - precision: 0.6105 - val_loss: 0.3825 - val_acc: 0.6105 - val_precision: 0.6105\n",
      "Epoch 2/5\n",
      "20967/20967 [==============================] - 63s 3ms/step - loss: 0.3903 - acc: 0.6097 - precision: 0.6105 - val_loss: 0.3825 - val_acc: 0.6105 - val_precision: 0.6105\n",
      "Epoch 3/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.3901 - acc: 0.6099 - precision: 0.6108 - val_loss: 0.3825 - val_acc: 0.6105 - val_precision: 0.6105\n",
      "Epoch 4/5\n",
      "20967/20967 [==============================] - 62s 3ms/step - loss: 0.3909 - acc: 0.6091 - precision: 0.6104 - val_loss: 0.3825 - val_acc: 0.6105 - val_precision: 0.6105\n",
      "Epoch 5/5\n",
      "20967/20967 [==============================] - 65s 3ms/step - loss: 0.3905 - acc: 0.6095 - precision: 0.6104 - val_loss: 0.3825 - val_acc: 0.6105 - val_precision: 0.6105\n",
      "Testing on 3 split\n",
      "Train on 20968 samples, validate on 2330 samples\n",
      "Epoch 1/5\n",
      "20968/20968 [==============================] - 66s 3ms/step - loss: 0.6101 - acc: 0.3899 - precision: 0.0259 - val_loss: 0.6106 - val_acc: 0.3897 - val_precision: 0.0000e+00\n",
      "Epoch 2/5\n",
      "20968/20968 [==============================] - 64s 3ms/step - loss: 0.6107 - acc: 0.3893 - precision: 0.0114 - val_loss: 0.6106 - val_acc: 0.3897 - val_precision: 0.0000e+00\n",
      "Epoch 3/5\n",
      "20968/20968 [==============================] - 64s 3ms/step - loss: 0.6054 - acc: 0.3946 - precision: 0.1169 - val_loss: 0.6080 - val_acc: 0.3897 - val_precision: 0.0000e+00\n",
      "Epoch 4/5\n",
      "20968/20968 [==============================] - 71s 3ms/step - loss: 0.5338 - acc: 0.4662 - precision: 0.5982 - val_loss: 0.3753 - val_acc: 0.4691 - val_precision: 0.6094\n",
      "Epoch 5/5\n",
      "20968/20968 [==============================] - 69s 3ms/step - loss: 0.4011 - acc: 0.5989 - precision: 0.6117 - val_loss: 0.3753 - val_acc: 0.4691 - val_precision: 0.6094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#genres_int and runtime_category_int, as well as the values for genres_int and made_in_us_int.\n",
    "cross_columns = [['genres','runtime_category'],\n",
    "                     ['genres','made_in_us']]\n",
    "\n",
    "X = df[df_features]\n",
    "y = df[df_class]\n",
    "histories1=[]\n",
    "histories2=[]\n",
    "\n",
    "for train,test in zip(train_list[0:5:2],test_list[0:5:2]):\n",
    "    print(\"Testing on\", len(histories1)+1, \"split\")\n",
    "    df_train = deepcopy(df.iloc[train])\n",
    "    \n",
    "    for col in numeric_headers:\n",
    "        col_vals = df_train[col]\n",
    "        std = np.std(col_vals)\n",
    "        random.seed(1)\n",
    "        df_train[col] = col_vals.apply(lambda x: x + (random.random() * .5 * std))\n",
    "    \n",
    "    df_test = deepcopy(df.iloc[test])\n",
    "    ohe = OneHotEncoder()\n",
    "    X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    y_train = df_train[df_class].values.astype(np.int)\n",
    "    y_test = df_test[df_class].values.astype(np.int)\n",
    "    # and save off the numeric features\n",
    "    X_train_num =  df_train[numeric_headers].values\n",
    "    X_test_num = df_test[numeric_headers].values\n",
    "    #'workclass','education','marital_status','occupation','relationship','race','sex','country'\n",
    "\n",
    "    # we need to create separate lists for each branch\n",
    "    embed_branches = []\n",
    "    X_ints_train = []\n",
    "    X_ints_test = []\n",
    "    all_inputs = []\n",
    "    all_wide_branch_outputs = []\n",
    "\n",
    "    for cols in cross_columns:\n",
    "        # encode crossed columns as ints for the embedding\n",
    "        enc = LabelEncoder()\n",
    "\n",
    "        # create crossed labels\n",
    "        X_crossed_train = df_train[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "        X_crossed_test = df_test[cols].apply(lambda x: '_'.join(str(x)), axis=1)\n",
    "\n",
    "        enc.fit(np.hstack((X_crossed_train.values,  X_crossed_test.values)))\n",
    "        X_crossed_train = enc.transform(X_crossed_train)\n",
    "        X_crossed_test = enc.transform(X_crossed_test)\n",
    "        X_ints_train.append( X_crossed_train )\n",
    "        X_ints_test.append( X_crossed_test )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name = '_'.join(cols))\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name = '_'.join(cols)+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_wide_branch_outputs.append(x)\n",
    "\n",
    "    # merge the branches together\n",
    "    wide_branch = concatenate(all_wide_branch_outputs, name='wide_concat')\n",
    "    wide_branch = Dense(units=1,activation='sigmoid',name='wide_combined')(wide_branch)\n",
    "\n",
    "    # reset this input branch\n",
    "    all_deep_branch_outputs = []\n",
    "    # add in the embeddings\n",
    "    for col in categorical_headers_ints:\n",
    "        # encode as ints for the embedding\n",
    "        X_ints_train.append( df_train[col].values )\n",
    "        X_ints_test.append( df_test[col].values )\n",
    "\n",
    "        # get the number of categories\n",
    "        N = max(X_ints_train[-1]+1) # same as the max(df_train[col])\n",
    "\n",
    "        # create embedding branch from the number of categories\n",
    "        inputs = Input(shape=(1,),dtype='int32', name=col)\n",
    "        all_inputs.append(inputs)\n",
    "        x = Embedding(input_dim=N, \n",
    "                      output_dim=int(np.sqrt(N)), \n",
    "                      input_length=1, name=col+'_embed')(inputs)\n",
    "        x = Flatten()(x)\n",
    "        all_deep_branch_outputs.append(x)\n",
    "\n",
    "    # also get a dense branch of the numeric features\n",
    "    all_inputs.append(Input(shape=(X_train_num.shape[1],),\n",
    "                            sparse=False,\n",
    "                            name='numeric_data'))\n",
    "\n",
    "    x = Dense(units=20, activation='relu',name='numeric_1')(all_inputs[-1])\n",
    "    all_deep_branch_outputs.append( x )\n",
    "\n",
    "\n",
    "    # let's encode the integer outputs as one hot encoded labels\n",
    "    #ohe = OneHotEncoder()\n",
    "    #X_train_ohe = ohe.fit_transform(df_train[categorical_headers_ints].values)\n",
    "    #X_test_ohe = ohe.transform(df_test[categorical_headers_ints].values)\n",
    "\n",
    "    # create sparse input branch for ohe\n",
    "    #inputsSparse = Input(shape=(X_train_ohe.shape[1],),sparse=True, name='X_ohe')\n",
    "    #sparse_branch = Dense(units=20, activation='relu', name='ohe_1')(inputsSparse)\n",
    "\n",
    "\n",
    "    # merge the deep branches together\n",
    "    deep_branch = concatenate(all_deep_branch_outputs,name='concat_embeds')\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=50,activation='relu', name='deep1')(drop_out_deep)\n",
    "    drop_out_deep = Dropout(0.10)(deep_branch) \n",
    "    deep_branch = Dense(units=25,activation='relu', name='deep2')(drop_out_deep)\n",
    "    final_branch1 = concatenate([wide_branch, deep_branch],name='concat_deep_wide')\n",
    "    final_branch1 = Dense(units=1,activation='sigmoid',name='combined')(final_branch1)\n",
    "\n",
    "    model1 = Model(inputs=all_inputs, outputs=final_branch1)\n",
    "    model1.compile(optimizer='adagrad',\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['accuracy', precision])\n",
    "    history1 = model1.fit(X_ints_train+ [X_train_num],\n",
    "                    y_train, \n",
    "                    epochs=5, \n",
    "                    batch_size=32, \n",
    "                    verbose=1, \n",
    "                    validation_data = (X_ints_test + [X_test_num], y_test))\n",
    "    histories1.append(history1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with only puturbing the class variable slightly:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform t-SNE clustering of the weights in two of our OHE embedded layers to look for similarities between the separate classes of our Runtime Category and a subsample of our genres. We aim to prove that the Runtimes should have little to do with each other and be 4 completely separate classes, while the genres should get clustered together to other entries that have part of the same genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "weights=model1.get_layer(name='runtime_category_int_embed').get_weights()\n",
    "weight_labels=['Short Film','Less than Feature Film','Below Average Feature Film','Above Average Feature Film']\n",
    "tsne = TSNE(n_components=2, verbose=1)\n",
    "transformed_weights = tsne.fit_transform(weights[0])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(transformed_weights[:,0], transformed_weights[:,1],lw=0, s=40)\n",
    "for i, txt in enumerate(weight_labels):\n",
    "    ax.annotate(txt, (transformed_weights[:,0][i], transformed_weights[:,1][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "weights=model1.get_layer(name='genres_int_embed').get_weights()\n",
    "weight_labels=df['genres'].unique()[0:13]\n",
    "tsne = TSNE(n_components=2, verbose=1)\n",
    "transformed_weights = tsne.fit_transform(weights[0][0:13])\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(transformed_weights[:,0], transformed_weights[:,1],lw=0, s=40)\n",
    "\n",
    "for i, txt in enumerate(weight_labels):\n",
    "    ax.annotate(txt, (transformed_weights[:,0][i], transformed_weights[:,1][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We see from the two plots of the t-SNE clusters that the runtimes were indeed 4 separate classes. Some of the genres were close such as Comedy_Horror, Comedy_Romance, Comedy and Animation_Comedy_Family. Some of the \"Action\" genres were successfully grouped together. There are some errors, but this is largely due to the fact not all possible genres are included in this cluster. We only perform the t-SNE clustering on a small subset, since 1441 different classes would be illegible."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
