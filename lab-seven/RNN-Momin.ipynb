{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "The dataset we will be using is a collection of amazon reviews for instant video products found at http://jmcauley.ucsd.edu/data/amazon/. Our set includes the reviews’ product, reviewer, text review, rating, helpfulness/unhelpfulness, and other metadata. The specific dataset we are using is a “5-core” dataset meaning that it includes only products and reviewers that have more than 5 reviews on amazon. This means that each product in this dataset has at least 5 reviews and that each reviewer in this dataset has posted at least 5 reviews for this category. The set includes over 37,000 reviews. \n",
    "\n",
    "### Purpose\n",
    "\n",
    "This data was originally collected by Amazon as consumers browsed, bought, and reviewed products. This data is necessary for amazon to be able to display the reviews on each product. The specific dataset we are using is UCSD’s collection that has been structured by two researchers (Julian McAuley, Alex Yang) to understand why and what reviews are helpful to consumers when it comes to purchasing an object. They outline their findings with this data in the following paper: http://cseweb.ucsd.edu/~jmcauley/pdfs/www16b.pdf\n",
    "\n",
    "### Prediction Task\n",
    "\n",
    "Reviews have become increasingly crucial in consumer purchase decisions. As discussed in a BrightLocal study, 88% of consumers incorporate reviews into their purchase decisions. This finding for most consumers is obvious. A less obvious finding is that although customers are relying more on review data, they are reading less of them. It was found that by reading up to six reviews 73% of consumers formed an opinion as opposed to 64% in 2014. Moreover, it was found that by reading just one to three reviews 40% of consumers formed an opinion as opposed to 29% in 2014. \n",
    "\n",
    "Due to the importance of consumer reviews, online marketplaces such as Amazon are interested in learning which products are the most well-reviewed, and businesses are interested in analyzing consumer sentiment about their products. Thus, our goal is predicting the star rating (on a scale of 1 to 5) that a particular user gave a product based on the text of their review.\n",
    "\n",
    "The application of this system is that, given a system that can match an Amazon review to a star value, we could apply this system to other forms of text reviews that do not include a star review, such as tweets or (short) blog posts. This would allow companies to get a fuller picture of their star rating, rather than just Amazon product reviews.\n",
    "\n",
    "### Evaluation Metric\n",
    "\n",
    "Our data is heavily class imbalanced. We have 5 categories of rating, and a score of 5 (the highest) happens 56% of the time, whereas a score of 1 (the lowest) happens only 4.6% of the time. We feel that it is important for online marketplaces and businesses making products to get a full understanding of negative reviews as well as positive reviews; metrics that do not account for class imbalance will make product reviews look much more positive than they actually are. As a consequence, we decide to use weighted F1 score as our evaluation metric. Weighted F1 score accounts for class imbalance in the categories, suiting our business case better than other metrics. Further, both precision and recall are important to our task. \n",
    "\n",
    "Precision is important because mislabeled reviews can give an incorrect picture of an individual reviewer's sentiment; perhaps a business will want to examine more closely all reviews with a 1 star score, for example, and send an email to each of these customers that attempts to resolve their issues. If our system incorrectly labels a review as 1 star when it is really more than 1 star, the business will waste time emailing this customer when they don't need to be emailed.\n",
    "\n",
    "Recall is important because it represents completeness; how well did we represent the sentiment of users as a whole? If a company is interested in using our results to compute an overall star score, for example, the recall score is very important because it details if that score is representative of what users actually think or not.\n",
    "\n",
    "### Train/Test Split\n",
    "\n",
    "Because we do not have an especially large dataset, we will use stratified 10-fold cross validation to split our training and testing data. This fits with our proposed use case because the business using our services would want to train on an existing dataset (such as our Amazon review dataset) and apply the model to a different, but related, dataset (such as comments on the company's webpage or tweets at the company). There is not a time series aspect in our data to worry about either.\n",
    "\n",
    "We will stratify the folds in our cross validation. Our reasoning behind this decision is that stratification mirrors the real use case for our system. The reason why there is a large class imbalance is likely motivated by the psychology of why people post reviews; it is unlikely that the bias towards positive reviews seen in our dataset is unique to our dataset. Rather, we would expect that an analysis of other datasets would reveal the same positive bias. Therefore, this class imbalance is something we want to preserve; lack of stratification would skew this class imbalance.\n",
    "\n",
    "### Sources\n",
    "BrightLocal, Business2community, Bazaarvoice, webrepublic, reprevive, Econsultancy,business2community,Reevoo and Social Media Today:\n",
    "\n",
    "https://www.vendasta.com/blog/50-stats-you-need-to-know-about-online-reviews\n",
    "\n",
    "Forbes: \n",
    "\n",
    "https://www.forbes.com/sites/jaysondemers/2015/12/28/how-important-are-customer-reviews-for-online-marketing/#276bfb421928\n",
    "\n",
    "UCSD:\n",
    "\n",
    "http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "http://cseweb.ucsd.edu/~jmcauley/pdfs/www16b.pdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Processing\n",
    "In this section we will prepare the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "#Get rid of memory cached by jupyter notebook\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:54:40) [MSC v.1900 64 bit (AMD64)]\n",
      "1.14.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37126 entries, 0 to 37125\n",
      "Data columns (total 9 columns):\n",
      "asin              37126 non-null object\n",
      "helpful           37126 non-null object\n",
      "overall           37126 non-null int64\n",
      "reviewText        37126 non-null object\n",
      "reviewTime        37126 non-null object\n",
      "reviewerID        37126 non-null object\n",
      "reviewerName      36797 non-null object\n",
      "summary           37126 non-null object\n",
      "unixReviewTime    37126 non-null int64\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "print(sys.version)\n",
    "print(np.__version__)\n",
    "\n",
    "\n",
    "#load dataset\n",
    "dataframe = pd.read_json('../lab-one/reviews_Amazon_Instant_Video_5.json',lines=True)\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract information for number of reviews by each reviewer\n",
    "reviewer_ids = list(dataframe['reviewerID'])\n",
    "authorToNumReviews = {user_id:reviewer_ids.count(user_id) for user_id in set(reviewer_ids)}\n",
    "dataframe['reviewLength'] = [len(text) for text in dataframe['reviewText']]\n",
    "dataframe['reviewerNumberReviews'] = [authorToNumReviews[author] for author in dataframe['reviewerID']]\n",
    "\n",
    "#extract additional columns for analysis\n",
    "helpful_count = []\n",
    "unhelpful_count = []\n",
    "helpful_ratio = []\n",
    "for (h,total) in dataframe['helpful']:\n",
    "    helpful_count.append(h)\n",
    "    unhelpful_count.append(total-h)\n",
    "    if total == 0:\n",
    "        helpful_ratio.append(None)\n",
    "    else:\n",
    "        helpful_ratio.append(h/(total))\n",
    "dataframe['numberUnhelpful'] = unhelpful_count\n",
    "dataframe['numberHelpful'] = helpful_count\n",
    "dataframe['helpfulRatio'] = helpful_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 37126\n",
      "Number of 5 star reviews: 20890\n",
      "Number of 1 star reviews: 1718\n"
     ]
    }
   ],
   "source": [
    "print('Number of reviews:',len(dataframe.overall))\n",
    "print('Number of 5 star reviews:',sum(dataframe.overall==5))\n",
    "print('Number of 1 star reviews:',sum(dataframe.overall==1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this analysis we verify that the review score is heavily class imbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data types\n",
    "The features of this dataset are as follows :\n",
    "+ asin - ID of the product - Nominal\n",
    "+ helpful - A tuple containing the number of people that thought the review was helpful or unhelpful - Both ordinal, stored as integers\n",
    "+ overall - The overall rating that a product received. Ordinal, stored as integer\n",
    "+ reviewText - The full text of the review - Bag of words\n",
    "+ reviewTime - The timestamp of the review - Interval\n",
    "+ reviewerID - The ID of the reviewer - Nominal\n",
    "+ reviewerName - The name of the reviewer - Nominal\n",
    "+ summary - A summary of the review  - Bag of words\n",
    "+ unixReviewTime - The UNIX timestamp of the review - Interval\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data quality\n",
    "\n",
    "As mentioned before, this dataset is missing 329 reviewer names, as can be seen from the outputs above and below. We decided to keep this data as is, as there was another unique identifier for reviewers - reviewerID - that we could use to associate a reviewer with a review. Reviewer names were also not a part of our analysis or predicition, so it would in no way skew our results at the end. \n",
    "<br/>\n",
    "\n",
    "The most probable reason why there were missing values for reviewerName is that Amazon had given the option to reviewers to post anonymously and had hidden their names in the review. Since only logged in members are allowed to post reviews, we can assume that the reviewerID is sufficient for us to identify reviews by the same members.\n",
    "\n",
    "<br/> \n",
    "Furthermore, entries where numberHelpful and numberUnhelpful were 0 posed an interesting situation. Although there is an argument to classify these objects as missing and revmove or impute, we beleive these objects to be valuable as is. These reviews can help with predicting a different class of reviews: indistinct reviews. These are reviews that simply no other customers found to be helpful or unhelpful. It can be seen that over 50% of the values have 0 for those two attributes. \n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24095"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of null_data in any of the columns. \n",
    "null_data = dataframe[dataframe.isnull().any(axis=1)]\n",
    "len(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the number of duplicate entries in the dataset\n",
    "len(dataframe[dataframe.duplicated(['asin','reviewerID'],keep=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewLength</th>\n",
       "      <th>reviewerNumberReviews</th>\n",
       "      <th>numberUnhelpful</th>\n",
       "      <th>numberHelpful</th>\n",
       "      <th>helpfulRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37126.00000</td>\n",
       "      <td>3.712600e+04</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>13133.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.20953</td>\n",
       "      <td>1.376795e+09</td>\n",
       "      <td>515.292033</td>\n",
       "      <td>10.667026</td>\n",
       "      <td>0.725475</td>\n",
       "      <td>1.293541</td>\n",
       "      <td>0.574588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.11855</td>\n",
       "      <td>3.054958e+07</td>\n",
       "      <td>835.145610</td>\n",
       "      <td>13.346323</td>\n",
       "      <td>3.532468</td>\n",
       "      <td>8.301778</td>\n",
       "      <td>0.391384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.754560e+08</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.367798e+09</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.384992e+09</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.394150e+09</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.406074e+09</td>\n",
       "      <td>18152.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           overall  unixReviewTime  reviewLength  reviewerNumberReviews  \\\n",
       "count  37126.00000    3.712600e+04  37126.000000           37126.000000   \n",
       "mean       4.20953    1.376795e+09    515.292033              10.667026   \n",
       "std        1.11855    3.054958e+07    835.145610              13.346323   \n",
       "min        1.00000    9.754560e+08      4.000000               5.000000   \n",
       "25%        4.00000    1.367798e+09    145.000000               5.000000   \n",
       "50%        5.00000    1.384992e+09    232.000000               7.000000   \n",
       "75%        5.00000    1.394150e+09    484.000000              10.000000   \n",
       "max        5.00000    1.406074e+09  18152.000000             123.000000   \n",
       "\n",
       "       numberUnhelpful  numberHelpful  helpfulRatio  \n",
       "count     37126.000000   37126.000000  13133.000000  \n",
       "mean          0.725475       1.293541      0.574588  \n",
       "std           3.532468       8.301778      0.391384  \n",
       "min           0.000000       0.000000      0.000000  \n",
       "25%           0.000000       0.000000      0.200000  \n",
       "50%           0.000000       0.000000      0.666667  \n",
       "75%           0.000000       1.000000      1.000000  \n",
       "max         214.000000     484.000000      1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#More information about the dataset\n",
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515.2920325378441"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = np.zeros(10)\n",
    "avg_len = np.mean([len(x) for x in dataframe['reviewText']])\n",
    "avg_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21110 unique tokens. Distilled to 21110 top words.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37126 entries, 0 to 37125\n",
      "Data columns (total 11 columns):\n",
      "asin                     37126 non-null object\n",
      "overall                  37126 non-null int64\n",
      "reviewText               37126 non-null object\n",
      "reviewerID               37126 non-null object\n",
      "reviewerName             36797 non-null object\n",
      "summary                  37126 non-null object\n",
      "reviewLength             37126 non-null int64\n",
      "reviewerNumberReviews    37126 non-null int64\n",
      "numberUnhelpful          37126 non-null int64\n",
      "numberHelpful            37126 non-null int64\n",
      "helpfulRatio             13133 non-null float64\n",
      "dtypes: float64(1), int64(5), object(5)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "words = set(nltk.corpus.words.words())\n",
    "def english_filter(passed_string):\n",
    "    passed_string = re.sub(r'[^\\w\\s]','',passed_string)\n",
    "    passed_string = re.sub(' +',' ',passed_string)\n",
    "    passed_string = ' '.join(y for y in passed_string.splitlines())\n",
    "    passed_string = passed_string.rstrip()\n",
    "    passed_string = passed_string.rstrip('\\n')\n",
    "    passed_string = \" \".join((w if w in words else \"\") for w in passed_string.split(' '))\n",
    "    passed_string = text_to_word_sequence(passed_string, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True, split=' ')\n",
    "    return passed_string\n",
    "unneeded_attributes = ['unixReviewTime', 'helpful', 'reviewTime']\n",
    "ordinal_attributes = ['numberHelpful', 'numberUnhelpful', 'reviewLength', 'overall', 'reviewerNumberReviews']\n",
    "nominal_attributes = ['asin', 'reviewerID', 'reviewerName']\n",
    "\n",
    "for attr in unneeded_attributes:\n",
    "    if attr in dataframe:\n",
    "        del dataframe[attr]\n",
    "\n",
    "dataframe[ordinal_attributes] = dataframe[ordinal_attributes].astype(np.int64)\n",
    "dataframe['reviewText'] = dataframe.apply(lambda row: english_filter(row['reviewText']), axis=1)\n",
    "dataframe['summary'] = dataframe.apply(lambda row: english_filter(row['summary']), axis=1)\n",
    "NUM_TOP_WORDS = None\n",
    "max_review_length = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM_TOP_WORDS)\n",
    "tokenizer.fit_on_texts(dataframe['reviewText'])\n",
    "\n",
    "X = tokenizer.texts_to_sequences(dataframe['reviewText'])\n",
    "X = sequence.pad_sequences(X, maxlen=max_review_length)\n",
    "word_index = tokenizer.word_index\n",
    "NUM_TOP_WORDS = len(word_index) if NUM_TOP_WORDS==None else NUM_TOP_WORDS\n",
    "top_words = min((len(word_index),NUM_TOP_WORDS))\n",
    "print('Found %s unique tokens. Distilled to %d top words.' % (len(word_index),top_words))\n",
    "\n",
    "\n",
    "y = dataframe['overall']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "y_train=[]\n",
    "y_test = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train.append(X[train_index])\n",
    "    X_test.append(X[test_index])\n",
    "    y_train.append(y[train_index])\n",
    "    y_test.append(y[test_index])\n",
    "\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (37126, 200)\n",
      "Shape of label tensor: (37126,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of data tensor:', X.shape)\n",
    "print('Shape of label tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, make_scorer\n",
    "weighted_f1 = make_scorer(f1_score, average='weighted')\n",
    "from sklearn.utils import class_weight\n",
    "class_weight = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train[0]),\n",
    "                                                 y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x9d in position 2776: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x9d in position 2776: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EMBED_SIZE = 100\n",
    "# the embed size should match the file you load glove from\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt')\n",
    "# save key/array pairs of the embeddings\n",
    "#  the key of the dictionary is the word, the array is the embedding\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "# now fill in the matrix, using the ordering from the\n",
    "#  keras word tokenizer from before\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBED_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBED_SIZE,\n",
    "                            input_length=max_review_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN :\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          2111100   \n",
      "_________________________________________________________________\n",
      "gru_11 (GRU)                 (None, 100)               60300     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,171,501\n",
      "Trainable params: 60,401\n",
      "Non-trainable params: 2,111,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "RNN :\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          2111100   \n",
      "_________________________________________________________________\n",
      "gru_12 (GRU)                 (None, 100)               60300     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,171,501\n",
      "Trainable params: 60,401\n",
      "Non-trainable params: 2,111,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "RNN :\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 100)          2111100   \n",
      "_________________________________________________________________\n",
      "gru_13 (GRU)                 (None, 100)               60300     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 2,171,501\n",
      "Trainable params: 60,401\n",
      "Non-trainable params: 2,111,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "\n",
    "rnn_1 = Sequential()\n",
    "rnn_2 = Sequential()\n",
    "rnn_3 = Sequential()\n",
    "\n",
    "rnn_list = [rnn_1,rnn_2,rnn_3]\n",
    "\n",
    "for r in rnn_list:\n",
    "    r.add(embedding_layer)\n",
    "    r.add(GRU(100,dropout=0.2, recurrent_dropout=0.2))\n",
    "    r.add(Dense(1, activation='relu'))\n",
    "    adam = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n",
    "    r.compile(loss='mean_squared_error', \n",
    "                  optimizer=adam, \n",
    "                  metrics=['mse'])#,weighted_f1])\n",
    "\n",
    "for r in rnn_list:\n",
    "    print (\"RNN :\")\n",
    "    print(r.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 : \n",
      "\n",
      "Train on 33412 samples, validate on 3714 samples\n",
      "Epoch 1/10\n",
      "33412/33412 [==============================] - 122s 4ms/step - loss: 1.6241 - mean_squared_error: 1.6241 - val_loss: 1.2217 - val_mean_squared_error: 1.2217\n",
      "Epoch 2/10\n",
      "33412/33412 [==============================] - 101s 3ms/step - loss: 1.2390 - mean_squared_error: 1.2390 - val_loss: 1.1737 - val_mean_squared_error: 1.1737\n",
      "Epoch 3/10\n",
      "33412/33412 [==============================] - 100s 3ms/step - loss: 1.2203 - mean_squared_error: 1.2203 - val_loss: 1.1485 - val_mean_squared_error: 1.1485\n",
      "Epoch 4/10\n",
      "33412/33412 [==============================] - 101s 3ms/step - loss: 1.1364 - mean_squared_error: 1.1364 - val_loss: 1.0493 - val_mean_squared_error: 1.0493\n",
      "Epoch 5/10\n",
      "33412/33412 [==============================] - 101s 3ms/step - loss: 1.0658 - mean_squared_error: 1.0658 - val_loss: 0.9855 - val_mean_squared_error: 0.9855\n",
      "Epoch 6/10\n",
      "33412/33412 [==============================] - 101s 3ms/step - loss: 1.0190 - mean_squared_error: 1.0190 - val_loss: 0.9641 - val_mean_squared_error: 0.9641\n",
      "Epoch 7/10\n",
      "33412/33412 [==============================] - 102s 3ms/step - loss: 0.9776 - mean_squared_error: 0.9776 - val_loss: 0.9815 - val_mean_squared_error: 0.9815\n",
      "Epoch 8/10\n",
      "33412/33412 [==============================] - 102s 3ms/step - loss: 0.9573 - mean_squared_error: 0.9573 - val_loss: 0.9078 - val_mean_squared_error: 0.9078\n",
      "Epoch 9/10\n",
      "33412/33412 [==============================] - 103s 3ms/step - loss: 0.9351 - mean_squared_error: 0.9351 - val_loss: 0.8901 - val_mean_squared_error: 0.8901\n",
      "Epoch 10/10\n",
      "33412/33412 [==============================] - 100s 3ms/step - loss: 0.9159 - mean_squared_error: 0.9159 - val_loss: 0.8990 - val_mean_squared_error: 0.8990\n",
      "Fold  2 : \n",
      "\n",
      "Train on 33412 samples, validate on 3714 samples\n",
      "Epoch 1/10\n",
      "33412/33412 [==============================] - 101s 3ms/step - loss: 1.4430 - mean_squared_error: 1.4430 - val_loss: 1.2215 - val_mean_squared_error: 1.2215\n",
      "Epoch 2/10\n",
      "33412/33412 [==============================] - 98s 3ms/step - loss: 1.2227 - mean_squared_error: 1.2227 - val_loss: 1.1455 - val_mean_squared_error: 1.1455\n",
      "Epoch 3/10\n",
      "33412/33412 [==============================] - 99s 3ms/step - loss: 1.1351 - mean_squared_error: 1.1351 - val_loss: 1.0925 - val_mean_squared_error: 1.0925\n",
      "Epoch 4/10\n",
      "33412/33412 [==============================] - 97s 3ms/step - loss: 1.0660 - mean_squared_error: 1.0660 - val_loss: 1.0106 - val_mean_squared_error: 1.0106\n",
      "Epoch 5/10\n",
      "33412/33412 [==============================] - 98s 3ms/step - loss: 1.0266 - mean_squared_error: 1.0266 - val_loss: 0.9947 - val_mean_squared_error: 0.9947\n",
      "Epoch 6/10\n",
      "33412/33412 [==============================] - 97s 3ms/step - loss: 0.9941 - mean_squared_error: 0.9941 - val_loss: 0.9478 - val_mean_squared_error: 0.9478\n",
      "Epoch 7/10\n",
      "33412/33412 [==============================] - 100s 3ms/step - loss: 0.9560 - mean_squared_error: 0.9560 - val_loss: 0.9266 - val_mean_squared_error: 0.9266\n",
      "Epoch 8/10\n",
      "33412/33412 [==============================] - 101s 3ms/step - loss: 0.9330 - mean_squared_error: 0.9330 - val_loss: 0.9830 - val_mean_squared_error: 0.9830\n",
      "Epoch 9/10\n",
      "33412/33412 [==============================] - 107s 3ms/step - loss: 0.9321 - mean_squared_error: 0.9321 - val_loss: 0.9442 - val_mean_squared_error: 0.9442\n",
      "Epoch 10/10\n",
      "33412/33412 [==============================] - 98s 3ms/step - loss: 0.8916 - mean_squared_error: 0.8916 - val_loss: 0.8940 - val_mean_squared_error: 0.8940\n",
      "Fold  3 : \n",
      "\n",
      "Train on 33412 samples, validate on 3714 samples\n",
      "Epoch 1/10\n",
      "33412/33412 [==============================] - 104s 3ms/step - loss: 1.5144 - mean_squared_error: 1.5144 - val_loss: 1.2415 - val_mean_squared_error: 1.2415\n",
      "Epoch 2/10\n",
      "33412/33412 [==============================] - 99s 3ms/step - loss: 1.2414 - mean_squared_error: 1.2414 - val_loss: 1.2128 - val_mean_squared_error: 1.2128\n",
      "Epoch 3/10\n",
      "33412/33412 [==============================] - 96s 3ms/step - loss: 1.2242 - mean_squared_error: 1.2242 - val_loss: 1.1838 - val_mean_squared_error: 1.1838\n",
      "Epoch 4/10\n",
      "33412/33412 [==============================] - 96s 3ms/step - loss: 1.1503 - mean_squared_error: 1.1503 - val_loss: 1.1497 - val_mean_squared_error: 1.1497\n",
      "Epoch 5/10\n",
      "33412/33412 [==============================] - 95s 3ms/step - loss: 1.0696 - mean_squared_error: 1.0696 - val_loss: 1.0203 - val_mean_squared_error: 1.0203\n",
      "Epoch 6/10\n",
      "33412/33412 [==============================] - 96s 3ms/step - loss: 1.0064 - mean_squared_error: 1.0064 - val_loss: 1.0087 - val_mean_squared_error: 1.0087\n",
      "Epoch 7/10\n",
      "33412/33412 [==============================] - 96s 3ms/step - loss: 0.9696 - mean_squared_error: 0.9696 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "Epoch 8/10\n",
      "33412/33412 [==============================] - 95s 3ms/step - loss: 0.9363 - mean_squared_error: 0.9363 - val_loss: 0.9911 - val_mean_squared_error: 0.9911\n",
      "Epoch 9/10\n",
      "33412/33412 [==============================] - 95s 3ms/step - loss: 0.9473 - mean_squared_error: 0.9473 - val_loss: 1.0129 - val_mean_squared_error: 1.0129\n",
      "Epoch 10/10\n",
      "33412/33412 [==============================] - 95s 3ms/step - loss: 0.9060 - mean_squared_error: 0.9060 - val_loss: 1.0140 - val_mean_squared_error: 1.0140\n"
     ]
    }
   ],
   "source": [
    "history_list = []\n",
    "\n",
    "for fold in range(0,3):\n",
    "    print (\"Fold \",fold + 1, \": \\n\")\n",
    "    history_rnn_temp= rnn_list[fold].fit(X_train[fold], y_train[fold], validation_data=(X_test[fold], y_test[fold]), epochs=10, batch_size=64, shuffle=True, class_weight=class_weight)\n",
    "    history_list.append(history_rnn_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'epochs')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ca22e9a780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.title('Training')\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(history_rnn.history['mean_squared_error'])\n",
    "plt.ylabel('MSE Training')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(history_rnn.history['val_mean_squared_error'])\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(history_rnn.history['loss'])\n",
    "plt.ylabel('MSE Training Loss')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(history_rnn.history['val_loss'])\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-126bcd5ba40b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mtsne\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtransformed_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformed_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_weights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m         \"\"\"\n\u001b[1;32m--> 858\u001b[1;33m         \u001b[0membedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    859\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, skip_num_points)\u001b[0m\n\u001b[0;32m    658\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    659\u001b[0m             X = check_array(X, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[1;32m--> 660\u001b[1;33m                             dtype=[np.float32, np.float64])\n\u001b[0m\u001b[0;32m    661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'barnes_hut'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m             raise ValueError(\"'n_components' should be inferior to 4 for the \"\n",
      "\u001b[1;32mc:\\users\\momin\\envs\\ml_lab1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    439\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# To ensure that array flags are maintained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "weights = []\n",
    "weight_labels=[]\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        weights.append(embedding_vector)\n",
    "        weight_labels.append(word)\n",
    "        if len(weight_labels)==50:\n",
    "            break\n",
    "tsne = TSNE(n_components=2, verbose=1)\n",
    "transformed_weights = tsne.fit_transform(weights)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(transformed_weights[:,0], transformed_weights[:,1],lw=0, s=40)\n",
    "for i, txt in enumerate(weight_labels):\n",
    "    ax.annotate(txt, (transformed_weights[:,0][i], transformed_weights[:,1][i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
