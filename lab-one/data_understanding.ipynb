{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37126 entries, 0 to 37125\n",
      "Data columns (total 9 columns):\n",
      "asin              37126 non-null object\n",
      "helpful           37126 non-null object\n",
      "overall           37126 non-null int64\n",
      "reviewText        37126 non-null object\n",
      "reviewTime        37126 non-null object\n",
      "reviewerID        37126 non-null object\n",
      "reviewerName      36797 non-null object\n",
      "summary           37126 non-null object\n",
      "unixReviewTime    37126 non-null int64\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#load dataset\n",
    "import pandas as pd\n",
    "dataframe = pd.read_json('reviews_Amazon_Instant_Video_5.json',lines=True)\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data types\n",
    "The features of this dataset are as follows :\n",
    "+ asin - ID of the product - Nominal\n",
    "+ helpful - A tuple containing the number of people that thought the review was helpful or unhelpful - Both ordinal, stored as integers\n",
    "+ overall - The overall rating that a product received. Ordinal, stored as integer\n",
    "+ reviewText - The full text of the review - Bag of words\n",
    "+ reviewTime - The timestamp of the review - Interval\n",
    "+ reviewerID - The ID of the reviewer - Nominal\n",
    "+ reviewerName - The name of the reviewer - Nominal\n",
    "+ summary - A summary of the review  - Bag of words\n",
    "+ unixReviewTime - The UNIX timestamp of the review - Interval\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Additionally, we extracted the following attributes from the already existing attributes that will help us in our analysis of the dataset :\n",
    "+ numberHelpful - The amount of people that thought the review was helpful, extracted from the helpful tuple. Ordinal, stored as integer\n",
    "+ numberUnhelpful - The amount of people that thought the review was unhelpful, extracted from the helpful tuple. Ordinal, stored as integer\n",
    "+ reviewerNumberReviews - The number of reviews each reviewer had left. Ordinal, stored as integer\n",
    "+ reviewLength  - The length of the review text. Ordinal, stored as integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#extract additional columns for analysis\n",
    "dataframe['numberUnhelpful']= [y for [x,y] in dataframe['helpful']]\n",
    "dataframe['numberHelpful']= [x for [x,y] in dataframe['helpful'] ]\n",
    "dataframe['reviewLength'] = [len(x) for x in dataframe['reviewText']]\n",
    "\n",
    "#extract information for number of reviews by each reviewer\n",
    "reviewerNames = list(dataframe['reviewerName'])\n",
    "authorToNumReviews = {name:reviewerNames.count(name) for name in set(reviewerNames)}\n",
    "dataframe['reviewerNumberReviews'] = [authorToNumReviews[author] for author in dataframe['reviewerName']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "We had to convert the reviewText and summary to a bag of words model to ease us in our analysis and prediction. Those were stored in two variables, <i>review_bag</i> and <i>summary_bag</i>.\n",
    "<br/> <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "review_bag = count_vect.fit_transform(dataframe['reviewText'])\n",
    "summary_bag = count_vect.fit_transform(dataframe['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> \n",
    "We discarded the attributes we would not need for our analysis and set the appropriate storage types to those that were not already assigned. \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37126 entries, 0 to 37125\n",
      "Data columns (total 10 columns):\n",
      "asin                     37126 non-null object\n",
      "overall                  37126 non-null int64\n",
      "reviewText               37126 non-null object\n",
      "reviewerID               37126 non-null object\n",
      "reviewerName             36797 non-null object\n",
      "summary                  37126 non-null object\n",
      "numberUnhelpful          37126 non-null int64\n",
      "numberHelpful            37126 non-null int64\n",
      "reviewLength             37126 non-null int64\n",
      "reviewerNumberReviews    37126 non-null int64\n",
      "dtypes: int64(5), object(5)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unneeded_attributes = ['unixReviewTime', 'helpful', 'reviewTime']\n",
    "ordinal_attributes = ['numberHelpful', 'numberUnhelpful', 'reviewLength', 'overall', 'reviewerNumberReviews']\n",
    "nominal_attributes = ['asin', 'reviewerID', 'reviewerName']\n",
    "\n",
    "for attr in unneeded_attributes:\n",
    "    if attr in dataframe:\n",
    "        del dataframe[attr]\n",
    "\n",
    "dataframe[ordinal_attributes] = dataframe[ordinal_attributes].astype(np.int64)\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Data quality\n",
    "\n",
    "The dataset that was provided was not missing any values for the attributes we wanted to use. It was, however, missing 329 reviewer names, as can be seen from the outputs above and below. We decided to keep this data as is, as there was another unique identifier for reviewers - reviewerID - that we could use to associate a reviewer with a review. Reviewer names were also not a part of our analysis or predicition, so it would in no way skew our results at the end. \n",
    "<br/>\n",
    "The most probable reason why there were missing values for reviewerName is that Amazon had given the option to reviewers to post anonymously and had hidden their names in the review. Since only logged in members are allowed to post reviews, we can assume that the reviewerID is sufficient for us to identify reviews by the same members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "329"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_data = dataframe[dataframe.isnull().any(axis=1)]\n",
    "len(null_data)\n",
    "#pd.get_dummies(dataframe.reviewerID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/> \n",
    "Furthermore, we decided to not treat entries where numberHelpful and numberUnhelpful were 0 as missing, as it was not an erroneous entry of information, but could signify that simply no other customers found this review to be helpful or unhelpful and could damage our final result, should we choose to delete or impute these values. It can be seen that over 50% of the values have 0 for those two attributes. \n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>numberUnhelpful</th>\n",
       "      <th>numberHelpful</th>\n",
       "      <th>reviewLength</th>\n",
       "      <th>reviewerNumberReviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>37126.00000</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>37126.000000</td>\n",
       "      <td>37126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.20953</td>\n",
       "      <td>2.019016</td>\n",
       "      <td>1.293541</td>\n",
       "      <td>515.292033</td>\n",
       "      <td>25.152562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.11855</td>\n",
       "      <td>10.086076</td>\n",
       "      <td>8.301778</td>\n",
       "      <td>835.145610</td>\n",
       "      <td>88.755763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>232.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.00000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>484.000000</td>\n",
       "      <td>18152.000000</td>\n",
       "      <td>645.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           overall  numberUnhelpful  numberHelpful  reviewLength  \\\n",
       "count  37126.00000     37126.000000   37126.000000  37126.000000   \n",
       "mean       4.20953         2.019016       1.293541    515.292033   \n",
       "std        1.11855        10.086076       8.301778    835.145610   \n",
       "min        1.00000         0.000000       0.000000      4.000000   \n",
       "25%        4.00000         0.000000       0.000000    145.000000   \n",
       "50%        5.00000         0.000000       0.000000    232.000000   \n",
       "75%        5.00000         1.000000       1.000000    484.000000   \n",
       "max        5.00000       512.000000     484.000000  18152.000000   \n",
       "\n",
       "       reviewerNumberReviews  \n",
       "count           37126.000000  \n",
       "mean               25.152562  \n",
       "std                88.755763  \n",
       "min                 1.000000  \n",
       "25%                 5.000000  \n",
       "50%                 7.000000  \n",
       "75%                11.000000  \n",
       "max               645.000000  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "The dataset we chose had no duplicate entries in it and eliminated the need for us to handle such a case. There were no instances where the same review was posted twice or the same reviewer had posted on the same item twice. If we had to deal with such a case, we would have eliminated all such entries, as they could be interpreted as a mistake in the data collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe[dataframe.duplicated(['asin','reviewerID'],keep=False)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
